{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection (README.md for Member/Model folder): "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General performance summary table of models: \n",
    "\n",
    "|           |Train Set| Train Set|Train Set|Test Set|Test Set|Test Set|\n",
    "|-----------|-------|----------|---------|-------|----------|---------|\n",
    "| **Model**| **R2** | **RMSE** | **MAPE%**   | **R2**    | **RMSE**    | **MAPE%**  |\n",
    "| Linear Regression | 0.9965 | 799.3932 | 4.3926  | 0.9898 | 1339.5982 | 2.9076 |\n",
    "| SVM          | 0.9968 | 985.0937 | 3.3692% | 0.9611 | 831.7924 | 2.6539% |\n",
    "| KNN   | 0.9974 | 889.2344 | 2.7631% | 0.9113 | 1256.7745 | 4.0181% |\n",
    "| Random Forest   |  *0.9910* | 33.5004 | 0.0802% | 0.9897 | 430.0638| 1.3385% |\n",
    "| Adaboost    | 0.9999 | 138.6738 | 1.4610% | 0.8784 | 1471.1650| 5.5057% | \n",
    "| Catboost    | 0.9308 | 4556.6289 | 125.8332% | 0.8385 | 1695.4286| 6.1289% | \n",
    "| XGBoost       | 0.9970 | 925.0439 | 2.9174% | 0.9501 | 1015.8001| 3.5157% |\n",
    "| LightGBM    | *0.9903* | 549.2033 | 1.2529% | 0.9640 |805.4951| 2.4725% |\n",
    "| ARIMA      | 0.9970 | 733.2738 | 2.8100% | -1.5391 | 21103.8951 | 79.7169% |\n",
    "| GAN   | 0.9955  | 706.8428     | 3.29%        | 0.9651   | 731.9221   | 2.30%    |\n",
    "| GRU   | 0.9971   | 666.0494     | 2.98%        | 0.9738     | 651.7368    | 2.04%  |\n",
    "| LSTM  | 0.9969    | 666.1824     | 3.00%    | 0.9736     | 669.6527    | 2.07%  |\n",
    "\n",
    "SORT ACCORDING **R2_TEST**: \n",
    "\n",
    "|           |Train Set| Train Set|Train Set|Test Set|Test Set|Test Set|\n",
    "|-----------|-------|----------|---------|-------|----------|---------|\n",
    "| **Model**| **R2** | **RMSE** | **MAPE%**   | **R2**    | **RMSE**    | **MAPE%**  |\n",
    "| Linear Regression | 0.9965 | 799.3932 | 4.3926  | 0.9898 | 1339.5982 | 2.9076 |\n",
    "| Random Forest    | *0.9910* | 33.5004 | 0.0802% | 0.9897 | 430.0638| 1.3385% |\n",
    "| GRU   | 0.9971   | 666.0494     | 2.98%        | 0.9738     | 651.7368    | 2.04%  |\n",
    "| LSTM  | 0.9969    | 666.1824     | 3.00%    | 0.9736     | 669.6527    | 2.07%  |\n",
    "| GAN   | 0.9955  | 706.8428     | 3.29%        | 0.9651   | 731.9221   | 2.30%    |\n",
    "| LightGBM           | *0.9903* | 549.2033 | 1.2529% | 0.9640 |805.4951| 2.4725% |\n",
    "| SVM          | 0.9968 | 985.0937 | 3.3692% | 0.9611 | 831.7924 | 2.6539% |\n",
    "| XGBoost           | 0.9970 | 925.0439 | 2.9174% | 0.9501 | 1015.8001| 3.5157% |\n",
    "| KNN   | 0.9974 | 889.2344 | 2.7631% | 0.9113 | 1256.7745 | 4.0181% |\n",
    "| Adaboost          | 0.9999 | 138.6738 | 1.4610% | 0.8784 | 1471.1650| 5.5057% | \n",
    "| Catboost          | 0.9308 | 4556.6289 | 125.8332% | 0.8385 | 1695.4286| 6.1289% |\n",
    "| ARIMA         | 0.9970 | 733.2738 | 2.8100% | -1.5391 | 21103.8951 | 79.7169% |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the performance results of the models *BITCOIN PRICE PREDICTION*\n",
    "\n",
    "**Overall**\n",
    "\n",
    "From the analysis, it can be observed that several models exhibit good performance in predicting Bitcoin prices. The top-performing models include LSTM, GRU, GAN, and LightGBM, Linear Regression, Random Forest, which demonstrate high R2 values on both the training and test sets. Additionally, these models exhibit low RMSE values and MAPE% on the test set, indicating accurate predictions with minimal error.\n",
    "\n",
    "On the other hand, KNN, Catboost, Adaboost, and ARIMA models display lower effectiveness compared to other models. These models exhibit lower R2 values on the test set and higher error metrics, particularly Adaboost and ARIMA, which demonstrate significantly higher MAPE% values on the test set.\n",
    "\n",
    "**Analyzing the different types of models used**\n",
    "*Experiments show that:*\n",
    "\n",
    "1. The statistical model ARIMA shows the lowest performance. This can be attributed to the fact that this method utilizes less information compared to other approaches, leading to lower performance.\n",
    "\n",
    "2. Machine learning models, such as Linear Regression, demonstrate good performance. It can be hypothesized that this is due to good data normalization and the presence of linear relationships between various economic and market factors. Linear regression gives better performance than KNN and SVM\n",
    "\n",
    "3. Ensemble learning models, including bagging methods such as Random Forest and boosting methods such as AdaBoost, CatBoost, XGBoost, and LightGBM, demonstrated good performance but fell short of expectations, with the exception of the Random Forest method. This is because Random Forests typically employ a large number of decision trees, each with a relatively high depth, which enables them to learn complex rules and make efficient use of the relationship between features. On the other hand, LightGBM, XGBoost, AdaBoost, and CatBoost also perform well but require adjusting the number and depth of trees for optimal results.\n",
    "\n",
    "4. The Deep Learning model demonstrates good performance at a high level, and there is still room for improvement. However, due to time and resource limitations, we were unable to adjust the parameters or create more complex neural networks to maximize the model's performance.\n",
    "\n",
    "**In summary**\n",
    "\n",
    "In summary, the analysis reveals the superiority of linear methods, such as Linear Regression and Random Forest, compared to other models in terms of training time and overall performance. Deep learning models exhibit good performance and have the potential for further improvement, but they require longer training times and resource-intensive parameter tuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run all models with the same data division"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Import Library, Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import  LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import  SVR\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb                                             \n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2660 entries, 0 to 2659\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Date                    2660 non-null   object \n",
      " 1   BTC_close               2660 non-null   float64\n",
      " 2   BTC_open                2660 non-null   float64\n",
      " 3   BTC_high                2660 non-null   float64\n",
      " 4   BTC_low                 2660 non-null   float64\n",
      " 5   difficulty              2660 non-null   int64  \n",
      " 6   addresses_active_count  2660 non-null   int64  \n",
      " 7   sum_lock_weight         2660 non-null   int64  \n",
      " 8   mean_lock_size_ytes     2660 non-null   float64\n",
      " 9   total_fees_usd          2660 non-null   float64\n",
      " 10  mean_hash_rate          2660 non-null   float64\n",
      " 11  xfer_cnt                2660 non-null   int64  \n",
      " 12  mean_tx_size_usd        2660 non-null   float64\n",
      " 13  ETH                     2660 non-null   float64\n",
      " 14  LTC                     2660 non-null   float64\n",
      " 15  XRP                     2660 non-null   float64\n",
      " 16  DOGE                    2660 non-null   float64\n",
      " 17  COPPER                  2660 non-null   float64\n",
      " 18  GOLD                    2660 non-null   float64\n",
      " 19  SILVER                  2660 non-null   float64\n",
      " 20  SPX                     2660 non-null   float64\n",
      " 21  JP225                   2660 non-null   float64\n",
      " 22  DJI                     2660 non-null   float64\n",
      " 23  BTC_close_tomorrow      2660 non-null   float64\n",
      "dtypes: float64(19), int64(4), object(1)\n",
      "memory usage: 498.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>BTC_open</th>\n",
       "      <th>BTC_high</th>\n",
       "      <th>BTC_low</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>addresses_active_count</th>\n",
       "      <th>sum_lock_weight</th>\n",
       "      <th>mean_lock_size_ytes</th>\n",
       "      <th>total_fees_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>LTC</th>\n",
       "      <th>XRP</th>\n",
       "      <th>DOGE</th>\n",
       "      <th>COPPER</th>\n",
       "      <th>GOLD</th>\n",
       "      <th>SILVER</th>\n",
       "      <th>SPX</th>\n",
       "      <th>JP225</th>\n",
       "      <th>DJI</th>\n",
       "      <th>BTC_close_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>415.8</td>\n",
       "      <td>412.8</td>\n",
       "      <td>417.5</td>\n",
       "      <td>410.3</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>445273</td>\n",
       "      <td>426654988</td>\n",
       "      <td>6.881532e+05</td>\n",
       "      <td>1.731272e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-11</td>\n",
       "      <td>419.1</td>\n",
       "      <td>415.8</td>\n",
       "      <td>422.4</td>\n",
       "      <td>415.1</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>434658</td>\n",
       "      <td>398582424</td>\n",
       "      <td>6.227850e+05</td>\n",
       "      <td>1.710193e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>410.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>410.4</td>\n",
       "      <td>419.1</td>\n",
       "      <td>420.7</td>\n",
       "      <td>407.0</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>374730</td>\n",
       "      <td>331208848</td>\n",
       "      <td>5.750154e+05</td>\n",
       "      <td>1.398444e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>412.4</td>\n",
       "      <td>410.4</td>\n",
       "      <td>415.9</td>\n",
       "      <td>409.6</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>421585</td>\n",
       "      <td>334817852</td>\n",
       "      <td>6.293569e+05</td>\n",
       "      <td>1.460678e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>414.3</td>\n",
       "      <td>412.4</td>\n",
       "      <td>416.1</td>\n",
       "      <td>411.2</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>451902</td>\n",
       "      <td>437739524</td>\n",
       "      <td>7.199663e+05</td>\n",
       "      <td>1.689298e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>26515.0</td>\n",
       "      <td>26341.3</td>\n",
       "      <td>26767.3</td>\n",
       "      <td>26183.5</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>863600</td>\n",
       "      <td>559141195</td>\n",
       "      <td>1.724510e+06</td>\n",
       "      <td>1.041701e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>76.87</td>\n",
       "      <td>0.47940</td>\n",
       "      <td>0.062193</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26339.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2023-06-18</td>\n",
       "      <td>26339.7</td>\n",
       "      <td>26515.0</td>\n",
       "      <td>26679.3</td>\n",
       "      <td>26290.6</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>883864</td>\n",
       "      <td>603064705</td>\n",
       "      <td>1.985675e+06</td>\n",
       "      <td>7.946708e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>77.20</td>\n",
       "      <td>0.48699</td>\n",
       "      <td>0.062107</td>\n",
       "      <td>3.8738</td>\n",
       "      <td>1969.45</td>\n",
       "      <td>24.198</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26845.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>2023-06-19</td>\n",
       "      <td>26845.9</td>\n",
       "      <td>26339.7</td>\n",
       "      <td>27029.7</td>\n",
       "      <td>26295.1</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>920552</td>\n",
       "      <td>567091224</td>\n",
       "      <td>1.758290e+06</td>\n",
       "      <td>8.514319e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>77.51</td>\n",
       "      <td>0.49341</td>\n",
       "      <td>0.062429</td>\n",
       "      <td>3.8643</td>\n",
       "      <td>1964.05</td>\n",
       "      <td>24.062</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28307.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>28307.7</td>\n",
       "      <td>26845.9</td>\n",
       "      <td>28393.0</td>\n",
       "      <td>26665.5</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>951926</td>\n",
       "      <td>543133484</td>\n",
       "      <td>1.677592e+06</td>\n",
       "      <td>1.052364e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>80.31</td>\n",
       "      <td>0.49270</td>\n",
       "      <td>0.063108</td>\n",
       "      <td>3.8835</td>\n",
       "      <td>1947.70</td>\n",
       "      <td>23.234</td>\n",
       "      <td>4388.71</td>\n",
       "      <td>33155.0</td>\n",
       "      <td>34356.0</td>\n",
       "      <td>29996.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>2023-06-21</td>\n",
       "      <td>29996.9</td>\n",
       "      <td>28307.7</td>\n",
       "      <td>30769.5</td>\n",
       "      <td>28270.5</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>920555</td>\n",
       "      <td>483181576</td>\n",
       "      <td>1.611773e+06</td>\n",
       "      <td>1.347976e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>85.12</td>\n",
       "      <td>0.49995</td>\n",
       "      <td>0.065644</td>\n",
       "      <td>3.9135</td>\n",
       "      <td>1944.90</td>\n",
       "      <td>22.810</td>\n",
       "      <td>4365.69</td>\n",
       "      <td>33390.0</td>\n",
       "      <td>34235.0</td>\n",
       "      <td>29890.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2660 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  BTC_close  BTC_open  BTC_high  BTC_low      difficulty   \n",
       "0     2016-03-10      415.8     412.8     417.5    410.3    158427203767  \\\n",
       "1     2016-03-11      419.1     415.8     422.4    415.1    158427203767   \n",
       "2     2016-03-12      410.4     419.1     420.7    407.0    158427203767   \n",
       "3     2016-03-13      412.4     410.4     415.9    409.6    158427203767   \n",
       "4     2016-03-14      414.3     412.4     416.1    411.2    158427203767   \n",
       "...          ...        ...       ...       ...      ...             ...   \n",
       "2655  2023-06-17    26515.0   26341.3   26767.3  26183.5  52350439455487   \n",
       "2656  2023-06-18    26339.7   26515.0   26679.3  26290.6  52350439455487   \n",
       "2657  2023-06-19    26845.9   26339.7   27029.7  26295.1  52350439455487   \n",
       "2658  2023-06-20    28307.7   26845.9   28393.0  26665.5  52350439455487   \n",
       "2659  2023-06-21    29996.9   28307.7   30769.5  28270.5  52350439455487   \n",
       "\n",
       "      addresses_active_count  sum_lock_weight  mean_lock_size_ytes   \n",
       "0                     445273        426654988         6.881532e+05  \\\n",
       "1                     434658        398582424         6.227850e+05   \n",
       "2                     374730        331208848         5.750154e+05   \n",
       "3                     421585        334817852         6.293569e+05   \n",
       "4                     451902        437739524         7.199663e+05   \n",
       "...                      ...              ...                  ...   \n",
       "2655                  863600        559141195         1.724510e+06   \n",
       "2656                  883864        603064705         1.985675e+06   \n",
       "2657                  920552        567091224         1.758290e+06   \n",
       "2658                  951926        543133484         1.677592e+06   \n",
       "2659                  920555        483181576         1.611773e+06   \n",
       "\n",
       "      total_fees_usd  ...    LTC      XRP      DOGE  COPPER     GOLD  SILVER   \n",
       "0       1.731272e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000  \\\n",
       "1       1.710193e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000   \n",
       "2       1.398444e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000   \n",
       "3       1.460678e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000   \n",
       "4       1.689298e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000   \n",
       "...              ...  ...    ...      ...       ...     ...      ...     ...   \n",
       "2655    1.041701e+06  ...  76.87  0.47940  0.062193  0.0000     0.00   0.000   \n",
       "2656    7.946708e+05  ...  77.20  0.48699  0.062107  3.8738  1969.45  24.198   \n",
       "2657    8.514319e+05  ...  77.51  0.49341  0.062429  3.8643  1964.05  24.062   \n",
       "2658    1.052364e+06  ...  80.31  0.49270  0.063108  3.8835  1947.70  23.234   \n",
       "2659    1.347976e+06  ...  85.12  0.49995  0.065644  3.9135  1944.90  22.810   \n",
       "\n",
       "          SPX    JP225      DJI  BTC_close_tomorrow  \n",
       "0        0.00      0.0      0.0               419.1  \n",
       "1        0.00      0.0      0.0               410.4  \n",
       "2        0.00      0.0      0.0               412.4  \n",
       "3        0.00      0.0      0.0               414.3  \n",
       "4        0.00      0.0      0.0               415.1  \n",
       "...       ...      ...      ...                 ...  \n",
       "2655     0.00      0.0      0.0             26339.7  \n",
       "2656     0.00      0.0      0.0             26845.9  \n",
       "2657     0.00      0.0      0.0             28307.7  \n",
       "2658  4388.71  33155.0  34356.0             29996.9  \n",
       "2659  4365.69  33390.0  34235.0             29890.5  \n",
       "\n",
       "[2660 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/lavibula/ML20222.PredictionBitcoin/main/data/data.csv\")\n",
    "# data = pd.read_csv(r\"C:\\Users\\Administrator\\OneDrive - Hanoi University of Science and Technology\\ITE10 - Data Science and AI - HUST\\20222\\ML\\Source_Codes\\ML20222.PredictionBitcoin\\data\\data.csv\")\n",
    "# print(data.info())\n",
    "data = data.sort_values('Date', ascending=True).reset_index(drop=True) # drop=True bỏ 'index' col cũ. \n",
    "\n",
    "# Use BTC_close_tomorrow as y (Target col) of X_today, instead of BTC_close_today\n",
    "data[\"BTC_close_tomorrow\"] = data[\"BTC_close\"].shift(-1)\n",
    "data = data.iloc[:-1] # data = data.drop(data.index[-1])\n",
    "print(data.info())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for pre-train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(['BTC_close_tomorrow', 'Date'], axis=1)\n",
    "y = data['BTC_close_tomorrow']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.25, random_state=42, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Use default parameters for all model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use default parameters for all model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.045664\n",
      "0:\tlearn: 12903.3976523\ttotal: 177ms\tremaining: 2m 57s\n",
      "1:\tlearn: 12359.3759762\ttotal: 191ms\tremaining: 1m 35s\n",
      "2:\tlearn: 11861.7824591\ttotal: 225ms\tremaining: 1m 14s\n",
      "3:\tlearn: 11382.2375075\ttotal: 272ms\tremaining: 1m 7s\n",
      "4:\tlearn: 10912.4977246\ttotal: 309ms\tremaining: 1m 1s\n",
      "5:\tlearn: 10460.7012842\ttotal: 347ms\tremaining: 57.5s\n",
      "6:\tlearn: 10025.1804093\ttotal: 395ms\tremaining: 56s\n",
      "7:\tlearn: 9611.2997119\ttotal: 424ms\tremaining: 52.6s\n",
      "8:\tlearn: 9225.3129340\ttotal: 443ms\tremaining: 48.7s\n",
      "9:\tlearn: 8850.0701352\ttotal: 460ms\tremaining: 45.6s\n",
      "10:\tlearn: 8495.5015763\ttotal: 504ms\tremaining: 45.3s\n",
      "11:\tlearn: 8161.4262947\ttotal: 527ms\tremaining: 43.4s\n",
      "12:\tlearn: 7835.7274803\ttotal: 563ms\tremaining: 42.8s\n",
      "13:\tlearn: 7514.5685945\ttotal: 646ms\tremaining: 45.5s\n",
      "14:\tlearn: 7215.9008284\ttotal: 673ms\tremaining: 44.2s\n",
      "15:\tlearn: 6923.5892757\ttotal: 705ms\tremaining: 43.4s\n",
      "16:\tlearn: 6655.5325661\ttotal: 726ms\tremaining: 42s\n",
      "17:\tlearn: 6379.4615779\ttotal: 774ms\tremaining: 42.2s\n",
      "18:\tlearn: 6117.6006419\ttotal: 808ms\tremaining: 41.7s\n",
      "19:\tlearn: 5870.8452126\ttotal: 825ms\tremaining: 40.4s\n",
      "20:\tlearn: 5643.6239335\ttotal: 844ms\tremaining: 39.3s\n",
      "21:\tlearn: 5416.1574899\ttotal: 858ms\tremaining: 38.1s\n",
      "22:\tlearn: 5193.8784517\ttotal: 872ms\tremaining: 37s\n",
      "23:\tlearn: 4984.3943236\ttotal: 882ms\tremaining: 35.9s\n",
      "24:\tlearn: 4786.3858255\ttotal: 896ms\tremaining: 34.9s\n",
      "25:\tlearn: 4588.4593326\ttotal: 907ms\tremaining: 34s\n",
      "26:\tlearn: 4407.5420401\ttotal: 920ms\tremaining: 33.1s\n",
      "27:\tlearn: 4236.6967419\ttotal: 934ms\tremaining: 32.4s\n",
      "28:\tlearn: 4071.1837090\ttotal: 952ms\tremaining: 31.9s\n",
      "29:\tlearn: 3918.6184034\ttotal: 972ms\tremaining: 31.4s\n",
      "30:\tlearn: 3772.6322965\ttotal: 1s\tremaining: 31.4s\n",
      "31:\tlearn: 3625.5820953\ttotal: 1.04s\tremaining: 31.5s\n",
      "32:\tlearn: 3490.1758025\ttotal: 1.1s\tremaining: 32.2s\n",
      "33:\tlearn: 3360.3626234\ttotal: 1.13s\tremaining: 32.1s\n",
      "34:\tlearn: 3235.4218766\ttotal: 1.15s\tremaining: 31.7s\n",
      "35:\tlearn: 3115.8076357\ttotal: 1.17s\tremaining: 31.3s\n",
      "36:\tlearn: 2997.7597844\ttotal: 1.18s\tremaining: 30.8s\n",
      "37:\tlearn: 2890.3483036\ttotal: 1.2s\tremaining: 30.3s\n",
      "38:\tlearn: 2786.1072775\ttotal: 1.23s\tremaining: 30.4s\n",
      "39:\tlearn: 2689.2376103\ttotal: 1.26s\tremaining: 30.2s\n",
      "40:\tlearn: 2592.1294255\ttotal: 1.28s\tremaining: 29.9s\n",
      "41:\tlearn: 2497.2085350\ttotal: 1.29s\tremaining: 29.4s\n",
      "42:\tlearn: 2406.5764051\ttotal: 1.3s\tremaining: 29.1s\n",
      "43:\tlearn: 2323.0400199\ttotal: 1.33s\tremaining: 28.9s\n",
      "44:\tlearn: 2242.7207329\ttotal: 1.34s\tremaining: 28.5s\n",
      "45:\tlearn: 2164.9085171\ttotal: 1.37s\tremaining: 28.4s\n",
      "46:\tlearn: 2093.4814823\ttotal: 1.38s\tremaining: 28.1s\n",
      "47:\tlearn: 2029.9132309\ttotal: 1.4s\tremaining: 27.7s\n",
      "48:\tlearn: 1964.7378006\ttotal: 1.41s\tremaining: 27.4s\n",
      "49:\tlearn: 1899.7656604\ttotal: 1.43s\tremaining: 27.1s\n",
      "50:\tlearn: 1839.1825941\ttotal: 1.44s\tremaining: 26.8s\n",
      "51:\tlearn: 1781.1175926\ttotal: 1.45s\tremaining: 26.5s\n",
      "52:\tlearn: 1727.3670733\ttotal: 1.47s\tremaining: 26.2s\n",
      "53:\tlearn: 1676.3010416\ttotal: 1.48s\tremaining: 25.9s\n",
      "54:\tlearn: 1624.9311387\ttotal: 1.49s\tremaining: 25.6s\n",
      "55:\tlearn: 1579.4287657\ttotal: 1.51s\tremaining: 25.4s\n",
      "56:\tlearn: 1539.9418615\ttotal: 1.52s\tremaining: 25.1s\n",
      "57:\tlearn: 1499.3688559\ttotal: 1.53s\tremaining: 24.8s\n",
      "58:\tlearn: 1464.2570394\ttotal: 1.54s\tremaining: 24.6s\n",
      "59:\tlearn: 1428.6856722\ttotal: 1.56s\tremaining: 24.4s\n",
      "60:\tlearn: 1392.5609727\ttotal: 1.57s\tremaining: 24.2s\n",
      "61:\tlearn: 1358.1570483\ttotal: 1.6s\tremaining: 24.3s\n",
      "62:\tlearn: 1327.6999207\ttotal: 1.63s\tremaining: 24.2s\n",
      "63:\tlearn: 1297.2014614\ttotal: 1.66s\tremaining: 24.2s\n",
      "64:\tlearn: 1268.8704967\ttotal: 1.69s\tremaining: 24.3s\n",
      "65:\tlearn: 1240.9969424\ttotal: 1.72s\tremaining: 24.3s\n",
      "66:\tlearn: 1214.7332939\ttotal: 1.75s\tremaining: 24.4s\n",
      "67:\tlearn: 1191.8757822\ttotal: 1.77s\tremaining: 24.3s\n",
      "68:\tlearn: 1169.6439984\ttotal: 1.78s\tremaining: 24.1s\n",
      "69:\tlearn: 1147.7995736\ttotal: 1.8s\tremaining: 23.9s\n",
      "70:\tlearn: 1128.9219554\ttotal: 1.81s\tremaining: 23.8s\n",
      "71:\tlearn: 1111.6460093\ttotal: 1.83s\tremaining: 23.6s\n",
      "72:\tlearn: 1092.7332382\ttotal: 1.84s\tremaining: 23.4s\n",
      "73:\tlearn: 1073.9344632\ttotal: 1.86s\tremaining: 23.2s\n",
      "74:\tlearn: 1057.0381019\ttotal: 1.87s\tremaining: 23.1s\n",
      "75:\tlearn: 1041.7261410\ttotal: 1.89s\tremaining: 22.9s\n",
      "76:\tlearn: 1027.7949719\ttotal: 1.9s\tremaining: 22.8s\n",
      "77:\tlearn: 1012.9728174\ttotal: 1.92s\tremaining: 22.7s\n",
      "78:\tlearn: 999.4002761\ttotal: 1.93s\tremaining: 22.5s\n",
      "79:\tlearn: 986.9130442\ttotal: 1.94s\tremaining: 22.3s\n",
      "80:\tlearn: 976.0750182\ttotal: 1.96s\tremaining: 22.3s\n",
      "81:\tlearn: 964.3074339\ttotal: 1.98s\tremaining: 22.2s\n",
      "82:\tlearn: 953.5094730\ttotal: 2s\tremaining: 22.1s\n",
      "83:\tlearn: 942.8621601\ttotal: 2.01s\tremaining: 22s\n",
      "84:\tlearn: 932.8513471\ttotal: 2.03s\tremaining: 21.8s\n",
      "85:\tlearn: 923.9071549\ttotal: 2.04s\tremaining: 21.7s\n",
      "86:\tlearn: 916.1557871\ttotal: 2.05s\tremaining: 21.5s\n",
      "87:\tlearn: 907.8584908\ttotal: 2.06s\tremaining: 21.4s\n",
      "88:\tlearn: 899.1871573\ttotal: 2.08s\tremaining: 21.3s\n",
      "89:\tlearn: 891.7982287\ttotal: 2.1s\tremaining: 21.3s\n",
      "90:\tlearn: 884.6945888\ttotal: 2.16s\tremaining: 21.6s\n",
      "91:\tlearn: 877.7077495\ttotal: 2.19s\tremaining: 21.7s\n",
      "92:\tlearn: 871.6991973\ttotal: 2.24s\tremaining: 21.9s\n",
      "93:\tlearn: 865.7899739\ttotal: 2.26s\tremaining: 21.8s\n",
      "94:\tlearn: 859.2191711\ttotal: 2.29s\tremaining: 21.8s\n",
      "95:\tlearn: 853.2263698\ttotal: 2.3s\tremaining: 21.7s\n",
      "96:\tlearn: 847.9973160\ttotal: 2.32s\tremaining: 21.6s\n",
      "97:\tlearn: 842.9414662\ttotal: 2.34s\tremaining: 21.5s\n",
      "98:\tlearn: 838.7113736\ttotal: 2.35s\tremaining: 21.4s\n",
      "99:\tlearn: 833.8145230\ttotal: 2.37s\tremaining: 21.3s\n",
      "100:\tlearn: 828.8680200\ttotal: 2.4s\tremaining: 21.4s\n",
      "101:\tlearn: 824.8479608\ttotal: 2.44s\tremaining: 21.4s\n",
      "102:\tlearn: 821.3316370\ttotal: 2.46s\tremaining: 21.4s\n",
      "103:\tlearn: 816.7909866\ttotal: 2.47s\tremaining: 21.3s\n",
      "104:\tlearn: 812.5615930\ttotal: 2.48s\tremaining: 21.2s\n",
      "105:\tlearn: 808.1257591\ttotal: 2.5s\tremaining: 21s\n",
      "106:\tlearn: 804.8889162\ttotal: 2.53s\tremaining: 21.1s\n",
      "107:\tlearn: 802.0333859\ttotal: 2.55s\tremaining: 21.1s\n",
      "108:\tlearn: 798.1216753\ttotal: 2.57s\tremaining: 21s\n",
      "109:\tlearn: 794.5845450\ttotal: 2.58s\tremaining: 20.9s\n",
      "110:\tlearn: 791.0177926\ttotal: 2.6s\tremaining: 20.8s\n",
      "111:\tlearn: 787.3263089\ttotal: 2.61s\tremaining: 20.7s\n",
      "112:\tlearn: 783.6463314\ttotal: 2.63s\tremaining: 20.6s\n",
      "113:\tlearn: 781.4929452\ttotal: 2.64s\tremaining: 20.5s\n",
      "114:\tlearn: 778.7147467\ttotal: 2.66s\tremaining: 20.5s\n",
      "115:\tlearn: 776.1212585\ttotal: 2.68s\tremaining: 20.4s\n",
      "116:\tlearn: 773.4307053\ttotal: 2.71s\tremaining: 20.5s\n",
      "117:\tlearn: 770.1602327\ttotal: 2.73s\tremaining: 20.4s\n",
      "118:\tlearn: 767.8153795\ttotal: 2.75s\tremaining: 20.4s\n",
      "119:\tlearn: 764.6792516\ttotal: 2.79s\tremaining: 20.5s\n",
      "120:\tlearn: 762.4283714\ttotal: 2.82s\tremaining: 20.5s\n",
      "121:\tlearn: 759.1032065\ttotal: 2.84s\tremaining: 20.5s\n",
      "122:\tlearn: 757.6063986\ttotal: 2.86s\tremaining: 20.4s\n",
      "123:\tlearn: 755.7013695\ttotal: 2.89s\tremaining: 20.4s\n",
      "124:\tlearn: 753.1092269\ttotal: 2.92s\tremaining: 20.5s\n",
      "125:\tlearn: 750.6385366\ttotal: 2.94s\tremaining: 20.4s\n",
      "126:\tlearn: 748.2348218\ttotal: 2.95s\tremaining: 20.3s\n",
      "127:\tlearn: 746.3790334\ttotal: 2.98s\tremaining: 20.3s\n",
      "128:\tlearn: 743.6577630\ttotal: 3s\tremaining: 20.3s\n",
      "129:\tlearn: 740.8255659\ttotal: 3.02s\tremaining: 20.2s\n",
      "130:\tlearn: 738.0113678\ttotal: 3.04s\tremaining: 20.2s\n",
      "131:\tlearn: 734.9867423\ttotal: 3.05s\tremaining: 20.1s\n",
      "132:\tlearn: 733.2222680\ttotal: 3.06s\tremaining: 19.9s\n",
      "133:\tlearn: 731.4340144\ttotal: 3.07s\tremaining: 19.8s\n",
      "134:\tlearn: 730.0461361\ttotal: 3.08s\tremaining: 19.7s\n",
      "135:\tlearn: 728.7842195\ttotal: 3.1s\tremaining: 19.7s\n",
      "136:\tlearn: 725.5085567\ttotal: 3.11s\tremaining: 19.6s\n",
      "137:\tlearn: 722.9655647\ttotal: 3.13s\tremaining: 19.6s\n",
      "138:\tlearn: 721.3522470\ttotal: 3.15s\tremaining: 19.5s\n",
      "139:\tlearn: 719.3618518\ttotal: 3.15s\tremaining: 19.4s\n",
      "140:\tlearn: 717.3485291\ttotal: 3.17s\tremaining: 19.3s\n",
      "141:\tlearn: 715.2914057\ttotal: 3.18s\tremaining: 19.2s\n",
      "142:\tlearn: 713.2098951\ttotal: 3.19s\tremaining: 19.1s\n",
      "143:\tlearn: 711.1481956\ttotal: 3.2s\tremaining: 19s\n",
      "144:\tlearn: 709.4007580\ttotal: 3.21s\tremaining: 18.9s\n",
      "145:\tlearn: 707.6120667\ttotal: 3.24s\tremaining: 18.9s\n",
      "146:\tlearn: 706.5588305\ttotal: 3.28s\tremaining: 19.1s\n",
      "147:\tlearn: 704.6212129\ttotal: 3.32s\tremaining: 19.1s\n",
      "148:\tlearn: 703.3202150\ttotal: 3.39s\tremaining: 19.3s\n",
      "149:\tlearn: 702.0581210\ttotal: 3.41s\tremaining: 19.3s\n",
      "150:\tlearn: 700.5800189\ttotal: 3.42s\tremaining: 19.2s\n",
      "151:\tlearn: 698.9319617\ttotal: 3.43s\tremaining: 19.1s\n",
      "152:\tlearn: 695.9376042\ttotal: 3.44s\tremaining: 19s\n",
      "153:\tlearn: 694.5779250\ttotal: 3.45s\tremaining: 19s\n",
      "154:\tlearn: 692.5005014\ttotal: 3.46s\tremaining: 18.9s\n",
      "155:\tlearn: 691.2115491\ttotal: 3.47s\tremaining: 18.8s\n",
      "156:\tlearn: 689.9998516\ttotal: 3.48s\tremaining: 18.7s\n",
      "157:\tlearn: 687.9949284\ttotal: 3.5s\tremaining: 18.6s\n",
      "158:\tlearn: 686.3627025\ttotal: 3.51s\tremaining: 18.6s\n",
      "159:\tlearn: 685.4189483\ttotal: 3.52s\tremaining: 18.5s\n",
      "160:\tlearn: 682.8777842\ttotal: 3.54s\tremaining: 18.4s\n",
      "161:\tlearn: 682.0868161\ttotal: 3.58s\tremaining: 18.5s\n",
      "162:\tlearn: 681.2521737\ttotal: 3.62s\tremaining: 18.6s\n",
      "163:\tlearn: 679.1703012\ttotal: 3.64s\tremaining: 18.6s\n",
      "164:\tlearn: 677.0954924\ttotal: 3.66s\tremaining: 18.5s\n",
      "165:\tlearn: 676.2575372\ttotal: 3.68s\tremaining: 18.5s\n",
      "166:\tlearn: 674.9072200\ttotal: 3.7s\tremaining: 18.4s\n",
      "167:\tlearn: 673.6187867\ttotal: 3.71s\tremaining: 18.4s\n",
      "168:\tlearn: 671.6586153\ttotal: 3.74s\tremaining: 18.4s\n",
      "169:\tlearn: 670.7400178\ttotal: 3.75s\tremaining: 18.3s\n",
      "170:\tlearn: 669.5581087\ttotal: 3.76s\tremaining: 18.2s\n",
      "171:\tlearn: 668.0003857\ttotal: 3.77s\tremaining: 18.2s\n",
      "172:\tlearn: 666.4796242\ttotal: 3.79s\tremaining: 18.1s\n",
      "173:\tlearn: 664.9041819\ttotal: 3.81s\tremaining: 18.1s\n",
      "174:\tlearn: 663.7654045\ttotal: 3.85s\tremaining: 18.1s\n",
      "175:\tlearn: 661.6331268\ttotal: 3.88s\tremaining: 18.1s\n",
      "176:\tlearn: 660.6529355\ttotal: 3.92s\tremaining: 18.2s\n",
      "177:\tlearn: 659.5681353\ttotal: 3.96s\tremaining: 18.3s\n",
      "178:\tlearn: 657.6548078\ttotal: 3.99s\tremaining: 18.3s\n",
      "179:\tlearn: 656.2584083\ttotal: 4.04s\tremaining: 18.4s\n",
      "180:\tlearn: 655.1762107\ttotal: 4.05s\tremaining: 18.3s\n",
      "181:\tlearn: 653.1362413\ttotal: 4.07s\tremaining: 18.3s\n",
      "182:\tlearn: 651.2984738\ttotal: 4.08s\tremaining: 18.2s\n",
      "183:\tlearn: 650.0005434\ttotal: 4.1s\tremaining: 18.2s\n",
      "184:\tlearn: 648.8757335\ttotal: 4.13s\tremaining: 18.2s\n",
      "185:\tlearn: 648.0589234\ttotal: 4.16s\tremaining: 18.2s\n",
      "186:\tlearn: 646.7987829\ttotal: 4.19s\tremaining: 18.2s\n",
      "187:\tlearn: 645.3803788\ttotal: 4.21s\tremaining: 18.2s\n",
      "188:\tlearn: 644.2169585\ttotal: 4.22s\tremaining: 18.1s\n",
      "189:\tlearn: 643.2217220\ttotal: 4.24s\tremaining: 18.1s\n",
      "190:\tlearn: 641.5535602\ttotal: 4.28s\tremaining: 18.1s\n",
      "191:\tlearn: 640.5061180\ttotal: 4.32s\tremaining: 18.2s\n",
      "192:\tlearn: 639.2780292\ttotal: 4.36s\tremaining: 18.2s\n",
      "193:\tlearn: 638.5206818\ttotal: 4.41s\tremaining: 18.3s\n",
      "194:\tlearn: 637.6644596\ttotal: 4.44s\tremaining: 18.3s\n",
      "195:\tlearn: 636.4296147\ttotal: 4.47s\tremaining: 18.3s\n",
      "196:\tlearn: 635.3267791\ttotal: 4.48s\tremaining: 18.3s\n",
      "197:\tlearn: 634.2043758\ttotal: 4.5s\tremaining: 18.2s\n",
      "198:\tlearn: 633.2280407\ttotal: 4.51s\tremaining: 18.1s\n",
      "199:\tlearn: 632.0322770\ttotal: 4.52s\tremaining: 18.1s\n",
      "200:\tlearn: 631.0591386\ttotal: 4.53s\tremaining: 18s\n",
      "201:\tlearn: 629.4492940\ttotal: 4.54s\tremaining: 18s\n",
      "202:\tlearn: 627.6272720\ttotal: 4.56s\tremaining: 17.9s\n",
      "203:\tlearn: 625.9317097\ttotal: 4.58s\tremaining: 17.9s\n",
      "204:\tlearn: 625.5379056\ttotal: 4.6s\tremaining: 17.8s\n",
      "205:\tlearn: 624.1547662\ttotal: 4.62s\tremaining: 17.8s\n",
      "206:\tlearn: 622.0549104\ttotal: 4.63s\tremaining: 17.7s\n",
      "207:\tlearn: 620.8797509\ttotal: 4.64s\tremaining: 17.7s\n",
      "208:\tlearn: 620.2694367\ttotal: 4.66s\tremaining: 17.6s\n",
      "209:\tlearn: 618.4061488\ttotal: 4.67s\tremaining: 17.6s\n",
      "210:\tlearn: 617.4880620\ttotal: 4.68s\tremaining: 17.5s\n",
      "211:\tlearn: 616.0864855\ttotal: 4.75s\tremaining: 17.6s\n",
      "212:\tlearn: 615.2052053\ttotal: 4.78s\tremaining: 17.7s\n",
      "213:\tlearn: 614.0629878\ttotal: 4.83s\tremaining: 17.7s\n",
      "214:\tlearn: 612.2226086\ttotal: 4.85s\tremaining: 17.7s\n",
      "215:\tlearn: 611.3419248\ttotal: 4.86s\tremaining: 17.6s\n",
      "216:\tlearn: 610.1165404\ttotal: 4.87s\tremaining: 17.6s\n",
      "217:\tlearn: 608.5305799\ttotal: 4.89s\tremaining: 17.5s\n",
      "218:\tlearn: 607.3047272\ttotal: 4.9s\tremaining: 17.5s\n",
      "219:\tlearn: 606.5312967\ttotal: 4.92s\tremaining: 17.4s\n",
      "220:\tlearn: 605.7033110\ttotal: 4.95s\tremaining: 17.4s\n",
      "221:\tlearn: 604.6032217\ttotal: 4.96s\tremaining: 17.4s\n",
      "222:\tlearn: 602.8229262\ttotal: 4.98s\tremaining: 17.3s\n",
      "223:\tlearn: 602.1159762\ttotal: 4.99s\tremaining: 17.3s\n",
      "224:\tlearn: 601.3510305\ttotal: 5.01s\tremaining: 17.3s\n",
      "225:\tlearn: 600.0611502\ttotal: 5.02s\tremaining: 17.2s\n",
      "226:\tlearn: 599.3151449\ttotal: 5.04s\tremaining: 17.2s\n",
      "227:\tlearn: 597.9382081\ttotal: 5.06s\tremaining: 17.1s\n",
      "228:\tlearn: 596.4692173\ttotal: 5.08s\tremaining: 17.1s\n",
      "229:\tlearn: 595.6396441\ttotal: 5.12s\tremaining: 17.1s\n",
      "230:\tlearn: 594.2341530\ttotal: 5.17s\tremaining: 17.2s\n",
      "231:\tlearn: 593.5359037\ttotal: 5.22s\tremaining: 17.3s\n",
      "232:\tlearn: 592.2899354\ttotal: 5.27s\tremaining: 17.4s\n",
      "233:\tlearn: 591.3276461\ttotal: 5.29s\tremaining: 17.3s\n",
      "234:\tlearn: 590.3700453\ttotal: 5.31s\tremaining: 17.3s\n",
      "235:\tlearn: 589.7526430\ttotal: 5.32s\tremaining: 17.2s\n",
      "236:\tlearn: 588.7525805\ttotal: 5.33s\tremaining: 17.2s\n",
      "237:\tlearn: 587.8399430\ttotal: 5.35s\tremaining: 17.1s\n",
      "238:\tlearn: 586.1741244\ttotal: 5.36s\tremaining: 17.1s\n",
      "239:\tlearn: 584.9667546\ttotal: 5.37s\tremaining: 17s\n",
      "240:\tlearn: 583.7944424\ttotal: 5.39s\tremaining: 17s\n",
      "241:\tlearn: 582.6572233\ttotal: 5.4s\tremaining: 16.9s\n",
      "242:\tlearn: 581.5705100\ttotal: 5.42s\tremaining: 16.9s\n",
      "243:\tlearn: 580.1568649\ttotal: 5.44s\tremaining: 16.9s\n",
      "244:\tlearn: 578.6655101\ttotal: 5.46s\tremaining: 16.8s\n",
      "245:\tlearn: 578.0533949\ttotal: 5.48s\tremaining: 16.8s\n",
      "246:\tlearn: 576.9294747\ttotal: 5.51s\tremaining: 16.8s\n",
      "247:\tlearn: 575.9172775\ttotal: 5.55s\tremaining: 16.8s\n",
      "248:\tlearn: 575.0149544\ttotal: 5.59s\tremaining: 16.8s\n",
      "249:\tlearn: 574.3300830\ttotal: 5.61s\tremaining: 16.8s\n",
      "250:\tlearn: 573.7147803\ttotal: 5.63s\tremaining: 16.8s\n",
      "251:\tlearn: 572.7376446\ttotal: 5.66s\tremaining: 16.8s\n",
      "252:\tlearn: 571.6506025\ttotal: 5.68s\tremaining: 16.8s\n",
      "253:\tlearn: 570.7761177\ttotal: 5.71s\tremaining: 16.8s\n",
      "254:\tlearn: 570.0085642\ttotal: 5.72s\tremaining: 16.7s\n",
      "255:\tlearn: 569.1746747\ttotal: 5.74s\tremaining: 16.7s\n",
      "256:\tlearn: 567.9244820\ttotal: 5.76s\tremaining: 16.6s\n",
      "257:\tlearn: 566.5150831\ttotal: 5.77s\tremaining: 16.6s\n",
      "258:\tlearn: 565.5928853\ttotal: 5.78s\tremaining: 16.5s\n",
      "259:\tlearn: 564.6460921\ttotal: 5.8s\tremaining: 16.5s\n",
      "260:\tlearn: 564.0187990\ttotal: 5.81s\tremaining: 16.5s\n",
      "261:\tlearn: 563.2236936\ttotal: 5.85s\tremaining: 16.5s\n",
      "262:\tlearn: 561.2294813\ttotal: 5.9s\tremaining: 16.5s\n",
      "263:\tlearn: 560.6640816\ttotal: 5.94s\tremaining: 16.6s\n",
      "264:\tlearn: 559.5005832\ttotal: 5.96s\tremaining: 16.5s\n",
      "265:\tlearn: 559.0567076\ttotal: 5.97s\tremaining: 16.5s\n",
      "266:\tlearn: 558.1958983\ttotal: 5.99s\tremaining: 16.4s\n",
      "267:\tlearn: 556.8384484\ttotal: 6s\tremaining: 16.4s\n",
      "268:\tlearn: 556.1499118\ttotal: 6.02s\tremaining: 16.4s\n",
      "269:\tlearn: 554.9510546\ttotal: 6.03s\tremaining: 16.3s\n",
      "270:\tlearn: 553.6289928\ttotal: 6.04s\tremaining: 16.3s\n",
      "271:\tlearn: 552.6600252\ttotal: 6.07s\tremaining: 16.2s\n",
      "272:\tlearn: 551.5804206\ttotal: 6.08s\tremaining: 16.2s\n",
      "273:\tlearn: 550.5604133\ttotal: 6.09s\tremaining: 16.2s\n",
      "274:\tlearn: 549.5243381\ttotal: 6.11s\tremaining: 16.1s\n",
      "275:\tlearn: 548.6067351\ttotal: 6.13s\tremaining: 16.1s\n",
      "276:\tlearn: 547.9915285\ttotal: 6.15s\tremaining: 16.1s\n",
      "277:\tlearn: 547.1365018\ttotal: 6.17s\tremaining: 16s\n",
      "278:\tlearn: 546.3255072\ttotal: 6.2s\tremaining: 16s\n",
      "279:\tlearn: 545.6245294\ttotal: 6.22s\tremaining: 16s\n",
      "280:\tlearn: 544.3340036\ttotal: 6.25s\tremaining: 16s\n",
      "281:\tlearn: 543.3792324\ttotal: 6.26s\tremaining: 15.9s\n",
      "282:\tlearn: 542.3296400\ttotal: 6.28s\tremaining: 15.9s\n",
      "283:\tlearn: 541.4213595\ttotal: 6.3s\tremaining: 15.9s\n",
      "284:\tlearn: 540.5398678\ttotal: 6.31s\tremaining: 15.8s\n",
      "285:\tlearn: 539.7625675\ttotal: 6.33s\tremaining: 15.8s\n",
      "286:\tlearn: 538.1170110\ttotal: 6.34s\tremaining: 15.8s\n",
      "287:\tlearn: 536.8876913\ttotal: 6.36s\tremaining: 15.7s\n",
      "288:\tlearn: 536.0103237\ttotal: 6.37s\tremaining: 15.7s\n",
      "289:\tlearn: 534.8277303\ttotal: 6.38s\tremaining: 15.6s\n",
      "290:\tlearn: 534.1201517\ttotal: 6.39s\tremaining: 15.6s\n",
      "291:\tlearn: 533.3422459\ttotal: 6.41s\tremaining: 15.5s\n",
      "292:\tlearn: 532.6859608\ttotal: 6.42s\tremaining: 15.5s\n",
      "293:\tlearn: 531.9397293\ttotal: 6.43s\tremaining: 15.4s\n",
      "294:\tlearn: 531.3042932\ttotal: 6.44s\tremaining: 15.4s\n",
      "295:\tlearn: 529.8229572\ttotal: 6.45s\tremaining: 15.3s\n",
      "296:\tlearn: 528.3757792\ttotal: 6.46s\tremaining: 15.3s\n",
      "297:\tlearn: 527.7771665\ttotal: 6.47s\tremaining: 15.2s\n",
      "298:\tlearn: 526.7339326\ttotal: 6.49s\tremaining: 15.2s\n",
      "299:\tlearn: 525.8723764\ttotal: 6.5s\tremaining: 15.2s\n",
      "300:\tlearn: 524.8400676\ttotal: 6.51s\tremaining: 15.1s\n",
      "301:\tlearn: 524.1331498\ttotal: 6.52s\tremaining: 15.1s\n",
      "302:\tlearn: 522.8939617\ttotal: 6.55s\tremaining: 15.1s\n",
      "303:\tlearn: 522.0529794\ttotal: 6.56s\tremaining: 15s\n",
      "304:\tlearn: 521.1063984\ttotal: 6.58s\tremaining: 15s\n",
      "305:\tlearn: 520.3522815\ttotal: 6.59s\tremaining: 15s\n",
      "306:\tlearn: 519.2448599\ttotal: 6.61s\tremaining: 14.9s\n",
      "307:\tlearn: 518.3135443\ttotal: 6.64s\tremaining: 14.9s\n",
      "308:\tlearn: 517.7243569\ttotal: 6.66s\tremaining: 14.9s\n",
      "309:\tlearn: 517.2635973\ttotal: 6.68s\tremaining: 14.9s\n",
      "310:\tlearn: 516.7247990\ttotal: 6.7s\tremaining: 14.8s\n",
      "311:\tlearn: 516.1959833\ttotal: 6.71s\tremaining: 14.8s\n",
      "312:\tlearn: 515.3114142\ttotal: 6.72s\tremaining: 14.8s\n",
      "313:\tlearn: 514.6156562\ttotal: 6.74s\tremaining: 14.7s\n",
      "314:\tlearn: 513.9117187\ttotal: 6.75s\tremaining: 14.7s\n",
      "315:\tlearn: 513.0450171\ttotal: 6.77s\tremaining: 14.6s\n",
      "316:\tlearn: 512.0467949\ttotal: 6.78s\tremaining: 14.6s\n",
      "317:\tlearn: 511.3353734\ttotal: 6.79s\tremaining: 14.6s\n",
      "318:\tlearn: 510.5426242\ttotal: 6.8s\tremaining: 14.5s\n",
      "319:\tlearn: 509.7350428\ttotal: 6.82s\tremaining: 14.5s\n",
      "320:\tlearn: 509.1571009\ttotal: 6.83s\tremaining: 14.5s\n",
      "321:\tlearn: 507.9179258\ttotal: 6.84s\tremaining: 14.4s\n",
      "322:\tlearn: 507.1038100\ttotal: 6.86s\tremaining: 14.4s\n",
      "323:\tlearn: 506.2343655\ttotal: 6.87s\tremaining: 14.3s\n",
      "324:\tlearn: 505.4328652\ttotal: 6.89s\tremaining: 14.3s\n",
      "325:\tlearn: 504.8952803\ttotal: 6.9s\tremaining: 14.3s\n",
      "326:\tlearn: 503.6493853\ttotal: 6.92s\tremaining: 14.2s\n",
      "327:\tlearn: 502.7574592\ttotal: 6.93s\tremaining: 14.2s\n",
      "328:\tlearn: 501.9256256\ttotal: 6.95s\tremaining: 14.2s\n",
      "329:\tlearn: 501.4865767\ttotal: 6.96s\tremaining: 14.1s\n",
      "330:\tlearn: 500.9332238\ttotal: 6.98s\tremaining: 14.1s\n",
      "331:\tlearn: 500.1954616\ttotal: 6.99s\tremaining: 14.1s\n",
      "332:\tlearn: 499.8860706\ttotal: 7.01s\tremaining: 14s\n",
      "333:\tlearn: 499.4228219\ttotal: 7.02s\tremaining: 14s\n",
      "334:\tlearn: 498.7777828\ttotal: 7.03s\tremaining: 14s\n",
      "335:\tlearn: 498.5150562\ttotal: 7.05s\tremaining: 13.9s\n",
      "336:\tlearn: 497.5901251\ttotal: 7.06s\tremaining: 13.9s\n",
      "337:\tlearn: 496.5645762\ttotal: 7.08s\tremaining: 13.9s\n",
      "338:\tlearn: 496.2763895\ttotal: 7.09s\tremaining: 13.8s\n",
      "339:\tlearn: 495.3675351\ttotal: 7.1s\tremaining: 13.8s\n",
      "340:\tlearn: 494.7798911\ttotal: 7.11s\tremaining: 13.7s\n",
      "341:\tlearn: 494.1827788\ttotal: 7.12s\tremaining: 13.7s\n",
      "342:\tlearn: 493.2715859\ttotal: 7.13s\tremaining: 13.7s\n",
      "343:\tlearn: 492.8572345\ttotal: 7.14s\tremaining: 13.6s\n",
      "344:\tlearn: 492.2103838\ttotal: 7.16s\tremaining: 13.6s\n",
      "345:\tlearn: 491.6905642\ttotal: 7.17s\tremaining: 13.6s\n",
      "346:\tlearn: 490.9818696\ttotal: 7.19s\tremaining: 13.5s\n",
      "347:\tlearn: 489.6665541\ttotal: 7.21s\tremaining: 13.5s\n",
      "348:\tlearn: 489.0309473\ttotal: 7.22s\tremaining: 13.5s\n",
      "349:\tlearn: 488.1803204\ttotal: 7.24s\tremaining: 13.4s\n",
      "350:\tlearn: 487.4214337\ttotal: 7.26s\tremaining: 13.4s\n",
      "351:\tlearn: 486.8827811\ttotal: 7.28s\tremaining: 13.4s\n",
      "352:\tlearn: 485.8540732\ttotal: 7.31s\tremaining: 13.4s\n",
      "353:\tlearn: 485.3318673\ttotal: 7.32s\tremaining: 13.4s\n",
      "354:\tlearn: 484.7242714\ttotal: 7.33s\tremaining: 13.3s\n",
      "355:\tlearn: 483.9906094\ttotal: 7.35s\tremaining: 13.3s\n",
      "356:\tlearn: 483.5069544\ttotal: 7.36s\tremaining: 13.3s\n",
      "357:\tlearn: 482.7285930\ttotal: 7.37s\tremaining: 13.2s\n",
      "358:\tlearn: 482.0398266\ttotal: 7.39s\tremaining: 13.2s\n",
      "359:\tlearn: 481.0095851\ttotal: 7.4s\tremaining: 13.2s\n",
      "360:\tlearn: 480.4596923\ttotal: 7.41s\tremaining: 13.1s\n",
      "361:\tlearn: 479.9102480\ttotal: 7.44s\tremaining: 13.1s\n",
      "362:\tlearn: 479.3866161\ttotal: 7.47s\tremaining: 13.1s\n",
      "363:\tlearn: 478.5442854\ttotal: 7.49s\tremaining: 13.1s\n",
      "364:\tlearn: 477.7582912\ttotal: 7.51s\tremaining: 13.1s\n",
      "365:\tlearn: 477.3922542\ttotal: 7.53s\tremaining: 13s\n",
      "366:\tlearn: 476.6634716\ttotal: 7.54s\tremaining: 13s\n",
      "367:\tlearn: 475.9563392\ttotal: 7.56s\tremaining: 13s\n",
      "368:\tlearn: 475.5732947\ttotal: 7.58s\tremaining: 13s\n",
      "369:\tlearn: 475.0787087\ttotal: 7.59s\tremaining: 12.9s\n",
      "370:\tlearn: 474.7878805\ttotal: 7.6s\tremaining: 12.9s\n",
      "371:\tlearn: 474.0128990\ttotal: 7.61s\tremaining: 12.8s\n",
      "372:\tlearn: 473.3332205\ttotal: 7.62s\tremaining: 12.8s\n",
      "373:\tlearn: 472.6498322\ttotal: 7.63s\tremaining: 12.8s\n",
      "374:\tlearn: 472.0755207\ttotal: 7.64s\tremaining: 12.7s\n",
      "375:\tlearn: 471.5504793\ttotal: 7.66s\tremaining: 12.7s\n",
      "376:\tlearn: 471.0815505\ttotal: 7.67s\tremaining: 12.7s\n",
      "377:\tlearn: 470.5182139\ttotal: 7.68s\tremaining: 12.6s\n",
      "378:\tlearn: 469.6813258\ttotal: 7.7s\tremaining: 12.6s\n",
      "379:\tlearn: 469.3176920\ttotal: 7.72s\tremaining: 12.6s\n",
      "380:\tlearn: 468.8774802\ttotal: 7.73s\tremaining: 12.6s\n",
      "381:\tlearn: 467.9841825\ttotal: 7.75s\tremaining: 12.5s\n",
      "382:\tlearn: 467.0682108\ttotal: 7.76s\tremaining: 12.5s\n",
      "383:\tlearn: 466.2663850\ttotal: 7.77s\tremaining: 12.5s\n",
      "384:\tlearn: 465.4496118\ttotal: 7.79s\tremaining: 12.4s\n",
      "385:\tlearn: 464.9758832\ttotal: 7.8s\tremaining: 12.4s\n",
      "386:\tlearn: 464.2786342\ttotal: 7.82s\tremaining: 12.4s\n",
      "387:\tlearn: 463.8581332\ttotal: 7.83s\tremaining: 12.3s\n",
      "388:\tlearn: 463.4663106\ttotal: 7.84s\tremaining: 12.3s\n",
      "389:\tlearn: 462.8287259\ttotal: 7.86s\tremaining: 12.3s\n",
      "390:\tlearn: 462.3529801\ttotal: 7.87s\tremaining: 12.3s\n",
      "391:\tlearn: 461.9581648\ttotal: 7.89s\tremaining: 12.2s\n",
      "392:\tlearn: 461.3295874\ttotal: 7.9s\tremaining: 12.2s\n",
      "393:\tlearn: 460.5167775\ttotal: 7.92s\tremaining: 12.2s\n",
      "394:\tlearn: 459.9440053\ttotal: 7.94s\tremaining: 12.2s\n",
      "395:\tlearn: 459.3965197\ttotal: 7.96s\tremaining: 12.1s\n",
      "396:\tlearn: 458.7517880\ttotal: 7.97s\tremaining: 12.1s\n",
      "397:\tlearn: 458.1330147\ttotal: 8.03s\tremaining: 12.1s\n",
      "398:\tlearn: 457.6119089\ttotal: 8.06s\tremaining: 12.1s\n",
      "399:\tlearn: 457.0769672\ttotal: 8.1s\tremaining: 12.1s\n",
      "400:\tlearn: 456.1886714\ttotal: 8.13s\tremaining: 12.2s\n",
      "401:\tlearn: 455.7296845\ttotal: 8.15s\tremaining: 12.1s\n",
      "402:\tlearn: 455.2747581\ttotal: 8.16s\tremaining: 12.1s\n",
      "403:\tlearn: 454.6584314\ttotal: 8.18s\tremaining: 12.1s\n",
      "404:\tlearn: 454.1246429\ttotal: 8.19s\tremaining: 12s\n",
      "405:\tlearn: 453.6859529\ttotal: 8.2s\tremaining: 12s\n",
      "406:\tlearn: 453.3032584\ttotal: 8.21s\tremaining: 12s\n",
      "407:\tlearn: 452.7766798\ttotal: 8.22s\tremaining: 11.9s\n",
      "408:\tlearn: 452.2360268\ttotal: 8.23s\tremaining: 11.9s\n",
      "409:\tlearn: 451.8280366\ttotal: 8.24s\tremaining: 11.9s\n",
      "410:\tlearn: 451.4201103\ttotal: 8.25s\tremaining: 11.8s\n",
      "411:\tlearn: 450.6422490\ttotal: 8.27s\tremaining: 11.8s\n",
      "412:\tlearn: 450.1312274\ttotal: 8.28s\tremaining: 11.8s\n",
      "413:\tlearn: 449.8076409\ttotal: 8.29s\tremaining: 11.7s\n",
      "414:\tlearn: 449.3168588\ttotal: 8.3s\tremaining: 11.7s\n",
      "415:\tlearn: 448.8357575\ttotal: 8.31s\tremaining: 11.7s\n",
      "416:\tlearn: 448.5775092\ttotal: 8.32s\tremaining: 11.6s\n",
      "417:\tlearn: 448.0279516\ttotal: 8.33s\tremaining: 11.6s\n",
      "418:\tlearn: 447.4158559\ttotal: 8.35s\tremaining: 11.6s\n",
      "419:\tlearn: 446.7626546\ttotal: 8.36s\tremaining: 11.5s\n",
      "420:\tlearn: 446.4044410\ttotal: 8.39s\tremaining: 11.5s\n",
      "421:\tlearn: 445.8507819\ttotal: 8.43s\tremaining: 11.5s\n",
      "422:\tlearn: 445.1886425\ttotal: 8.46s\tremaining: 11.5s\n",
      "423:\tlearn: 444.7405228\ttotal: 8.48s\tremaining: 11.5s\n",
      "424:\tlearn: 444.1680854\ttotal: 8.5s\tremaining: 11.5s\n",
      "425:\tlearn: 443.5197444\ttotal: 8.55s\tremaining: 11.5s\n",
      "426:\tlearn: 442.8988471\ttotal: 8.57s\tremaining: 11.5s\n",
      "427:\tlearn: 442.1220186\ttotal: 8.59s\tremaining: 11.5s\n",
      "428:\tlearn: 441.4827285\ttotal: 8.6s\tremaining: 11.4s\n",
      "429:\tlearn: 441.0094752\ttotal: 8.61s\tremaining: 11.4s\n",
      "430:\tlearn: 440.2684068\ttotal: 8.62s\tremaining: 11.4s\n",
      "431:\tlearn: 439.5665275\ttotal: 8.63s\tremaining: 11.3s\n",
      "432:\tlearn: 439.1370809\ttotal: 8.64s\tremaining: 11.3s\n",
      "433:\tlearn: 438.3100666\ttotal: 8.66s\tremaining: 11.3s\n",
      "434:\tlearn: 437.7359179\ttotal: 8.68s\tremaining: 11.3s\n",
      "435:\tlearn: 437.1597706\ttotal: 8.69s\tremaining: 11.2s\n",
      "436:\tlearn: 436.3136075\ttotal: 8.7s\tremaining: 11.2s\n",
      "437:\tlearn: 435.6264988\ttotal: 8.72s\tremaining: 11.2s\n",
      "438:\tlearn: 434.8538479\ttotal: 8.74s\tremaining: 11.2s\n",
      "439:\tlearn: 434.4140746\ttotal: 8.76s\tremaining: 11.2s\n",
      "440:\tlearn: 433.5416507\ttotal: 8.78s\tremaining: 11.1s\n",
      "441:\tlearn: 432.6328763\ttotal: 8.8s\tremaining: 11.1s\n",
      "442:\tlearn: 432.0622447\ttotal: 8.81s\tremaining: 11.1s\n",
      "443:\tlearn: 431.4926158\ttotal: 8.82s\tremaining: 11s\n",
      "444:\tlearn: 431.3052267\ttotal: 8.83s\tremaining: 11s\n",
      "445:\tlearn: 430.6287065\ttotal: 8.85s\tremaining: 11s\n",
      "446:\tlearn: 429.9952322\ttotal: 8.86s\tremaining: 11s\n",
      "447:\tlearn: 429.4788301\ttotal: 8.87s\tremaining: 10.9s\n",
      "448:\tlearn: 428.9552049\ttotal: 8.89s\tremaining: 10.9s\n",
      "449:\tlearn: 428.2165269\ttotal: 8.9s\tremaining: 10.9s\n",
      "450:\tlearn: 427.8756692\ttotal: 8.91s\tremaining: 10.8s\n",
      "451:\tlearn: 427.1353241\ttotal: 8.92s\tremaining: 10.8s\n",
      "452:\tlearn: 426.4587052\ttotal: 8.94s\tremaining: 10.8s\n",
      "453:\tlearn: 425.7123340\ttotal: 8.95s\tremaining: 10.8s\n",
      "454:\tlearn: 424.8983995\ttotal: 8.96s\tremaining: 10.7s\n",
      "455:\tlearn: 424.2648819\ttotal: 8.98s\tremaining: 10.7s\n",
      "456:\tlearn: 423.7354254\ttotal: 8.99s\tremaining: 10.7s\n",
      "457:\tlearn: 423.1961804\ttotal: 9.02s\tremaining: 10.7s\n",
      "458:\tlearn: 422.3423804\ttotal: 9.08s\tremaining: 10.7s\n",
      "459:\tlearn: 421.9064355\ttotal: 9.12s\tremaining: 10.7s\n",
      "460:\tlearn: 421.4681069\ttotal: 9.16s\tremaining: 10.7s\n",
      "461:\tlearn: 420.9097117\ttotal: 9.19s\tremaining: 10.7s\n",
      "462:\tlearn: 420.2957887\ttotal: 9.21s\tremaining: 10.7s\n",
      "463:\tlearn: 419.5687465\ttotal: 9.22s\tremaining: 10.7s\n",
      "464:\tlearn: 419.0906238\ttotal: 9.24s\tremaining: 10.6s\n",
      "465:\tlearn: 418.5977443\ttotal: 9.25s\tremaining: 10.6s\n",
      "466:\tlearn: 417.9527666\ttotal: 9.28s\tremaining: 10.6s\n",
      "467:\tlearn: 416.9228269\ttotal: 9.29s\tremaining: 10.6s\n",
      "468:\tlearn: 416.4951141\ttotal: 9.31s\tremaining: 10.5s\n",
      "469:\tlearn: 415.9502150\ttotal: 9.33s\tremaining: 10.5s\n",
      "470:\tlearn: 415.5425631\ttotal: 9.35s\tremaining: 10.5s\n",
      "471:\tlearn: 415.0469084\ttotal: 9.37s\tremaining: 10.5s\n",
      "472:\tlearn: 414.5993538\ttotal: 9.39s\tremaining: 10.5s\n",
      "473:\tlearn: 414.2631685\ttotal: 9.41s\tremaining: 10.4s\n",
      "474:\tlearn: 413.8818595\ttotal: 9.42s\tremaining: 10.4s\n",
      "475:\tlearn: 413.5355324\ttotal: 9.43s\tremaining: 10.4s\n",
      "476:\tlearn: 412.7238405\ttotal: 9.45s\tremaining: 10.4s\n",
      "477:\tlearn: 412.2224438\ttotal: 9.46s\tremaining: 10.3s\n",
      "478:\tlearn: 411.6164205\ttotal: 9.48s\tremaining: 10.3s\n",
      "479:\tlearn: 411.0124174\ttotal: 9.49s\tremaining: 10.3s\n",
      "480:\tlearn: 410.4598758\ttotal: 9.52s\tremaining: 10.3s\n",
      "481:\tlearn: 410.1114859\ttotal: 9.53s\tremaining: 10.2s\n",
      "482:\tlearn: 409.5215411\ttotal: 9.56s\tremaining: 10.2s\n",
      "483:\tlearn: 409.3010734\ttotal: 9.58s\tremaining: 10.2s\n",
      "484:\tlearn: 408.7783829\ttotal: 9.6s\tremaining: 10.2s\n",
      "485:\tlearn: 408.2456764\ttotal: 9.62s\tremaining: 10.2s\n",
      "486:\tlearn: 407.8985872\ttotal: 9.65s\tremaining: 10.2s\n",
      "487:\tlearn: 407.3764648\ttotal: 9.67s\tremaining: 10.1s\n",
      "488:\tlearn: 406.9323468\ttotal: 9.68s\tremaining: 10.1s\n",
      "489:\tlearn: 406.4104449\ttotal: 9.69s\tremaining: 10.1s\n",
      "490:\tlearn: 406.0195955\ttotal: 9.71s\tremaining: 10.1s\n",
      "491:\tlearn: 405.6843472\ttotal: 9.72s\tremaining: 10s\n",
      "492:\tlearn: 405.2045283\ttotal: 9.74s\tremaining: 10s\n",
      "493:\tlearn: 404.8335700\ttotal: 9.78s\tremaining: 10s\n",
      "494:\tlearn: 404.1438615\ttotal: 9.8s\tremaining: 9.99s\n",
      "495:\tlearn: 403.7845251\ttotal: 9.82s\tremaining: 9.98s\n",
      "496:\tlearn: 403.2173371\ttotal: 9.84s\tremaining: 9.96s\n",
      "497:\tlearn: 402.7501755\ttotal: 9.86s\tremaining: 9.94s\n",
      "498:\tlearn: 402.3764991\ttotal: 9.88s\tremaining: 9.91s\n",
      "499:\tlearn: 401.9971980\ttotal: 9.89s\tremaining: 9.89s\n",
      "500:\tlearn: 401.8315076\ttotal: 9.9s\tremaining: 9.86s\n",
      "501:\tlearn: 401.6281771\ttotal: 9.91s\tremaining: 9.84s\n",
      "502:\tlearn: 401.2674730\ttotal: 9.93s\tremaining: 9.81s\n",
      "503:\tlearn: 400.6348018\ttotal: 9.94s\tremaining: 9.79s\n",
      "504:\tlearn: 400.1490706\ttotal: 9.96s\tremaining: 9.76s\n",
      "505:\tlearn: 399.3415993\ttotal: 9.97s\tremaining: 9.74s\n",
      "506:\tlearn: 399.1464086\ttotal: 10s\tremaining: 9.73s\n",
      "507:\tlearn: 398.8639250\ttotal: 10s\tremaining: 9.72s\n",
      "508:\tlearn: 398.1770501\ttotal: 10.1s\tremaining: 9.7s\n",
      "509:\tlearn: 397.5228429\ttotal: 10.1s\tremaining: 9.68s\n",
      "510:\tlearn: 397.2664162\ttotal: 10.1s\tremaining: 9.66s\n",
      "511:\tlearn: 396.8530868\ttotal: 10.1s\tremaining: 9.64s\n",
      "512:\tlearn: 396.5270104\ttotal: 10.1s\tremaining: 9.63s\n",
      "513:\tlearn: 396.1875494\ttotal: 10.2s\tremaining: 9.62s\n",
      "514:\tlearn: 395.6551761\ttotal: 10.2s\tremaining: 9.61s\n",
      "515:\tlearn: 395.1671850\ttotal: 10.2s\tremaining: 9.59s\n",
      "516:\tlearn: 394.8016762\ttotal: 10.2s\tremaining: 9.56s\n",
      "517:\tlearn: 394.3298302\ttotal: 10.2s\tremaining: 9.53s\n",
      "518:\tlearn: 393.7978420\ttotal: 10.3s\tremaining: 9.5s\n",
      "519:\tlearn: 393.1497479\ttotal: 10.3s\tremaining: 9.47s\n",
      "520:\tlearn: 392.7909153\ttotal: 10.3s\tremaining: 9.45s\n",
      "521:\tlearn: 392.2742884\ttotal: 10.3s\tremaining: 9.42s\n",
      "522:\tlearn: 391.8707582\ttotal: 10.3s\tremaining: 9.39s\n",
      "523:\tlearn: 391.5440258\ttotal: 10.3s\tremaining: 9.36s\n",
      "524:\tlearn: 391.3235385\ttotal: 10.3s\tremaining: 9.34s\n",
      "525:\tlearn: 391.0036517\ttotal: 10.3s\tremaining: 9.32s\n",
      "526:\tlearn: 390.5925184\ttotal: 10.4s\tremaining: 9.29s\n",
      "527:\tlearn: 390.2801218\ttotal: 10.4s\tremaining: 9.27s\n",
      "528:\tlearn: 389.8487803\ttotal: 10.4s\tremaining: 9.25s\n",
      "529:\tlearn: 389.7055723\ttotal: 10.4s\tremaining: 9.24s\n",
      "530:\tlearn: 389.3769124\ttotal: 10.5s\tremaining: 9.25s\n",
      "531:\tlearn: 389.1431946\ttotal: 10.5s\tremaining: 9.24s\n",
      "532:\tlearn: 389.0251974\ttotal: 10.5s\tremaining: 9.23s\n",
      "533:\tlearn: 388.4946482\ttotal: 10.5s\tremaining: 9.21s\n",
      "534:\tlearn: 387.9310710\ttotal: 10.6s\tremaining: 9.18s\n",
      "535:\tlearn: 387.6327618\ttotal: 10.6s\tremaining: 9.15s\n",
      "536:\tlearn: 387.2156797\ttotal: 10.6s\tremaining: 9.13s\n",
      "537:\tlearn: 386.5605906\ttotal: 10.6s\tremaining: 9.1s\n",
      "538:\tlearn: 385.8112476\ttotal: 10.6s\tremaining: 9.08s\n",
      "539:\tlearn: 385.3686653\ttotal: 10.6s\tremaining: 9.05s\n",
      "540:\tlearn: 385.1079208\ttotal: 10.6s\tremaining: 9.02s\n",
      "541:\tlearn: 384.5453198\ttotal: 10.6s\tremaining: 9s\n",
      "542:\tlearn: 384.1560069\ttotal: 10.7s\tremaining: 8.97s\n",
      "543:\tlearn: 383.5460103\ttotal: 10.7s\tremaining: 8.94s\n",
      "544:\tlearn: 383.1257545\ttotal: 10.7s\tremaining: 8.91s\n",
      "545:\tlearn: 382.7525689\ttotal: 10.7s\tremaining: 8.88s\n",
      "546:\tlearn: 382.0478887\ttotal: 10.7s\tremaining: 8.86s\n",
      "547:\tlearn: 381.4501536\ttotal: 10.7s\tremaining: 8.83s\n",
      "548:\tlearn: 381.0508668\ttotal: 10.7s\tremaining: 8.81s\n",
      "549:\tlearn: 380.7530291\ttotal: 10.7s\tremaining: 8.78s\n",
      "550:\tlearn: 380.4219616\ttotal: 10.7s\tremaining: 8.76s\n",
      "551:\tlearn: 379.9044205\ttotal: 10.8s\tremaining: 8.73s\n",
      "552:\tlearn: 379.3784500\ttotal: 10.8s\tremaining: 8.71s\n",
      "553:\tlearn: 379.0983132\ttotal: 10.8s\tremaining: 8.68s\n",
      "554:\tlearn: 378.7849690\ttotal: 10.8s\tremaining: 8.66s\n",
      "555:\tlearn: 378.2535448\ttotal: 10.8s\tremaining: 8.64s\n",
      "556:\tlearn: 377.9771969\ttotal: 10.8s\tremaining: 8.62s\n",
      "557:\tlearn: 377.8877203\ttotal: 10.8s\tremaining: 8.59s\n",
      "558:\tlearn: 377.2849987\ttotal: 10.9s\tremaining: 8.57s\n",
      "559:\tlearn: 376.8006398\ttotal: 10.9s\tremaining: 8.54s\n",
      "560:\tlearn: 376.6790035\ttotal: 10.9s\tremaining: 8.52s\n",
      "561:\tlearn: 376.1347119\ttotal: 10.9s\tremaining: 8.5s\n",
      "562:\tlearn: 375.9007160\ttotal: 10.9s\tremaining: 8.48s\n",
      "563:\tlearn: 375.2453500\ttotal: 10.9s\tremaining: 8.46s\n",
      "564:\tlearn: 374.8691941\ttotal: 11s\tremaining: 8.44s\n",
      "565:\tlearn: 374.5002036\ttotal: 11s\tremaining: 8.42s\n",
      "566:\tlearn: 374.0802361\ttotal: 11s\tremaining: 8.39s\n",
      "567:\tlearn: 373.5847936\ttotal: 11s\tremaining: 8.38s\n",
      "568:\tlearn: 373.0595736\ttotal: 11s\tremaining: 8.36s\n",
      "569:\tlearn: 372.6665327\ttotal: 11.1s\tremaining: 8.34s\n",
      "570:\tlearn: 372.1469236\ttotal: 11.1s\tremaining: 8.31s\n",
      "571:\tlearn: 372.0403978\ttotal: 11.1s\tremaining: 8.29s\n",
      "572:\tlearn: 371.6568164\ttotal: 11.1s\tremaining: 8.27s\n",
      "573:\tlearn: 371.4043502\ttotal: 11.1s\tremaining: 8.24s\n",
      "574:\tlearn: 371.0925115\ttotal: 11.1s\tremaining: 8.23s\n",
      "575:\tlearn: 370.7790608\ttotal: 11.1s\tremaining: 8.21s\n",
      "576:\tlearn: 370.3613710\ttotal: 11.2s\tremaining: 8.19s\n",
      "577:\tlearn: 369.8165375\ttotal: 11.2s\tremaining: 8.18s\n",
      "578:\tlearn: 369.5197147\ttotal: 11.2s\tremaining: 8.15s\n",
      "579:\tlearn: 369.0624652\ttotal: 11.2s\tremaining: 8.13s\n",
      "580:\tlearn: 368.5624888\ttotal: 11.2s\tremaining: 8.11s\n",
      "581:\tlearn: 367.8808968\ttotal: 11.3s\tremaining: 8.09s\n",
      "582:\tlearn: 367.5897817\ttotal: 11.3s\tremaining: 8.06s\n",
      "583:\tlearn: 366.9255310\ttotal: 11.3s\tremaining: 8.04s\n",
      "584:\tlearn: 366.1261230\ttotal: 11.3s\tremaining: 8.01s\n",
      "585:\tlearn: 365.7768336\ttotal: 11.3s\tremaining: 7.99s\n",
      "586:\tlearn: 365.4368529\ttotal: 11.3s\tremaining: 7.96s\n",
      "587:\tlearn: 364.9376487\ttotal: 11.3s\tremaining: 7.94s\n",
      "588:\tlearn: 364.6697799\ttotal: 11.3s\tremaining: 7.91s\n",
      "589:\tlearn: 364.1339314\ttotal: 11.3s\tremaining: 7.88s\n",
      "590:\tlearn: 363.7734580\ttotal: 11.4s\tremaining: 7.86s\n",
      "591:\tlearn: 363.2744375\ttotal: 11.4s\tremaining: 7.83s\n",
      "592:\tlearn: 362.9485619\ttotal: 11.4s\tremaining: 7.81s\n",
      "593:\tlearn: 362.5999498\ttotal: 11.4s\tremaining: 7.78s\n",
      "594:\tlearn: 362.4488602\ttotal: 11.4s\tremaining: 7.76s\n",
      "595:\tlearn: 362.1255639\ttotal: 11.4s\tremaining: 7.73s\n",
      "596:\tlearn: 361.4261264\ttotal: 11.4s\tremaining: 7.71s\n",
      "597:\tlearn: 361.0040649\ttotal: 11.4s\tremaining: 7.69s\n",
      "598:\tlearn: 360.5038713\ttotal: 11.5s\tremaining: 7.67s\n",
      "599:\tlearn: 360.1741138\ttotal: 11.5s\tremaining: 7.65s\n",
      "600:\tlearn: 359.5829530\ttotal: 11.5s\tremaining: 7.64s\n",
      "601:\tlearn: 359.2296615\ttotal: 11.5s\tremaining: 7.63s\n",
      "602:\tlearn: 358.7914676\ttotal: 11.6s\tremaining: 7.61s\n",
      "603:\tlearn: 358.2215827\ttotal: 11.6s\tremaining: 7.6s\n",
      "604:\tlearn: 357.8055811\ttotal: 11.6s\tremaining: 7.58s\n",
      "605:\tlearn: 357.4181999\ttotal: 11.6s\tremaining: 7.56s\n",
      "606:\tlearn: 356.9661446\ttotal: 11.6s\tremaining: 7.54s\n",
      "607:\tlearn: 356.4877329\ttotal: 11.7s\tremaining: 7.52s\n",
      "608:\tlearn: 355.8809845\ttotal: 11.7s\tremaining: 7.5s\n",
      "609:\tlearn: 355.4168593\ttotal: 11.7s\tremaining: 7.48s\n",
      "610:\tlearn: 354.9245455\ttotal: 11.7s\tremaining: 7.45s\n",
      "611:\tlearn: 354.6787743\ttotal: 11.7s\tremaining: 7.43s\n",
      "612:\tlearn: 354.3676894\ttotal: 11.7s\tremaining: 7.41s\n",
      "613:\tlearn: 354.0818071\ttotal: 11.7s\tremaining: 7.38s\n",
      "614:\tlearn: 353.7463674\ttotal: 11.8s\tremaining: 7.36s\n",
      "615:\tlearn: 353.3404981\ttotal: 11.8s\tremaining: 7.34s\n",
      "616:\tlearn: 352.9305099\ttotal: 11.8s\tremaining: 7.31s\n",
      "617:\tlearn: 352.6406414\ttotal: 11.8s\tremaining: 7.29s\n",
      "618:\tlearn: 352.2584650\ttotal: 11.8s\tremaining: 7.27s\n",
      "619:\tlearn: 351.8321988\ttotal: 11.8s\tremaining: 7.24s\n",
      "620:\tlearn: 351.3485644\ttotal: 11.8s\tremaining: 7.23s\n",
      "621:\tlearn: 351.0000356\ttotal: 11.9s\tremaining: 7.21s\n",
      "622:\tlearn: 350.4599914\ttotal: 11.9s\tremaining: 7.19s\n",
      "623:\tlearn: 350.3524467\ttotal: 11.9s\tremaining: 7.16s\n",
      "624:\tlearn: 350.2134238\ttotal: 11.9s\tremaining: 7.14s\n",
      "625:\tlearn: 349.8354450\ttotal: 11.9s\tremaining: 7.12s\n",
      "626:\tlearn: 349.5424674\ttotal: 11.9s\tremaining: 7.1s\n",
      "627:\tlearn: 349.1104783\ttotal: 11.9s\tremaining: 7.08s\n",
      "628:\tlearn: 348.6784142\ttotal: 12s\tremaining: 7.06s\n",
      "629:\tlearn: 348.2531074\ttotal: 12s\tremaining: 7.04s\n",
      "630:\tlearn: 347.6717559\ttotal: 12s\tremaining: 7.01s\n",
      "631:\tlearn: 347.4059185\ttotal: 12s\tremaining: 6.99s\n",
      "632:\tlearn: 347.3078327\ttotal: 12s\tremaining: 6.97s\n",
      "633:\tlearn: 347.0700021\ttotal: 12s\tremaining: 6.96s\n",
      "634:\tlearn: 346.7932428\ttotal: 12.1s\tremaining: 6.95s\n",
      "635:\tlearn: 346.4926838\ttotal: 12.1s\tremaining: 6.93s\n",
      "636:\tlearn: 346.1402190\ttotal: 12.1s\tremaining: 6.91s\n",
      "637:\tlearn: 345.7753166\ttotal: 12.1s\tremaining: 6.89s\n",
      "638:\tlearn: 345.4249638\ttotal: 12.2s\tremaining: 6.86s\n",
      "639:\tlearn: 345.2281954\ttotal: 12.2s\tremaining: 6.84s\n",
      "640:\tlearn: 344.8788654\ttotal: 12.2s\tremaining: 6.82s\n",
      "641:\tlearn: 344.6434800\ttotal: 12.2s\tremaining: 6.8s\n",
      "642:\tlearn: 344.5095452\ttotal: 12.2s\tremaining: 6.77s\n",
      "643:\tlearn: 344.0534173\ttotal: 12.2s\tremaining: 6.75s\n",
      "644:\tlearn: 343.5281283\ttotal: 12.2s\tremaining: 6.73s\n",
      "645:\tlearn: 343.2888258\ttotal: 12.2s\tremaining: 6.71s\n",
      "646:\tlearn: 343.0393119\ttotal: 12.3s\tremaining: 6.74s\n",
      "647:\tlearn: 342.7323133\ttotal: 12.4s\tremaining: 6.72s\n",
      "648:\tlearn: 342.2519569\ttotal: 12.4s\tremaining: 6.71s\n",
      "649:\tlearn: 341.9022995\ttotal: 12.5s\tremaining: 6.74s\n",
      "650:\tlearn: 341.4834484\ttotal: 12.6s\tremaining: 6.74s\n",
      "651:\tlearn: 341.0731668\ttotal: 12.6s\tremaining: 6.73s\n",
      "652:\tlearn: 340.6632627\ttotal: 12.7s\tremaining: 6.74s\n",
      "653:\tlearn: 340.3803111\ttotal: 12.7s\tremaining: 6.73s\n",
      "654:\tlearn: 340.1408627\ttotal: 12.8s\tremaining: 6.74s\n",
      "655:\tlearn: 339.9754702\ttotal: 12.8s\tremaining: 6.73s\n",
      "656:\tlearn: 339.4788430\ttotal: 12.9s\tremaining: 6.71s\n",
      "657:\tlearn: 339.0799520\ttotal: 12.9s\tremaining: 6.69s\n",
      "658:\tlearn: 338.7945931\ttotal: 12.9s\tremaining: 6.68s\n",
      "659:\tlearn: 338.6188868\ttotal: 13s\tremaining: 6.68s\n",
      "660:\tlearn: 338.4499869\ttotal: 13s\tremaining: 6.68s\n",
      "661:\tlearn: 338.2150480\ttotal: 13s\tremaining: 6.66s\n",
      "662:\tlearn: 337.7945681\ttotal: 13.1s\tremaining: 6.64s\n",
      "663:\tlearn: 337.3959467\ttotal: 13.1s\tremaining: 6.61s\n",
      "664:\tlearn: 337.2170787\ttotal: 13.1s\tremaining: 6.59s\n",
      "665:\tlearn: 336.6811870\ttotal: 13.1s\tremaining: 6.57s\n",
      "666:\tlearn: 336.4479723\ttotal: 13.1s\tremaining: 6.55s\n",
      "667:\tlearn: 336.0624988\ttotal: 13.1s\tremaining: 6.53s\n",
      "668:\tlearn: 335.4347880\ttotal: 13.2s\tremaining: 6.51s\n",
      "669:\tlearn: 335.2372141\ttotal: 13.2s\tremaining: 6.48s\n",
      "670:\tlearn: 334.8272436\ttotal: 13.2s\tremaining: 6.46s\n",
      "671:\tlearn: 334.6007819\ttotal: 13.2s\tremaining: 6.44s\n",
      "672:\tlearn: 334.3517642\ttotal: 13.2s\tremaining: 6.42s\n",
      "673:\tlearn: 333.9296635\ttotal: 13.2s\tremaining: 6.4s\n",
      "674:\tlearn: 333.7610523\ttotal: 13.2s\tremaining: 6.38s\n",
      "675:\tlearn: 333.5686448\ttotal: 13.3s\tremaining: 6.36s\n",
      "676:\tlearn: 333.0033839\ttotal: 13.3s\tremaining: 6.33s\n",
      "677:\tlearn: 332.7127851\ttotal: 13.3s\tremaining: 6.31s\n",
      "678:\tlearn: 332.2625380\ttotal: 13.3s\tremaining: 6.29s\n",
      "679:\tlearn: 331.7476841\ttotal: 13.3s\tremaining: 6.26s\n",
      "680:\tlearn: 331.2851122\ttotal: 13.3s\tremaining: 6.24s\n",
      "681:\tlearn: 331.0055397\ttotal: 13.3s\tremaining: 6.21s\n",
      "682:\tlearn: 330.6750819\ttotal: 13.3s\tremaining: 6.19s\n",
      "683:\tlearn: 330.3782997\ttotal: 13.3s\tremaining: 6.17s\n",
      "684:\tlearn: 330.0822689\ttotal: 13.4s\tremaining: 6.14s\n",
      "685:\tlearn: 329.3333512\ttotal: 13.4s\tremaining: 6.12s\n",
      "686:\tlearn: 328.9374141\ttotal: 13.4s\tremaining: 6.1s\n",
      "687:\tlearn: 328.6262106\ttotal: 13.4s\tremaining: 6.08s\n",
      "688:\tlearn: 328.3186558\ttotal: 13.4s\tremaining: 6.07s\n",
      "689:\tlearn: 328.0542422\ttotal: 13.5s\tremaining: 6.05s\n",
      "690:\tlearn: 327.6487142\ttotal: 13.5s\tremaining: 6.04s\n",
      "691:\tlearn: 327.2495114\ttotal: 13.5s\tremaining: 6.03s\n",
      "692:\tlearn: 326.9516897\ttotal: 13.6s\tremaining: 6.01s\n",
      "693:\tlearn: 326.5708286\ttotal: 13.6s\tremaining: 6s\n",
      "694:\tlearn: 326.4065054\ttotal: 13.6s\tremaining: 5.99s\n",
      "695:\tlearn: 326.0946927\ttotal: 13.7s\tremaining: 5.97s\n",
      "696:\tlearn: 325.9364736\ttotal: 13.7s\tremaining: 5.95s\n",
      "697:\tlearn: 325.6215412\ttotal: 13.7s\tremaining: 5.93s\n",
      "698:\tlearn: 325.4125601\ttotal: 13.7s\tremaining: 5.91s\n",
      "699:\tlearn: 325.2053264\ttotal: 13.8s\tremaining: 5.89s\n",
      "700:\tlearn: 324.9784992\ttotal: 13.8s\tremaining: 5.87s\n",
      "701:\tlearn: 324.7952338\ttotal: 13.8s\tremaining: 5.87s\n",
      "702:\tlearn: 324.4989748\ttotal: 13.9s\tremaining: 5.87s\n",
      "703:\tlearn: 324.3183751\ttotal: 14s\tremaining: 5.89s\n",
      "704:\tlearn: 324.0408691\ttotal: 14.1s\tremaining: 5.89s\n",
      "705:\tlearn: 323.7509839\ttotal: 14.1s\tremaining: 5.87s\n",
      "706:\tlearn: 323.5520463\ttotal: 14.1s\tremaining: 5.86s\n",
      "707:\tlearn: 323.1906010\ttotal: 14.1s\tremaining: 5.83s\n",
      "708:\tlearn: 323.0235107\ttotal: 14.2s\tremaining: 5.82s\n",
      "709:\tlearn: 322.9197197\ttotal: 14.3s\tremaining: 5.83s\n",
      "710:\tlearn: 322.5835979\ttotal: 14.3s\tremaining: 5.81s\n",
      "711:\tlearn: 322.1451993\ttotal: 14.3s\tremaining: 5.79s\n",
      "712:\tlearn: 321.9361718\ttotal: 14.3s\tremaining: 5.77s\n",
      "713:\tlearn: 321.7847823\ttotal: 14.3s\tremaining: 5.74s\n",
      "714:\tlearn: 321.4029300\ttotal: 14.4s\tremaining: 5.72s\n",
      "715:\tlearn: 320.9381421\ttotal: 14.4s\tremaining: 5.7s\n",
      "716:\tlearn: 320.5818750\ttotal: 14.4s\tremaining: 5.67s\n",
      "717:\tlearn: 320.3336422\ttotal: 14.4s\tremaining: 5.65s\n",
      "718:\tlearn: 319.8520033\ttotal: 14.4s\tremaining: 5.63s\n",
      "719:\tlearn: 319.7064357\ttotal: 14.4s\tremaining: 5.61s\n",
      "720:\tlearn: 319.2868232\ttotal: 14.4s\tremaining: 5.58s\n",
      "721:\tlearn: 319.1439743\ttotal: 14.4s\tremaining: 5.56s\n",
      "722:\tlearn: 318.5856953\ttotal: 14.5s\tremaining: 5.54s\n",
      "723:\tlearn: 318.3517660\ttotal: 14.5s\tremaining: 5.52s\n",
      "724:\tlearn: 317.9191867\ttotal: 14.5s\tremaining: 5.5s\n",
      "725:\tlearn: 317.6178505\ttotal: 14.5s\tremaining: 5.49s\n",
      "726:\tlearn: 317.5365145\ttotal: 14.6s\tremaining: 5.46s\n",
      "727:\tlearn: 317.4017848\ttotal: 14.6s\tremaining: 5.44s\n",
      "728:\tlearn: 317.1496419\ttotal: 14.6s\tremaining: 5.42s\n",
      "729:\tlearn: 316.7745228\ttotal: 14.6s\tremaining: 5.4s\n",
      "730:\tlearn: 316.2078045\ttotal: 14.6s\tremaining: 5.38s\n",
      "731:\tlearn: 315.7641017\ttotal: 14.7s\tremaining: 5.37s\n",
      "732:\tlearn: 315.3803180\ttotal: 14.7s\tremaining: 5.34s\n",
      "733:\tlearn: 315.1628081\ttotal: 14.7s\tremaining: 5.32s\n",
      "734:\tlearn: 314.8955879\ttotal: 14.7s\tremaining: 5.3s\n",
      "735:\tlearn: 314.4664810\ttotal: 14.7s\tremaining: 5.28s\n",
      "736:\tlearn: 313.9460974\ttotal: 14.8s\tremaining: 5.27s\n",
      "737:\tlearn: 313.8691331\ttotal: 14.8s\tremaining: 5.25s\n",
      "738:\tlearn: 313.6031488\ttotal: 14.8s\tremaining: 5.23s\n",
      "739:\tlearn: 313.3970116\ttotal: 14.8s\tremaining: 5.21s\n",
      "740:\tlearn: 313.2253904\ttotal: 14.8s\tremaining: 5.18s\n",
      "741:\tlearn: 313.0959418\ttotal: 14.9s\tremaining: 5.16s\n",
      "742:\tlearn: 312.9324244\ttotal: 14.9s\tremaining: 5.15s\n",
      "743:\tlearn: 312.6742071\ttotal: 14.9s\tremaining: 5.13s\n",
      "744:\tlearn: 312.3894142\ttotal: 14.9s\tremaining: 5.11s\n",
      "745:\tlearn: 312.1772881\ttotal: 14.9s\tremaining: 5.09s\n",
      "746:\tlearn: 311.7264730\ttotal: 15s\tremaining: 5.07s\n",
      "747:\tlearn: 311.5352647\ttotal: 15s\tremaining: 5.04s\n",
      "748:\tlearn: 311.2722784\ttotal: 15s\tremaining: 5.02s\n",
      "749:\tlearn: 310.9499584\ttotal: 15s\tremaining: 5s\n",
      "750:\tlearn: 310.6682663\ttotal: 15s\tremaining: 4.98s\n",
      "751:\tlearn: 310.4205937\ttotal: 15s\tremaining: 4.95s\n",
      "752:\tlearn: 310.1544776\ttotal: 15s\tremaining: 4.93s\n",
      "753:\tlearn: 309.9447754\ttotal: 15.1s\tremaining: 4.92s\n",
      "754:\tlearn: 309.7017274\ttotal: 15.1s\tremaining: 4.91s\n",
      "755:\tlearn: 309.1993562\ttotal: 15.1s\tremaining: 4.89s\n",
      "756:\tlearn: 308.9348521\ttotal: 15.2s\tremaining: 4.87s\n",
      "757:\tlearn: 308.7275414\ttotal: 15.2s\tremaining: 4.86s\n",
      "758:\tlearn: 308.1490255\ttotal: 15.2s\tremaining: 4.83s\n",
      "759:\tlearn: 307.7418364\ttotal: 15.2s\tremaining: 4.81s\n",
      "760:\tlearn: 307.5879614\ttotal: 15.3s\tremaining: 4.79s\n",
      "761:\tlearn: 307.3893275\ttotal: 15.3s\tremaining: 4.77s\n",
      "762:\tlearn: 307.0766862\ttotal: 15.3s\tremaining: 4.75s\n",
      "763:\tlearn: 306.9810210\ttotal: 15.3s\tremaining: 4.73s\n",
      "764:\tlearn: 306.5953927\ttotal: 15.3s\tremaining: 4.71s\n",
      "765:\tlearn: 306.3542959\ttotal: 15.3s\tremaining: 4.69s\n",
      "766:\tlearn: 306.2243133\ttotal: 15.4s\tremaining: 4.67s\n",
      "767:\tlearn: 305.8775559\ttotal: 15.4s\tremaining: 4.64s\n",
      "768:\tlearn: 305.5489866\ttotal: 15.4s\tremaining: 4.62s\n",
      "769:\tlearn: 305.3071406\ttotal: 15.4s\tremaining: 4.6s\n",
      "770:\tlearn: 304.9782085\ttotal: 15.4s\tremaining: 4.58s\n",
      "771:\tlearn: 304.8834608\ttotal: 15.4s\tremaining: 4.55s\n",
      "772:\tlearn: 304.3285350\ttotal: 15.4s\tremaining: 4.53s\n",
      "773:\tlearn: 304.0759332\ttotal: 15.5s\tremaining: 4.51s\n",
      "774:\tlearn: 303.4576092\ttotal: 15.5s\tremaining: 4.49s\n",
      "775:\tlearn: 303.1941607\ttotal: 15.5s\tremaining: 4.47s\n",
      "776:\tlearn: 302.9573122\ttotal: 15.5s\tremaining: 4.45s\n",
      "777:\tlearn: 302.6774109\ttotal: 15.5s\tremaining: 4.43s\n",
      "778:\tlearn: 302.4469503\ttotal: 15.6s\tremaining: 4.41s\n",
      "779:\tlearn: 301.8250982\ttotal: 15.6s\tremaining: 4.39s\n",
      "780:\tlearn: 301.6033157\ttotal: 15.6s\tremaining: 4.37s\n",
      "781:\tlearn: 301.3500466\ttotal: 15.6s\tremaining: 4.36s\n",
      "782:\tlearn: 300.9563936\ttotal: 15.6s\tremaining: 4.34s\n",
      "783:\tlearn: 300.4844847\ttotal: 15.7s\tremaining: 4.32s\n",
      "784:\tlearn: 300.3182688\ttotal: 15.7s\tremaining: 4.3s\n",
      "785:\tlearn: 299.9892849\ttotal: 15.7s\tremaining: 4.28s\n",
      "786:\tlearn: 299.5181980\ttotal: 15.7s\tremaining: 4.25s\n",
      "787:\tlearn: 299.2705062\ttotal: 15.7s\tremaining: 4.23s\n",
      "788:\tlearn: 298.8878559\ttotal: 15.8s\tremaining: 4.21s\n",
      "789:\tlearn: 298.4874345\ttotal: 15.8s\tremaining: 4.19s\n",
      "790:\tlearn: 298.2244009\ttotal: 15.8s\tremaining: 4.17s\n",
      "791:\tlearn: 298.0394470\ttotal: 15.8s\tremaining: 4.14s\n",
      "792:\tlearn: 297.7860073\ttotal: 15.8s\tremaining: 4.12s\n",
      "793:\tlearn: 297.6626953\ttotal: 15.8s\tremaining: 4.1s\n",
      "794:\tlearn: 297.5752922\ttotal: 15.8s\tremaining: 4.08s\n",
      "795:\tlearn: 297.3167523\ttotal: 15.8s\tremaining: 4.06s\n",
      "796:\tlearn: 297.0487215\ttotal: 15.9s\tremaining: 4.04s\n",
      "797:\tlearn: 296.9006369\ttotal: 15.9s\tremaining: 4.02s\n",
      "798:\tlearn: 296.5268461\ttotal: 15.9s\tremaining: 4s\n",
      "799:\tlearn: 296.2773227\ttotal: 15.9s\tremaining: 3.98s\n",
      "800:\tlearn: 296.1272133\ttotal: 15.9s\tremaining: 3.96s\n",
      "801:\tlearn: 295.8492616\ttotal: 16s\tremaining: 3.94s\n",
      "802:\tlearn: 295.6750594\ttotal: 16s\tremaining: 3.92s\n",
      "803:\tlearn: 295.4702407\ttotal: 16s\tremaining: 3.89s\n",
      "804:\tlearn: 295.2507729\ttotal: 16s\tremaining: 3.87s\n",
      "805:\tlearn: 294.9786435\ttotal: 16s\tremaining: 3.85s\n",
      "806:\tlearn: 294.6955843\ttotal: 16s\tremaining: 3.83s\n",
      "807:\tlearn: 294.4792724\ttotal: 16.1s\tremaining: 3.82s\n",
      "808:\tlearn: 293.9967125\ttotal: 16.1s\tremaining: 3.8s\n",
      "809:\tlearn: 293.7754608\ttotal: 16.1s\tremaining: 3.78s\n",
      "810:\tlearn: 293.6343342\ttotal: 16.1s\tremaining: 3.76s\n",
      "811:\tlearn: 293.3876000\ttotal: 16.2s\tremaining: 3.74s\n",
      "812:\tlearn: 293.1758725\ttotal: 16.2s\tremaining: 3.72s\n",
      "813:\tlearn: 292.7608420\ttotal: 16.2s\tremaining: 3.7s\n",
      "814:\tlearn: 292.6841583\ttotal: 16.2s\tremaining: 3.68s\n",
      "815:\tlearn: 292.2561628\ttotal: 16.2s\tremaining: 3.66s\n",
      "816:\tlearn: 291.7109247\ttotal: 16.2s\tremaining: 3.64s\n",
      "817:\tlearn: 291.4804729\ttotal: 16.2s\tremaining: 3.62s\n",
      "818:\tlearn: 290.9989269\ttotal: 16.3s\tremaining: 3.59s\n",
      "819:\tlearn: 290.6849455\ttotal: 16.3s\tremaining: 3.57s\n",
      "820:\tlearn: 290.5463992\ttotal: 16.3s\tremaining: 3.55s\n",
      "821:\tlearn: 290.0940350\ttotal: 16.3s\tremaining: 3.53s\n",
      "822:\tlearn: 289.9144292\ttotal: 16.3s\tremaining: 3.51s\n",
      "823:\tlearn: 289.7789553\ttotal: 16.3s\tremaining: 3.49s\n",
      "824:\tlearn: 289.6302343\ttotal: 16.4s\tremaining: 3.47s\n",
      "825:\tlearn: 289.1915576\ttotal: 16.4s\tremaining: 3.45s\n",
      "826:\tlearn: 288.9549311\ttotal: 16.4s\tremaining: 3.42s\n",
      "827:\tlearn: 288.6071278\ttotal: 16.4s\tremaining: 3.4s\n",
      "828:\tlearn: 288.4912452\ttotal: 16.4s\tremaining: 3.38s\n",
      "829:\tlearn: 288.3800790\ttotal: 16.4s\tremaining: 3.36s\n",
      "830:\tlearn: 287.9069339\ttotal: 16.4s\tremaining: 3.34s\n",
      "831:\tlearn: 287.7095819\ttotal: 16.4s\tremaining: 3.32s\n",
      "832:\tlearn: 287.4702341\ttotal: 16.4s\tremaining: 3.29s\n",
      "833:\tlearn: 287.2805658\ttotal: 16.4s\tremaining: 3.27s\n",
      "834:\tlearn: 286.9743632\ttotal: 16.5s\tremaining: 3.25s\n",
      "835:\tlearn: 286.6731852\ttotal: 16.5s\tremaining: 3.23s\n",
      "836:\tlearn: 286.3499142\ttotal: 16.5s\tremaining: 3.21s\n",
      "837:\tlearn: 286.0384032\ttotal: 16.5s\tremaining: 3.19s\n",
      "838:\tlearn: 285.8408730\ttotal: 16.5s\tremaining: 3.17s\n",
      "839:\tlearn: 285.5790217\ttotal: 16.6s\tremaining: 3.16s\n",
      "840:\tlearn: 285.1545834\ttotal: 16.6s\tremaining: 3.14s\n",
      "841:\tlearn: 284.8980911\ttotal: 16.6s\tremaining: 3.12s\n",
      "842:\tlearn: 284.8309940\ttotal: 16.7s\tremaining: 3.1s\n",
      "843:\tlearn: 284.6079860\ttotal: 16.7s\tremaining: 3.08s\n",
      "844:\tlearn: 284.4249728\ttotal: 16.7s\tremaining: 3.06s\n",
      "845:\tlearn: 284.2537586\ttotal: 16.7s\tremaining: 3.04s\n",
      "846:\tlearn: 283.7473835\ttotal: 16.7s\tremaining: 3.02s\n",
      "847:\tlearn: 283.4233835\ttotal: 16.7s\tremaining: 3s\n",
      "848:\tlearn: 283.3377199\ttotal: 16.8s\tremaining: 2.98s\n",
      "849:\tlearn: 283.1124523\ttotal: 16.8s\tremaining: 2.96s\n",
      "850:\tlearn: 282.6189901\ttotal: 16.8s\tremaining: 2.94s\n",
      "851:\tlearn: 282.1777256\ttotal: 16.8s\tremaining: 2.92s\n",
      "852:\tlearn: 281.9577011\ttotal: 16.8s\tremaining: 2.9s\n",
      "853:\tlearn: 281.8133771\ttotal: 16.8s\tremaining: 2.88s\n",
      "854:\tlearn: 281.5376388\ttotal: 16.8s\tremaining: 2.86s\n",
      "855:\tlearn: 281.3751008\ttotal: 16.9s\tremaining: 2.84s\n",
      "856:\tlearn: 281.1276288\ttotal: 16.9s\tremaining: 2.82s\n",
      "857:\tlearn: 280.8862721\ttotal: 16.9s\tremaining: 2.8s\n",
      "858:\tlearn: 280.5412419\ttotal: 16.9s\tremaining: 2.77s\n",
      "859:\tlearn: 280.3243109\ttotal: 16.9s\tremaining: 2.75s\n",
      "860:\tlearn: 280.0913834\ttotal: 16.9s\tremaining: 2.73s\n",
      "861:\tlearn: 279.8194299\ttotal: 17s\tremaining: 2.72s\n",
      "862:\tlearn: 279.6294551\ttotal: 17s\tremaining: 2.7s\n",
      "863:\tlearn: 279.4456143\ttotal: 17s\tremaining: 2.68s\n",
      "864:\tlearn: 279.2345431\ttotal: 17s\tremaining: 2.66s\n",
      "865:\tlearn: 278.9022601\ttotal: 17s\tremaining: 2.64s\n",
      "866:\tlearn: 278.5339407\ttotal: 17.1s\tremaining: 2.62s\n",
      "867:\tlearn: 278.4530485\ttotal: 17.1s\tremaining: 2.6s\n",
      "868:\tlearn: 278.1880491\ttotal: 17.1s\tremaining: 2.58s\n",
      "869:\tlearn: 278.0107098\ttotal: 17.1s\tremaining: 2.56s\n",
      "870:\tlearn: 277.7086597\ttotal: 17.2s\tremaining: 2.54s\n",
      "871:\tlearn: 277.3263839\ttotal: 17.2s\tremaining: 2.52s\n",
      "872:\tlearn: 276.9650173\ttotal: 17.2s\tremaining: 2.5s\n",
      "873:\tlearn: 276.7875663\ttotal: 17.2s\tremaining: 2.48s\n",
      "874:\tlearn: 276.5228458\ttotal: 17.2s\tremaining: 2.46s\n",
      "875:\tlearn: 276.2620262\ttotal: 17.3s\tremaining: 2.44s\n",
      "876:\tlearn: 276.0857366\ttotal: 17.3s\tremaining: 2.42s\n",
      "877:\tlearn: 275.9293045\ttotal: 17.3s\tremaining: 2.4s\n",
      "878:\tlearn: 275.6781779\ttotal: 17.3s\tremaining: 2.38s\n",
      "879:\tlearn: 275.5448823\ttotal: 17.3s\tremaining: 2.36s\n",
      "880:\tlearn: 275.1082160\ttotal: 17.3s\tremaining: 2.34s\n",
      "881:\tlearn: 275.0010348\ttotal: 17.3s\tremaining: 2.32s\n",
      "882:\tlearn: 274.8335798\ttotal: 17.4s\tremaining: 2.3s\n",
      "883:\tlearn: 274.6112459\ttotal: 17.4s\tremaining: 2.28s\n",
      "884:\tlearn: 274.3572010\ttotal: 17.4s\tremaining: 2.26s\n",
      "885:\tlearn: 274.0634162\ttotal: 17.4s\tremaining: 2.24s\n",
      "886:\tlearn: 273.7225139\ttotal: 17.5s\tremaining: 2.22s\n",
      "887:\tlearn: 273.2806550\ttotal: 17.5s\tremaining: 2.21s\n",
      "888:\tlearn: 272.7921819\ttotal: 17.5s\tremaining: 2.19s\n",
      "889:\tlearn: 272.5553861\ttotal: 17.5s\tremaining: 2.17s\n",
      "890:\tlearn: 272.3873954\ttotal: 17.5s\tremaining: 2.15s\n",
      "891:\tlearn: 272.2188121\ttotal: 17.6s\tremaining: 2.13s\n",
      "892:\tlearn: 272.0238152\ttotal: 17.6s\tremaining: 2.11s\n",
      "893:\tlearn: 271.8200247\ttotal: 17.6s\tremaining: 2.09s\n",
      "894:\tlearn: 271.5306710\ttotal: 17.6s\tremaining: 2.07s\n",
      "895:\tlearn: 271.3451812\ttotal: 17.6s\tremaining: 2.05s\n",
      "896:\tlearn: 270.8740378\ttotal: 17.7s\tremaining: 2.03s\n",
      "897:\tlearn: 270.6573890\ttotal: 17.7s\tremaining: 2.01s\n",
      "898:\tlearn: 270.4295240\ttotal: 17.7s\tremaining: 1.99s\n",
      "899:\tlearn: 270.2733903\ttotal: 17.7s\tremaining: 1.97s\n",
      "900:\tlearn: 270.0790356\ttotal: 17.8s\tremaining: 1.95s\n",
      "901:\tlearn: 269.6893672\ttotal: 17.8s\tremaining: 1.93s\n",
      "902:\tlearn: 269.4218019\ttotal: 17.8s\tremaining: 1.91s\n",
      "903:\tlearn: 269.3174285\ttotal: 17.8s\tremaining: 1.89s\n",
      "904:\tlearn: 269.1091594\ttotal: 17.8s\tremaining: 1.87s\n",
      "905:\tlearn: 269.0057843\ttotal: 17.9s\tremaining: 1.85s\n",
      "906:\tlearn: 268.9366936\ttotal: 17.9s\tremaining: 1.83s\n",
      "907:\tlearn: 268.7638307\ttotal: 17.9s\tremaining: 1.81s\n",
      "908:\tlearn: 268.6169448\ttotal: 17.9s\tremaining: 1.79s\n",
      "909:\tlearn: 268.4458666\ttotal: 17.9s\tremaining: 1.77s\n",
      "910:\tlearn: 268.1696135\ttotal: 17.9s\tremaining: 1.75s\n",
      "911:\tlearn: 267.8413008\ttotal: 17.9s\tremaining: 1.73s\n",
      "912:\tlearn: 267.6413303\ttotal: 17.9s\tremaining: 1.71s\n",
      "913:\tlearn: 267.4616718\ttotal: 17.9s\tremaining: 1.69s\n",
      "914:\tlearn: 267.3543077\ttotal: 18s\tremaining: 1.67s\n",
      "915:\tlearn: 267.1001129\ttotal: 18s\tremaining: 1.65s\n",
      "916:\tlearn: 266.9669654\ttotal: 18s\tremaining: 1.63s\n",
      "917:\tlearn: 266.7077417\ttotal: 18s\tremaining: 1.61s\n",
      "918:\tlearn: 266.5757818\ttotal: 18s\tremaining: 1.59s\n",
      "919:\tlearn: 266.2923072\ttotal: 18s\tremaining: 1.57s\n",
      "920:\tlearn: 266.2265264\ttotal: 18s\tremaining: 1.55s\n",
      "921:\tlearn: 265.8876017\ttotal: 18.1s\tremaining: 1.53s\n",
      "922:\tlearn: 265.5928879\ttotal: 18.1s\tremaining: 1.51s\n",
      "923:\tlearn: 265.4078463\ttotal: 18.1s\tremaining: 1.49s\n",
      "924:\tlearn: 265.0485683\ttotal: 18.1s\tremaining: 1.47s\n",
      "925:\tlearn: 264.7202336\ttotal: 18.1s\tremaining: 1.45s\n",
      "926:\tlearn: 264.5463177\ttotal: 18.1s\tremaining: 1.43s\n",
      "927:\tlearn: 264.2981155\ttotal: 18.2s\tremaining: 1.41s\n",
      "928:\tlearn: 264.0459560\ttotal: 18.2s\tremaining: 1.39s\n",
      "929:\tlearn: 263.7716654\ttotal: 18.2s\tremaining: 1.37s\n",
      "930:\tlearn: 263.5606712\ttotal: 18.2s\tremaining: 1.35s\n",
      "931:\tlearn: 263.4163855\ttotal: 18.2s\tremaining: 1.33s\n",
      "932:\tlearn: 263.0909691\ttotal: 18.3s\tremaining: 1.31s\n",
      "933:\tlearn: 262.7970389\ttotal: 18.3s\tremaining: 1.29s\n",
      "934:\tlearn: 262.4940217\ttotal: 18.3s\tremaining: 1.27s\n",
      "935:\tlearn: 262.3263694\ttotal: 18.3s\tremaining: 1.25s\n",
      "936:\tlearn: 262.1107641\ttotal: 18.3s\tremaining: 1.23s\n",
      "937:\tlearn: 261.8785273\ttotal: 18.4s\tremaining: 1.22s\n",
      "938:\tlearn: 261.7558093\ttotal: 18.4s\tremaining: 1.2s\n",
      "939:\tlearn: 261.5388181\ttotal: 18.4s\tremaining: 1.18s\n",
      "940:\tlearn: 261.2385648\ttotal: 18.4s\tremaining: 1.16s\n",
      "941:\tlearn: 260.9936509\ttotal: 18.5s\tremaining: 1.14s\n",
      "942:\tlearn: 260.7363560\ttotal: 18.5s\tremaining: 1.12s\n",
      "943:\tlearn: 260.4688969\ttotal: 18.5s\tremaining: 1.1s\n",
      "944:\tlearn: 260.2749623\ttotal: 18.5s\tremaining: 1.08s\n",
      "945:\tlearn: 260.1612822\ttotal: 18.5s\tremaining: 1.06s\n",
      "946:\tlearn: 259.7401973\ttotal: 18.5s\tremaining: 1.04s\n",
      "947:\tlearn: 259.5413516\ttotal: 18.5s\tremaining: 1.02s\n",
      "948:\tlearn: 259.4661832\ttotal: 18.5s\tremaining: 996ms\n",
      "949:\tlearn: 259.1491672\ttotal: 18.5s\tremaining: 976ms\n",
      "950:\tlearn: 258.8437163\ttotal: 18.6s\tremaining: 956ms\n",
      "951:\tlearn: 258.6709663\ttotal: 18.6s\tremaining: 937ms\n",
      "952:\tlearn: 258.5072831\ttotal: 18.6s\tremaining: 917ms\n",
      "953:\tlearn: 258.2325232\ttotal: 18.6s\tremaining: 897ms\n",
      "954:\tlearn: 257.9359870\ttotal: 18.6s\tremaining: 878ms\n",
      "955:\tlearn: 257.6906861\ttotal: 18.6s\tremaining: 858ms\n",
      "956:\tlearn: 257.6198769\ttotal: 18.7s\tremaining: 840ms\n",
      "957:\tlearn: 257.3190094\ttotal: 18.7s\tremaining: 820ms\n",
      "958:\tlearn: 257.2149683\ttotal: 18.7s\tremaining: 801ms\n",
      "959:\tlearn: 256.9810020\ttotal: 18.7s\tremaining: 781ms\n",
      "960:\tlearn: 256.8585868\ttotal: 18.8s\tremaining: 761ms\n",
      "961:\tlearn: 256.7219464\ttotal: 18.8s\tremaining: 741ms\n",
      "962:\tlearn: 256.5146556\ttotal: 18.8s\tremaining: 722ms\n",
      "963:\tlearn: 256.3127734\ttotal: 18.8s\tremaining: 702ms\n",
      "964:\tlearn: 256.0554023\ttotal: 18.8s\tremaining: 682ms\n",
      "965:\tlearn: 255.7723516\ttotal: 18.8s\tremaining: 663ms\n",
      "966:\tlearn: 255.7108846\ttotal: 18.8s\tremaining: 643ms\n",
      "967:\tlearn: 255.3082406\ttotal: 18.9s\tremaining: 624ms\n",
      "968:\tlearn: 255.1810581\ttotal: 18.9s\tremaining: 604ms\n",
      "969:\tlearn: 254.8500131\ttotal: 18.9s\tremaining: 585ms\n",
      "970:\tlearn: 254.6866241\ttotal: 18.9s\tremaining: 565ms\n",
      "971:\tlearn: 254.4959743\ttotal: 18.9s\tremaining: 546ms\n",
      "972:\tlearn: 254.1310736\ttotal: 19s\tremaining: 526ms\n",
      "973:\tlearn: 254.0258230\ttotal: 19s\tremaining: 507ms\n",
      "974:\tlearn: 253.8349386\ttotal: 19s\tremaining: 487ms\n",
      "975:\tlearn: 253.6048964\ttotal: 19s\tremaining: 467ms\n",
      "976:\tlearn: 253.5693806\ttotal: 19s\tremaining: 448ms\n",
      "977:\tlearn: 253.3658693\ttotal: 19s\tremaining: 428ms\n",
      "978:\tlearn: 253.1827611\ttotal: 19s\tremaining: 409ms\n",
      "979:\tlearn: 252.9262080\ttotal: 19.1s\tremaining: 390ms\n",
      "980:\tlearn: 252.6742035\ttotal: 19.1s\tremaining: 370ms\n",
      "981:\tlearn: 252.3086955\ttotal: 19.1s\tremaining: 351ms\n",
      "982:\tlearn: 252.1566998\ttotal: 19.2s\tremaining: 332ms\n",
      "983:\tlearn: 251.9769883\ttotal: 19.2s\tremaining: 312ms\n",
      "984:\tlearn: 251.7237315\ttotal: 19.2s\tremaining: 292ms\n",
      "985:\tlearn: 251.4203274\ttotal: 19.2s\tremaining: 273ms\n",
      "986:\tlearn: 251.2049536\ttotal: 19.2s\tremaining: 253ms\n",
      "987:\tlearn: 250.9275121\ttotal: 19.2s\tremaining: 234ms\n",
      "988:\tlearn: 250.7445718\ttotal: 19.3s\tremaining: 214ms\n",
      "989:\tlearn: 250.5633482\ttotal: 19.3s\tremaining: 195ms\n",
      "990:\tlearn: 250.2681923\ttotal: 19.3s\tremaining: 175ms\n",
      "991:\tlearn: 250.1605936\ttotal: 19.3s\tremaining: 156ms\n",
      "992:\tlearn: 250.0920651\ttotal: 19.3s\tremaining: 136ms\n",
      "993:\tlearn: 249.9248613\ttotal: 19.4s\tremaining: 117ms\n",
      "994:\tlearn: 249.6526567\ttotal: 19.4s\tremaining: 97.4ms\n",
      "995:\tlearn: 249.5232274\ttotal: 19.4s\tremaining: 77.9ms\n",
      "996:\tlearn: 249.3893577\ttotal: 19.4s\tremaining: 58.4ms\n",
      "997:\tlearn: 249.2115613\ttotal: 19.4s\tremaining: 38.9ms\n",
      "998:\tlearn: 249.0911727\ttotal: 19.5s\tremaining: 19.5ms\n",
      "999:\tlearn: 248.8643908\ttotal: 19.5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE%</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1244.0956</td>\n",
       "      <td>2.7946</td>\n",
       "      <td>0.9912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1727.4708</td>\n",
       "      <td>4.3434</td>\n",
       "      <td>0.9830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>2261.5156</td>\n",
       "      <td>5.6872</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>2580.2157</td>\n",
       "      <td>6.8414</td>\n",
       "      <td>0.9620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>2646.6129</td>\n",
       "      <td>6.3558</td>\n",
       "      <td>0.9601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>3134.5864</td>\n",
       "      <td>7.5077</td>\n",
       "      <td>0.9440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>17475.8987</td>\n",
       "      <td>59.6271</td>\n",
       "      <td>-0.7417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVR</td>\n",
       "      <td>28069.0541</td>\n",
       "      <td>73.3994</td>\n",
       "      <td>-3.4932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name        RMSE    MAPE%  r2_score\n",
       "0       LinearRegression   1244.0956   2.7946    0.9912\n",
       "3  RandomForestRegressor   1727.4708   4.3434    0.9830\n",
       "7          LGBMRegressor   2261.5156   5.6872    0.9708\n",
       "4      AdaBoostRegressor   2580.2157   6.8414    0.9620\n",
       "6           XGBRegressor   2646.6129   6.3558    0.9601\n",
       "5      CatBoostRegressor   3134.5864   7.5077    0.9440\n",
       "2    KNeighborsRegressor  17475.8987  59.6271   -0.7417\n",
       "1                    SVR  28069.0541  73.3994   -3.4932"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Use default parameters for all model\")\n",
    "models= [\n",
    "    LinearRegression(),\n",
    "    SVR(),\n",
    "    KNeighborsRegressor(), \n",
    "    RandomForestRegressor(),\n",
    "    AdaBoostRegressor(),\n",
    "    CatBoostRegressor(), \n",
    "    xgb.XGBRegressor(),\n",
    "    lgb.LGBMRegressor()\n",
    "]\n",
    "\n",
    "entries = []                                           \n",
    "for model in models:\n",
    "\n",
    "    rmse_l = []\n",
    "    mape_l = []\n",
    "    r2_score_l = []\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    r2_score_value = round(r2_score(y_test, y_pred_test), 4)\n",
    "    rmse = round(mean_squared_error(y_test, y_pred_test, squared=False), 4)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "    mape = round(mape*100, 4)\n",
    "\n",
    "    r2_score_l.append(r2_score_value)\n",
    "    rmse_l.append(rmse)\n",
    "    mape_l.append(mape)\n",
    "\n",
    "    entries.append([model_name, np.mean(rmse_l), np.mean(mape_l), np.mean(r2_score_l)])\n",
    "\n",
    "model_df = pd.DataFrame(entries, columns=['model_name', 'RMSE', 'MAPE%', 'r2_score'])\n",
    "model_df.sort_values(by=['r2_score'], ascending=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Use best parameters for all model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {'C': 1000,\n",
    "  'coef0': 0.0, 'degree': 3, 'epsilon': 0.001,\n",
    "    'gamma': 0.0001, 'kernel': 'rbf', 'shrinking': True, 'tol': 0.001}\n",
    "\n",
    "randomforest_params = {'max_features': None, 'n_estimators': 300}\n",
    "\n",
    "adaboost_params = {'estimator': None,\n",
    " 'n_estimators': 125,\n",
    "  'learning_rate': 0.95,\n",
    " 'loss': 'linear',\n",
    " 'base_estimator': 'deprecated',\n",
    " 'random_state': 0,\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    \"depth\": 7,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"iterations\": 150,\n",
    "}\n",
    "\n",
    "ligtgbm_params = {'random_state': 42, 'objective': 'regression', \n",
    "              'num_leaves': 35, 'min_child_samples': 5,\n",
    " 'metric': 'rmse', 'max_depth': 8, 'max_bin': 500,\n",
    " 'learning_rate': 0.48, 'lambda_l2': 0.2, 'lambda_l1': 0.1,\n",
    " 'boosting_type': 'dart'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use best parameters for all model\n",
      "0:\tlearn: 13350.4368497\ttotal: 36.7ms\tremaining: 5.47s\n",
      "1:\tlearn: 13226.3326890\ttotal: 67.2ms\tremaining: 4.97s\n",
      "2:\tlearn: 13108.0706290\ttotal: 85.2ms\tremaining: 4.17s\n",
      "3:\tlearn: 12995.8413044\ttotal: 109ms\tremaining: 3.97s\n",
      "4:\tlearn: 12880.6630324\ttotal: 132ms\tremaining: 3.84s\n",
      "5:\tlearn: 12763.2415500\ttotal: 154ms\tremaining: 3.69s\n",
      "6:\tlearn: 12647.2468445\ttotal: 186ms\tremaining: 3.81s\n",
      "7:\tlearn: 12532.5291320\ttotal: 220ms\tremaining: 3.9s\n",
      "8:\tlearn: 12421.0616741\ttotal: 249ms\tremaining: 3.9s\n",
      "9:\tlearn: 12311.3125667\ttotal: 269ms\tremaining: 3.76s\n",
      "10:\tlearn: 12201.1737521\ttotal: 286ms\tremaining: 3.62s\n",
      "11:\tlearn: 12093.8808719\ttotal: 309ms\tremaining: 3.55s\n",
      "12:\tlearn: 11992.0767049\ttotal: 331ms\tremaining: 3.49s\n",
      "13:\tlearn: 11881.9716813\ttotal: 352ms\tremaining: 3.42s\n",
      "14:\tlearn: 11773.5349851\ttotal: 383ms\tremaining: 3.45s\n",
      "15:\tlearn: 11666.0617614\ttotal: 419ms\tremaining: 3.5s\n",
      "16:\tlearn: 11561.9819263\ttotal: 467ms\tremaining: 3.65s\n",
      "17:\tlearn: 11463.1504213\ttotal: 495ms\tremaining: 3.63s\n",
      "18:\tlearn: 11364.3516598\ttotal: 531ms\tremaining: 3.66s\n",
      "19:\tlearn: 11263.7964937\ttotal: 563ms\tremaining: 3.66s\n",
      "20:\tlearn: 11161.3878456\ttotal: 592ms\tremaining: 3.64s\n",
      "21:\tlearn: 11062.0554125\ttotal: 616ms\tremaining: 3.58s\n",
      "22:\tlearn: 10966.0433663\ttotal: 645ms\tremaining: 3.56s\n",
      "23:\tlearn: 10862.7734810\ttotal: 667ms\tremaining: 3.5s\n",
      "24:\tlearn: 10764.9611648\ttotal: 689ms\tremaining: 3.44s\n",
      "25:\tlearn: 10668.4432306\ttotal: 707ms\tremaining: 3.37s\n",
      "26:\tlearn: 10576.9810017\ttotal: 724ms\tremaining: 3.3s\n",
      "27:\tlearn: 10480.0280337\ttotal: 746ms\tremaining: 3.25s\n",
      "28:\tlearn: 10388.3802778\ttotal: 774ms\tremaining: 3.23s\n",
      "29:\tlearn: 10296.5264487\ttotal: 855ms\tremaining: 3.42s\n",
      "30:\tlearn: 10203.9692545\ttotal: 913ms\tremaining: 3.5s\n",
      "31:\tlearn: 10114.6798186\ttotal: 940ms\tremaining: 3.46s\n",
      "32:\tlearn: 10023.3243626\ttotal: 958ms\tremaining: 3.4s\n",
      "33:\tlearn: 9933.1642124\ttotal: 975ms\tremaining: 3.33s\n",
      "34:\tlearn: 9842.8018375\ttotal: 993ms\tremaining: 3.26s\n",
      "35:\tlearn: 9753.9333776\ttotal: 1.03s\tremaining: 3.25s\n",
      "36:\tlearn: 9671.0532985\ttotal: 1.07s\tremaining: 3.28s\n",
      "37:\tlearn: 9583.2827168\ttotal: 1.12s\tremaining: 3.3s\n",
      "38:\tlearn: 9497.6351980\ttotal: 1.17s\tremaining: 3.33s\n",
      "39:\tlearn: 9415.4397605\ttotal: 1.2s\tremaining: 3.31s\n",
      "40:\tlearn: 9330.9493548\ttotal: 1.23s\tremaining: 3.28s\n",
      "41:\tlearn: 9247.8792229\ttotal: 1.26s\tremaining: 3.23s\n",
      "42:\tlearn: 9164.8996429\ttotal: 1.32s\tremaining: 3.3s\n",
      "43:\tlearn: 9084.1393574\ttotal: 1.36s\tremaining: 3.27s\n",
      "44:\tlearn: 9001.9741006\ttotal: 1.4s\tremaining: 3.27s\n",
      "45:\tlearn: 8920.7242423\ttotal: 1.43s\tremaining: 3.23s\n",
      "46:\tlearn: 8841.4696797\ttotal: 1.45s\tremaining: 3.19s\n",
      "47:\tlearn: 8761.1465818\ttotal: 1.47s\tremaining: 3.13s\n",
      "48:\tlearn: 8686.0296294\ttotal: 1.49s\tremaining: 3.07s\n",
      "49:\tlearn: 8605.8797761\ttotal: 1.51s\tremaining: 3.02s\n",
      "50:\tlearn: 8527.4421979\ttotal: 1.54s\tremaining: 2.99s\n",
      "51:\tlearn: 8452.3159813\ttotal: 1.61s\tremaining: 3.04s\n",
      "52:\tlearn: 8375.1978863\ttotal: 1.7s\tremaining: 3.12s\n",
      "53:\tlearn: 8300.3570570\ttotal: 1.74s\tremaining: 3.1s\n",
      "54:\tlearn: 8229.0964076\ttotal: 1.77s\tremaining: 3.05s\n",
      "55:\tlearn: 8152.6515262\ttotal: 1.79s\tremaining: 3.01s\n",
      "56:\tlearn: 8079.0341735\ttotal: 1.82s\tremaining: 2.97s\n",
      "57:\tlearn: 8008.2715873\ttotal: 1.85s\tremaining: 2.94s\n",
      "58:\tlearn: 7938.1426206\ttotal: 1.88s\tremaining: 2.89s\n",
      "59:\tlearn: 7869.3098077\ttotal: 1.9s\tremaining: 2.84s\n",
      "60:\tlearn: 7800.2777631\ttotal: 1.92s\tremaining: 2.8s\n",
      "61:\tlearn: 7734.2893424\ttotal: 1.95s\tremaining: 2.77s\n",
      "62:\tlearn: 7666.9377799\ttotal: 1.99s\tremaining: 2.75s\n",
      "63:\tlearn: 7598.6832875\ttotal: 2.02s\tremaining: 2.72s\n",
      "64:\tlearn: 7536.6111355\ttotal: 2.06s\tremaining: 2.69s\n",
      "65:\tlearn: 7472.2960646\ttotal: 2.12s\tremaining: 2.7s\n",
      "66:\tlearn: 7407.4775638\ttotal: 2.15s\tremaining: 2.67s\n",
      "67:\tlearn: 7342.6308897\ttotal: 2.17s\tremaining: 2.62s\n",
      "68:\tlearn: 7275.4974423\ttotal: 2.19s\tremaining: 2.58s\n",
      "69:\tlearn: 7212.4366390\ttotal: 2.23s\tremaining: 2.54s\n",
      "70:\tlearn: 7150.2975123\ttotal: 2.25s\tremaining: 2.51s\n",
      "71:\tlearn: 7088.9266999\ttotal: 2.28s\tremaining: 2.47s\n",
      "72:\tlearn: 7026.0678752\ttotal: 2.3s\tremaining: 2.42s\n",
      "73:\tlearn: 6964.8220527\ttotal: 2.32s\tremaining: 2.38s\n",
      "74:\tlearn: 6909.0082263\ttotal: 2.33s\tremaining: 2.33s\n",
      "75:\tlearn: 6847.5154506\ttotal: 2.35s\tremaining: 2.29s\n",
      "76:\tlearn: 6787.7190014\ttotal: 2.38s\tremaining: 2.25s\n",
      "77:\tlearn: 6728.2592133\ttotal: 2.41s\tremaining: 2.22s\n",
      "78:\tlearn: 6667.4104021\ttotal: 2.44s\tremaining: 2.2s\n",
      "79:\tlearn: 6610.9786016\ttotal: 2.5s\tremaining: 2.19s\n",
      "80:\tlearn: 6553.1884757\ttotal: 2.54s\tremaining: 2.17s\n",
      "81:\tlearn: 6494.7244317\ttotal: 2.57s\tremaining: 2.13s\n",
      "82:\tlearn: 6437.1199387\ttotal: 2.59s\tremaining: 2.09s\n",
      "83:\tlearn: 6379.8009272\ttotal: 2.62s\tremaining: 2.05s\n",
      "84:\tlearn: 6323.9446460\ttotal: 2.63s\tremaining: 2.02s\n",
      "85:\tlearn: 6270.7163492\ttotal: 2.65s\tremaining: 1.97s\n",
      "86:\tlearn: 6215.8631176\ttotal: 2.67s\tremaining: 1.93s\n",
      "87:\tlearn: 6162.5666146\ttotal: 2.69s\tremaining: 1.9s\n",
      "88:\tlearn: 6110.7485302\ttotal: 2.71s\tremaining: 1.86s\n",
      "89:\tlearn: 6055.5004157\ttotal: 2.73s\tremaining: 1.82s\n",
      "90:\tlearn: 6002.4792231\ttotal: 2.74s\tremaining: 1.78s\n",
      "91:\tlearn: 5952.2846167\ttotal: 2.76s\tremaining: 1.74s\n",
      "92:\tlearn: 5903.7123556\ttotal: 2.78s\tremaining: 1.7s\n",
      "93:\tlearn: 5854.2237713\ttotal: 2.8s\tremaining: 1.67s\n",
      "94:\tlearn: 5802.8817699\ttotal: 2.83s\tremaining: 1.64s\n",
      "95:\tlearn: 5752.3610134\ttotal: 2.85s\tremaining: 1.6s\n",
      "96:\tlearn: 5706.1564918\ttotal: 2.93s\tremaining: 1.6s\n",
      "97:\tlearn: 5657.7175624\ttotal: 3.03s\tremaining: 1.61s\n",
      "98:\tlearn: 5607.6602443\ttotal: 3.07s\tremaining: 1.58s\n",
      "99:\tlearn: 5559.7699877\ttotal: 3.1s\tremaining: 1.55s\n",
      "100:\tlearn: 5509.9695784\ttotal: 3.12s\tremaining: 1.51s\n",
      "101:\tlearn: 5460.8471463\ttotal: 3.14s\tremaining: 1.48s\n",
      "102:\tlearn: 5413.9302731\ttotal: 3.16s\tremaining: 1.44s\n",
      "103:\tlearn: 5366.7684451\ttotal: 3.2s\tremaining: 1.41s\n",
      "104:\tlearn: 5321.0157430\ttotal: 3.23s\tremaining: 1.38s\n",
      "105:\tlearn: 5275.2585882\ttotal: 3.27s\tremaining: 1.36s\n",
      "106:\tlearn: 5231.2111663\ttotal: 3.31s\tremaining: 1.33s\n",
      "107:\tlearn: 5186.6797463\ttotal: 3.37s\tremaining: 1.31s\n",
      "108:\tlearn: 5144.3851174\ttotal: 3.42s\tremaining: 1.29s\n",
      "109:\tlearn: 5099.4962324\ttotal: 3.47s\tremaining: 1.26s\n",
      "110:\tlearn: 5057.6284758\ttotal: 3.51s\tremaining: 1.23s\n",
      "111:\tlearn: 5012.4797712\ttotal: 3.54s\tremaining: 1.2s\n",
      "112:\tlearn: 4968.4069894\ttotal: 3.57s\tremaining: 1.17s\n",
      "113:\tlearn: 4928.2922503\ttotal: 3.6s\tremaining: 1.14s\n",
      "114:\tlearn: 4887.2554863\ttotal: 3.63s\tremaining: 1.1s\n",
      "115:\tlearn: 4844.6091412\ttotal: 3.65s\tremaining: 1.07s\n",
      "116:\tlearn: 4802.7579182\ttotal: 3.67s\tremaining: 1.04s\n",
      "117:\tlearn: 4761.4567139\ttotal: 3.7s\tremaining: 1s\n",
      "118:\tlearn: 4721.9675596\ttotal: 3.73s\tremaining: 973ms\n",
      "119:\tlearn: 4680.6287438\ttotal: 3.77s\tremaining: 943ms\n",
      "120:\tlearn: 4641.8712300\ttotal: 3.81s\tremaining: 915ms\n",
      "121:\tlearn: 4602.4563916\ttotal: 3.88s\tremaining: 889ms\n",
      "122:\tlearn: 4562.6576661\ttotal: 3.9s\tremaining: 857ms\n",
      "123:\tlearn: 4524.2670949\ttotal: 3.93s\tremaining: 824ms\n",
      "124:\tlearn: 4488.6876989\ttotal: 3.95s\tremaining: 790ms\n",
      "125:\tlearn: 4450.5628880\ttotal: 4s\tremaining: 762ms\n",
      "126:\tlearn: 4412.0449209\ttotal: 4.03s\tremaining: 730ms\n",
      "127:\tlearn: 4372.3740866\ttotal: 4.07s\tremaining: 699ms\n",
      "128:\tlearn: 4335.6441093\ttotal: 4.09s\tremaining: 666ms\n",
      "129:\tlearn: 4299.3094305\ttotal: 4.12s\tremaining: 633ms\n",
      "130:\tlearn: 4264.6617870\ttotal: 4.13s\tremaining: 599ms\n",
      "131:\tlearn: 4226.8595646\ttotal: 4.15s\tremaining: 566ms\n",
      "132:\tlearn: 4190.4626673\ttotal: 4.18s\tremaining: 535ms\n",
      "133:\tlearn: 4155.3916208\ttotal: 4.22s\tremaining: 504ms\n",
      "134:\tlearn: 4119.5822278\ttotal: 4.31s\tremaining: 479ms\n",
      "135:\tlearn: 4084.2900192\ttotal: 4.34s\tremaining: 446ms\n",
      "136:\tlearn: 4050.5859638\ttotal: 4.37s\tremaining: 414ms\n",
      "137:\tlearn: 4018.1486339\ttotal: 4.38s\tremaining: 381ms\n",
      "138:\tlearn: 3984.0235399\ttotal: 4.41s\tremaining: 349ms\n",
      "139:\tlearn: 3950.5591956\ttotal: 4.42s\tremaining: 316ms\n",
      "140:\tlearn: 3917.0593216\ttotal: 4.44s\tremaining: 283ms\n",
      "141:\tlearn: 3883.7129569\ttotal: 4.46s\tremaining: 251ms\n",
      "142:\tlearn: 3850.4469422\ttotal: 4.48s\tremaining: 219ms\n",
      "143:\tlearn: 3819.1762972\ttotal: 4.5s\tremaining: 188ms\n",
      "144:\tlearn: 3787.5424429\ttotal: 4.54s\tremaining: 156ms\n",
      "145:\tlearn: 3754.4427510\ttotal: 4.57s\tremaining: 125ms\n",
      "146:\tlearn: 3722.7231486\ttotal: 4.63s\tremaining: 94.5ms\n",
      "147:\tlearn: 3690.9175476\ttotal: 4.71s\tremaining: 63.6ms\n",
      "148:\tlearn: 3660.9079814\ttotal: 4.77s\tremaining: 32ms\n",
      "149:\tlearn: 3629.5596041\ttotal: 4.82s\tremaining: 0us\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE%</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1244.0956</td>\n",
       "      <td>2.7946</td>\n",
       "      <td>0.9912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1695.3050</td>\n",
       "      <td>4.3947</td>\n",
       "      <td>0.9836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>2126.3978</td>\n",
       "      <td>5.4214</td>\n",
       "      <td>0.9742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>2196.7684</td>\n",
       "      <td>5.1462</td>\n",
       "      <td>0.9725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>2646.6129</td>\n",
       "      <td>6.3558</td>\n",
       "      <td>0.9601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>8234.7899</td>\n",
       "      <td>15.7346</td>\n",
       "      <td>0.6133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>17475.8987</td>\n",
       "      <td>59.6271</td>\n",
       "      <td>-0.7417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVR</td>\n",
       "      <td>28249.9534</td>\n",
       "      <td>73.7372</td>\n",
       "      <td>-3.5513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name        RMSE    MAPE%  r2_score\n",
       "0       LinearRegression   1244.0956   2.7946    0.9912\n",
       "3  RandomForestRegressor   1695.3050   4.3947    0.9836\n",
       "4      AdaBoostRegressor   2126.3978   5.4214    0.9742\n",
       "7          LGBMRegressor   2196.7684   5.1462    0.9725\n",
       "6           XGBRegressor   2646.6129   6.3558    0.9601\n",
       "5      CatBoostRegressor   8234.7899  15.7346    0.6133\n",
       "2    KNeighborsRegressor  17475.8987  59.6271   -0.7417\n",
       "1                    SVR  28249.9534  73.7372   -3.5513"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Use best parameters for all model\")\n",
    "models= [\n",
    "    LinearRegression(),\n",
    "    SVR(**svm_params),\n",
    "    KNeighborsRegressor(), \n",
    "    RandomForestRegressor(**randomforest_params),\n",
    "    AdaBoostRegressor(**adaboost_params),\n",
    "    CatBoostRegressor(**catboost_params), \n",
    "    xgb.XGBRegressor(),\n",
    "    lgb.LGBMRegressor(**ligtgbm_params)\n",
    "]\n",
    "\n",
    "entries = []                                           \n",
    "for model in models:\n",
    "\n",
    "    rmse_l = []\n",
    "    mape_l = []\n",
    "    r2_score_l = []\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    r2_score_value = round(r2_score(y_test, y_pred_test), 4)\n",
    "    rmse = round(mean_squared_error(y_test, y_pred_test, squared=False), 4)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "    mape = round(mape*100, 4)\n",
    "\n",
    "    r2_score_l.append(r2_score_value)\n",
    "    rmse_l.append(rmse)\n",
    "    mape_l.append(mape)\n",
    "\n",
    "    entries.append([model_name, np.mean(rmse_l), np.mean(mape_l), np.mean(r2_score_l)])\n",
    "\n",
    "model_df = pd.DataFrame(entries, columns=['model_name', 'RMSE', 'MAPE%', 'r2_score'])\n",
    "model_df.sort_values(by=['r2_score'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = \n",
    "\n",
    "# total= pd.concat([model_df, df2],ignore_index=True)\n",
    "# total.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance when use `default parameters`/`best_parameters`\n",
    "The results of the metrics are also different when sharing the same Train set - Test set: 0.75-0.25\n",
    "\n",
    "Use `default parameters` for all model\n",
    "\n",
    "| model_name | RMSE     | MAPE%  | r2_score |\n",
    "| ---------- | -------- | ------ | -------- |\n",
    "| LinearRegression       | 945.4010 | 3.0251 | 0.9498   |\n",
    "| RandomForestRegressor | 1263.2753 | 4.6283 | 0.9104   |\n",
    "| XGBRegressor           | 1547.4020 | 5.5764 | 0.8655   |\n",
    "| LGBMRegressor          | 1584.6834 | 5.4142 | 0.8589   |\n",
    "| AdaBoostRegressor      | 2091.4853 | 7.4406 | 0.7543   |\n",
    "| CatBoostRegressor      | 2871.5251 | 11.8601 | 0.5368  |\n",
    "| KNeighborsRegressor    | 10909.4877 | 45.3154 | -5.6856 |\n",
    "| SVR                    | 14898.5495 | 61.4270 | -11.4686|\n",
    "\n",
    "Use `best parameters` for all model\n",
    "\n",
    "| model_name | RMSE     | MAPE%  | r2_score |\n",
    "| ---------- | -------- | ------ | -------- |\n",
    "| LinearRegression       | 945.4010 | 3.0251 | 0.9498   |\n",
    "| LGBMRegressor          | 1146.1757 | 3.7425 | 0.9262   |\n",
    "| RandomForestRegressor | 1278.9810 | 4.5589 | 0.9081   |\n",
    "| XGBRegressor           | 1547.4020 | 5.5764 | 0.8655   |\n",
    "| AdaBoostRegressor      | 2051.7571 | 7.5382 | 0.7635   |\n",
    "| CatBoostRegressor      | 2110.1710 | 8.5507 | 0.7499   |\n",
    "| KNeighborsRegressor    | 10909.4877 | 45.3154 | -5.6856 |\n",
    "| SVR                    | 15243.4767 | 63.2022 | -12.0526|\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e35676d33e03a9093a17dc7760f2b2aa4960ff6d3c0d7dc06348afdc0ca22c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
