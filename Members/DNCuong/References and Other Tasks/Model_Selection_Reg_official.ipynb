{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection: \n",
    "\n",
    "|           |Train Set| Train Set|Train Set|Test Set|Test Set|Test Set|\n",
    "|-----------|-------|----------|---------|-------|----------|---------|\n",
    "| **Model**| **R2** | **RMSE** | **MAPE%**   | **R2**    | **RMSE**    | **MAPE%**  |\n",
    "| Linear Regression | 0.9965 | 799.3932 | 4.3926  | 0.9898 | 1339.5982 | 2.9076 |\n",
    "| SVM          | 0.9968 | 985.0937 | 3.3692% | 0.9611 | 831.7924 | 2.6539% |\n",
    "| KNN   | --- | --- | --- | 0.9113 | 1256.7745 | 4.0181% |\n",
    "| Random Forest    | --- | 33.5004 | 0.0802% | 0.9897 | 430.0638| 1.3385% |\n",
    "| Adaboost          | 0.9924 | 1508.1469 | 77.2415% | 0.7346 | 2173.5470| 75.3318% | \n",
    "| XGBoost           | 0.9970 | 925.0439 | 2.9174% | 0.9501 | 1015.8001| 3.5157% |\n",
    "| LightGBM           | --- | 549.2033 | 1.2529% | 0.9640 |805.4951| 2.4725% |\n",
    "| ARIMA         | 0.9970 | 733.2738 | 2.8100% | -1.5391 | 21103.8951 | 79.7169% |\n",
    "| GAN           | 0.9955 | 706.8428 | 3.29% | 0.9651 | 731.9221| 2.30% |\n",
    "| GRU           | 0.9971 | 666.0494 | 2.98% | 0.9738 | 651.7368| 2.04% |\n",
    "| LSTM          | 0.9969 | 666.1824 | 3.00% | 0.9736 | 669.6527| 2.07% |\n",
    "\n",
    "\n",
    "SORT ACCORDING **R2_TEST**: \n",
    "\n",
    "|           |Train Set| Train Set|Train Set|Test Set|Test Set|Test Set|\n",
    "|-----------|-------|----------|---------|-------|----------|---------|\n",
    "| **Model**| **R2** | **RMSE** | **MAPE%**   | **R2**    | **RMSE**    | **MAPE%**  |\n",
    "| Linear Regression | 0.9965 | 799.3932 | 4.3926  | 0.9898 | 1339.5982 | 2.9076 |\n",
    "| Random Forest    | --- | 33.5004 | 0.0802% | 0.9897 | 430.0638| 1.3385% |\n",
    "| GRU           | 0.9971 | 666.0494 | 2.98% | 0.9738 | 651.7368| 2.04% |\n",
    "| LSTM          | 0.9969 | 666.1824 | 3.00% | 0.9736 | 669.6527| 2.07% |\n",
    "| GAN           | 0.9955 | 706.8428 | 3.29% | 0.9651 | 731.9221| 2.30% |\n",
    "| LightGBM           | --- | 549.2033 | 1.2529% | 0.9640 |805.4951| 2.4725% |\n",
    "| SVM          | 0.9968 | 985.0937 | 3.3692% | 0.9611 | 831.7924 | 2.6539% |\n",
    "| XGBoost           | 0.9970 | 925.0439 | 2.9174% | 0.9501 | 1015.8001| 3.5157% |\n",
    "| KNN   | --- | --- | --- | 0.9113 | 1256.7745 | 4.0181% |\n",
    "| Adaboost          | 0.9924 | 1508.1469 | 77.2415% | 0.7346 | 2173.5470| 75.3318% | \n",
    "| ARIMA         | 0.9970 | 733.2738 | 2.8100% | -1.5391 | 21103.8951 | 79.7169% |\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As we can see, the performance of the statistical\n",
    "models is the lower. \n",
    "\n",
    "Next to the linear methods, the method that we\n",
    "see the best performance \n",
    "\n",
    "Regarding ensemble learning methods, we can\n",
    "see the superiority of boosting, performance on\n",
    "this set of methods is unstronger than other mod-\n",
    "els.\n",
    "\n",
    "As for Deep Learning models, the performance is\n",
    "at a good threshold. We think the performance\n",
    "can be even better on GAN and LSTM but we\n",
    "don’t have resources to tune the parameters nor\n",
    "make the neural network more complicated to\n",
    "see if the performance can be higher than boosting. \n",
    "\n",
    "In summary, we can see the superiority of boost-\n",
    "ing un over linear models (with very fast train-\n",
    "ing times and very good performance). Deep\n",
    "Learning has a good performance but the train-\n",
    "ing time is really long and the tuning of the\n",
    "parameters is also extremely resource-intensive\n",
    "\n",
    "and time-consuming. Therefore, we will choose\n",
    "LightGBM as a representative model for analy-\n",
    "sis in the following sections.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection: \n",
    "\n",
    "bảng tổng hợp lại metrics của các model: \n",
    "\n",
    "|           |Train Set| Train Set|Train Set|Test Set|Test Set|Test Set|\n",
    "|-----------|-------|----------|---------|-------|----------|---------|\n",
    "| **Model**| **R2** | **RMSE** | **MAPE%**   | **R2**    | **RMSE**    | **MAPE%**  |\n",
    "| Linear Regression | 0.9965 | 799.3932 | 4.3926  | 0.9898 | 1339.5982 | 2.9076 |\n",
    "| SVM          | 0.9968 | 985.0937 | 3.3692% | 0.9611 | 831.7924 | 2.6539% |\n",
    "| KNN   | --- | --- | --- | 0.9113 | 1256.7745 | 4.0181% |\n",
    "| Random Forest    | --- | 33.5004 | 0.0802% | 0.9897 | 430.0638| 1.3385% |\n",
    "| Adaboost          | 0.9924 | 1508.1469 | 77.2415% | 0.7346 | 2173.5470| 75.3318% | \n",
    "| XGBoost           | 0.9970 | 925.0439 | 2.9174% | 0.9501 | 1015.8001| 3.5157% |\n",
    "| LightGBM           | --- | 549.2033 | 1.2529% | 0.9640 |805.4951| 2.4725% |\n",
    "| ARIMA         | 0.9970 | 733.2738 | 2.8100% | -1.5391 | 21103.8951 | 79.7169% |\n",
    "| GAN           | 0.9955 | 706.8428 | 3.29% | 0.9651 | 731.9221| 2.30% |\n",
    "| GRU           | 0.9971 | 666.0494 | 2.98% | 0.9738 | 651.7368| 2.04% |\n",
    "| LSTM          | 0.9969 | 666.1824 | 3.00% | 0.9736 | 669.6527| 2.07% |\n",
    "\n",
    "\n",
    "SORT ACCORDING **R2_TEST**: \n",
    "\n",
    "|           |Train Set| Train Set|Train Set|Test Set|Test Set|Test Set|\n",
    "|-----------|-------|----------|---------|-------|----------|---------|\n",
    "| **Model**| **R2** | **RMSE** | **MAPE%**   | **R2**    | **RMSE**    | **MAPE%**  |\n",
    "| Linear Regression | 0.9965 | 799.3932 | 4.3926  | 0.9898 | 1339.5982 | 2.9076 |\n",
    "| Random Forest    | --- | 33.5004 | 0.0802% | 0.9897 | 430.0638| 1.3385% |\n",
    "| GRU           | 0.9971 | 666.0494 | 2.98% | 0.9738 | 651.7368| 2.04% |\n",
    "| LSTM          | 0.9969 | 666.1824 | 3.00% | 0.9736 | 669.6527| 2.07% |\n",
    "| GAN           | 0.9955 | 706.8428 | 3.29% | 0.9651 | 731.9221| 2.30% |\n",
    "| LightGBM           | --- | 549.2033 | 1.2529% | 0.9640 |805.4951| 2.4725% |\n",
    "| SVM          | 0.9968 | 985.0937 | 3.3692% | 0.9611 | 831.7924 | 2.6539% |\n",
    "| XGBoost           | 0.9970 | 925.0439 | 2.9174% | 0.9501 | 1015.8001| 3.5157% |\n",
    "| KNN   | --- | --- | --- | 0.9113 | 1256.7745 | 4.0181% |\n",
    "| Adaboost          | 0.9924 | 1508.1469 | 77.2415% | 0.7346 | 2173.5470| 75.3318% | \n",
    "| ARIMA         | 0.9970 | 733.2738 | 2.8100% | -1.5391 | 21103.8951 | 79.7169% |\n",
    "\n",
    "DEMO Results của team mình: \n",
    "**MODEL SELECTION** *BITCOIN PRICE PREDICTION*\n",
    "\n",
    "Hiệu suất của các mô hình thống kê là thấp nhất. Điều này tương đối dễ hiểu vì trong phương pháp này mô hình sử dụng ít thông tin hơn so với các phương pháp khác, do đó hiệu suất thấp là không tránh khỏi.\n",
    "\n",
    "Các phương pháp tuyến tính cho thấy hiệu suất tốt ở top đầu . Chúng ta sẽ đưa ra một giả thuyết rằng vì việc chuẩn hóa data của chúng tôi tốt, cùng nhiều features có quan hệ tuyến tính.  \n",
    "\n",
    "Đối với các phương pháp học tổ hợp, chúng ta không thấy được sự quá ưu việt của Boosting (XGBoost, AdaBoost, LightGBM, ...), hiệu suất trên tập các phương pháp này cũng không mạnh hơn các mô hình khác, mà còn có phần kém hơn.\n",
    "\n",
    "Đối với các mô hình Deep Learning, hiệu suất ở ngưỡng tốt. Chúng tôi nghĩ rằng hiệu suất có thể còn tốt hơn trên LSTM, GRU và GAN nhưng chúng tôi không có tài nguyên để điều chỉnh các thông số cũng như làm cho mạng nơ-ron phức tạp hơn để xem xét xem hiệu suất có thể cao hơn nữa không. \n",
    "\n",
    "Tóm lại, chúng ta có thể thấy sự ưu thế của Linear Method so với các mô hình boosting (với thời gian huấn luyện rất nhanh và hiệu suất rất tốt). Deep Learning có hiệu suất tốt, thậm chí có thể tốt hơn nữa nhưng thời gian huấn luyện rất dài và điều chỉnh các thông số cũng cực kỳ tốn tài nguyên và thời gian. Do đó, chúng tôi sẽ chọn Linear Regression là một mô hình đại diện để phân tích trong các phần tiếp theo.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import  LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import  SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb                                             \n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import SCORERS, mean_absolute_percentage_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2660 entries, 0 to 2659\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Date                    2660 non-null   object \n",
      " 1   BTC_close               2660 non-null   float64\n",
      " 2   BTC_open                2660 non-null   float64\n",
      " 3   BTC_high                2660 non-null   float64\n",
      " 4   BTC_low                 2660 non-null   float64\n",
      " 5   difficulty              2660 non-null   int64  \n",
      " 6   addresses_active_count  2660 non-null   int64  \n",
      " 7   sum_lock_weight         2660 non-null   int64  \n",
      " 8   mean_lock_size_ytes     2660 non-null   float64\n",
      " 9   total_fees_usd          2660 non-null   float64\n",
      " 10  mean_hash_rate          2660 non-null   float64\n",
      " 11  xfer_cnt                2660 non-null   int64  \n",
      " 12  mean_tx_size_usd        2660 non-null   float64\n",
      " 13  ETH                     2660 non-null   float64\n",
      " 14  LTC                     2660 non-null   float64\n",
      " 15  XRP                     2660 non-null   float64\n",
      " 16  DOGE                    2660 non-null   float64\n",
      " 17  COPPER                  2660 non-null   float64\n",
      " 18  GOLD                    2660 non-null   float64\n",
      " 19  SILVER                  2660 non-null   float64\n",
      " 20  SPX                     2660 non-null   float64\n",
      " 21  JP225                   2660 non-null   float64\n",
      " 22  DJI                     2660 non-null   float64\n",
      " 23  BTC_close_tomorrow      2660 non-null   float64\n",
      "dtypes: float64(19), int64(4), object(1)\n",
      "memory usage: 498.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>BTC_open</th>\n",
       "      <th>BTC_high</th>\n",
       "      <th>BTC_low</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>addresses_active_count</th>\n",
       "      <th>sum_lock_weight</th>\n",
       "      <th>mean_lock_size_ytes</th>\n",
       "      <th>total_fees_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>LTC</th>\n",
       "      <th>XRP</th>\n",
       "      <th>DOGE</th>\n",
       "      <th>COPPER</th>\n",
       "      <th>GOLD</th>\n",
       "      <th>SILVER</th>\n",
       "      <th>SPX</th>\n",
       "      <th>JP225</th>\n",
       "      <th>DJI</th>\n",
       "      <th>BTC_close_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>415.8</td>\n",
       "      <td>412.8</td>\n",
       "      <td>417.5</td>\n",
       "      <td>410.3</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>445273</td>\n",
       "      <td>426654988</td>\n",
       "      <td>6.881532e+05</td>\n",
       "      <td>1.731272e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-11</td>\n",
       "      <td>419.1</td>\n",
       "      <td>415.8</td>\n",
       "      <td>422.4</td>\n",
       "      <td>415.1</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>434658</td>\n",
       "      <td>398582424</td>\n",
       "      <td>6.227850e+05</td>\n",
       "      <td>1.710193e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>410.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>410.4</td>\n",
       "      <td>419.1</td>\n",
       "      <td>420.7</td>\n",
       "      <td>407.0</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>374730</td>\n",
       "      <td>331208848</td>\n",
       "      <td>5.750154e+05</td>\n",
       "      <td>1.398444e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>412.4</td>\n",
       "      <td>410.4</td>\n",
       "      <td>415.9</td>\n",
       "      <td>409.6</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>421585</td>\n",
       "      <td>334817852</td>\n",
       "      <td>6.293569e+05</td>\n",
       "      <td>1.460678e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>414.3</td>\n",
       "      <td>412.4</td>\n",
       "      <td>416.1</td>\n",
       "      <td>411.2</td>\n",
       "      <td>158427203767</td>\n",
       "      <td>451902</td>\n",
       "      <td>437739524</td>\n",
       "      <td>7.199663e+05</td>\n",
       "      <td>1.689298e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>26515.0</td>\n",
       "      <td>26341.3</td>\n",
       "      <td>26767.3</td>\n",
       "      <td>26183.5</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>863600</td>\n",
       "      <td>559141195</td>\n",
       "      <td>1.724510e+06</td>\n",
       "      <td>1.041701e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>76.87</td>\n",
       "      <td>0.47940</td>\n",
       "      <td>0.062193</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26339.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2023-06-18</td>\n",
       "      <td>26339.7</td>\n",
       "      <td>26515.0</td>\n",
       "      <td>26679.3</td>\n",
       "      <td>26290.6</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>883864</td>\n",
       "      <td>603064705</td>\n",
       "      <td>1.985675e+06</td>\n",
       "      <td>7.946708e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>77.20</td>\n",
       "      <td>0.48699</td>\n",
       "      <td>0.062107</td>\n",
       "      <td>3.8738</td>\n",
       "      <td>1969.45</td>\n",
       "      <td>24.198</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26845.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>2023-06-19</td>\n",
       "      <td>26845.9</td>\n",
       "      <td>26339.7</td>\n",
       "      <td>27029.7</td>\n",
       "      <td>26295.1</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>920552</td>\n",
       "      <td>567091224</td>\n",
       "      <td>1.758290e+06</td>\n",
       "      <td>8.514319e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>77.51</td>\n",
       "      <td>0.49341</td>\n",
       "      <td>0.062429</td>\n",
       "      <td>3.8643</td>\n",
       "      <td>1964.05</td>\n",
       "      <td>24.062</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28307.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>28307.7</td>\n",
       "      <td>26845.9</td>\n",
       "      <td>28393.0</td>\n",
       "      <td>26665.5</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>951926</td>\n",
       "      <td>543133484</td>\n",
       "      <td>1.677592e+06</td>\n",
       "      <td>1.052364e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>80.31</td>\n",
       "      <td>0.49270</td>\n",
       "      <td>0.063108</td>\n",
       "      <td>3.8835</td>\n",
       "      <td>1947.70</td>\n",
       "      <td>23.234</td>\n",
       "      <td>4388.71</td>\n",
       "      <td>33155.0</td>\n",
       "      <td>34356.0</td>\n",
       "      <td>29996.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>2023-06-21</td>\n",
       "      <td>29996.9</td>\n",
       "      <td>28307.7</td>\n",
       "      <td>30769.5</td>\n",
       "      <td>28270.5</td>\n",
       "      <td>52350439455487</td>\n",
       "      <td>920555</td>\n",
       "      <td>483181576</td>\n",
       "      <td>1.611773e+06</td>\n",
       "      <td>1.347976e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>85.12</td>\n",
       "      <td>0.49995</td>\n",
       "      <td>0.065644</td>\n",
       "      <td>3.9135</td>\n",
       "      <td>1944.90</td>\n",
       "      <td>22.810</td>\n",
       "      <td>4365.69</td>\n",
       "      <td>33390.0</td>\n",
       "      <td>34235.0</td>\n",
       "      <td>29890.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2660 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  BTC_close  BTC_open  BTC_high  BTC_low      difficulty   \n",
       "0     2016-03-10      415.8     412.8     417.5    410.3    158427203767  \\\n",
       "1     2016-03-11      419.1     415.8     422.4    415.1    158427203767   \n",
       "2     2016-03-12      410.4     419.1     420.7    407.0    158427203767   \n",
       "3     2016-03-13      412.4     410.4     415.9    409.6    158427203767   \n",
       "4     2016-03-14      414.3     412.4     416.1    411.2    158427203767   \n",
       "...          ...        ...       ...       ...      ...             ...   \n",
       "2655  2023-06-17    26515.0   26341.3   26767.3  26183.5  52350439455487   \n",
       "2656  2023-06-18    26339.7   26515.0   26679.3  26290.6  52350439455487   \n",
       "2657  2023-06-19    26845.9   26339.7   27029.7  26295.1  52350439455487   \n",
       "2658  2023-06-20    28307.7   26845.9   28393.0  26665.5  52350439455487   \n",
       "2659  2023-06-21    29996.9   28307.7   30769.5  28270.5  52350439455487   \n",
       "\n",
       "      addresses_active_count  sum_lock_weight  mean_lock_size_ytes   \n",
       "0                     445273        426654988         6.881532e+05  \\\n",
       "1                     434658        398582424         6.227850e+05   \n",
       "2                     374730        331208848         5.750154e+05   \n",
       "3                     421585        334817852         6.293569e+05   \n",
       "4                     451902        437739524         7.199663e+05   \n",
       "...                      ...              ...                  ...   \n",
       "2655                  863600        559141195         1.724510e+06   \n",
       "2656                  883864        603064705         1.985675e+06   \n",
       "2657                  920552        567091224         1.758290e+06   \n",
       "2658                  951926        543133484         1.677592e+06   \n",
       "2659                  920555        483181576         1.611773e+06   \n",
       "\n",
       "      total_fees_usd  ...    LTC      XRP      DOGE  COPPER     GOLD  SILVER   \n",
       "0       1.731272e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000  \\\n",
       "1       1.710193e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000   \n",
       "2       1.398444e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000   \n",
       "3       1.460678e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000   \n",
       "4       1.689298e+04  ...   0.00  0.00000  0.000000  0.0000     0.00   0.000   \n",
       "...              ...  ...    ...      ...       ...     ...      ...     ...   \n",
       "2655    1.041701e+06  ...  76.87  0.47940  0.062193  0.0000     0.00   0.000   \n",
       "2656    7.946708e+05  ...  77.20  0.48699  0.062107  3.8738  1969.45  24.198   \n",
       "2657    8.514319e+05  ...  77.51  0.49341  0.062429  3.8643  1964.05  24.062   \n",
       "2658    1.052364e+06  ...  80.31  0.49270  0.063108  3.8835  1947.70  23.234   \n",
       "2659    1.347976e+06  ...  85.12  0.49995  0.065644  3.9135  1944.90  22.810   \n",
       "\n",
       "          SPX    JP225      DJI  BTC_close_tomorrow  \n",
       "0        0.00      0.0      0.0               419.1  \n",
       "1        0.00      0.0      0.0               410.4  \n",
       "2        0.00      0.0      0.0               412.4  \n",
       "3        0.00      0.0      0.0               414.3  \n",
       "4        0.00      0.0      0.0               415.1  \n",
       "...       ...      ...      ...                 ...  \n",
       "2655     0.00      0.0      0.0             26339.7  \n",
       "2656     0.00      0.0      0.0             26845.9  \n",
       "2657     0.00      0.0      0.0             28307.7  \n",
       "2658  4388.71  33155.0  34356.0             29996.9  \n",
       "2659  4365.69  33390.0  34235.0             29890.5  \n",
       "\n",
       "[2660 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/lavibula/ML20222.PredictionBitcoin/main/data/data.csv\")\n",
    "# data = pd.read_csv(r\"C:\\Users\\Administrator\\OneDrive - Hanoi University of Science and Technology\\ITE10 - Data Science and AI - HUST\\20222\\ML\\Source_Codes\\ML20222.PredictionBitcoin\\data\\data.csv\")\n",
    "# print(data.info())\n",
    "data = data.sort_values('Date', ascending=True).reset_index(drop=True) # drop=True bỏ 'index' col cũ. \n",
    "\n",
    "# Use BTC_close_tomorrow as y (Target col) of X_today, instead of BTC_close_today\n",
    "data[\"BTC_close_tomorrow\"] = data[\"BTC_close\"].shift(-1)\n",
    "data = data.iloc[:-1] # data = data.drop(data.index[-1])\n",
    "print(data.info())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for pre-train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(['BTC_close_tomorrow', 'Date'], axis=1)\n",
    "y = data['BTC_close_tomorrow']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.15, random_state=42, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Use best parameters for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'bootstrap': True,\n",
    "          'max_depth': None,\n",
    "          'max_features': None,\n",
    "          'min_samples_leaf': 1,\n",
    "          'min_samples_split': 2,\n",
    "          'n_estimators': 300}\n",
    "\n",
    "lgb_params = {'subsample': 1.0,\n",
    " 'random_state': 42,\n",
    " 'objective': 'regression',\n",
    " 'num_leaves': 35,\n",
    " 'min_child_samples': 5,\n",
    " 'metric': 'rmse',\n",
    " 'max_depth': 8,\n",
    " 'max_bin': 500,\n",
    " 'learning_rate': 0.48,\n",
    " 'lambda_l2': 0.2,\n",
    " 'lambda_l1': 0.1,\n",
    " 'boosting_type': 'dart'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ARIMA.__init__() missing 1 required positional argument: 'endog'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score\n\u001b[0;32m      3\u001b[0m models\u001b[39m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     LinearRegression(),\n\u001b[0;32m      5\u001b[0m     SVR(),\n\u001b[0;32m      6\u001b[0m     KNeighborsRegressor(), \n\u001b[0;32m      7\u001b[0m     RandomForestRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrf_params),\n\u001b[0;32m      8\u001b[0m     AdaBoostRegressor(),\n\u001b[0;32m      9\u001b[0m     xgb\u001b[39m.\u001b[39mXGBRegressor(),\n\u001b[0;32m     10\u001b[0m     lgb\u001b[39m.\u001b[39mLGBMRegressor(),\n\u001b[1;32m---> 11\u001b[0m     sm\u001b[39m.\u001b[39;49mtsa\u001b[39m.\u001b[39;49marima\u001b[39m.\u001b[39;49mARIMA(),\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     14\u001b[0m entries \u001b[39m=\u001b[39m []                                           \n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n",
      "\u001b[1;31mTypeError\u001b[0m: ARIMA.__init__() missing 1 required positional argument: 'endog'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "models= [\n",
    "    LinearRegression(),\n",
    "    SVR(),\n",
    "    KNeighborsRegressor(), \n",
    "    RandomForestRegressor(**rf_params),\n",
    "    AdaBoostRegressor(),\n",
    "    xgb.XGBRegressor(),\n",
    "    lgb.LGBMRegressor(),\n",
    "    sm.tsa.arima.ARIMA(),\n",
    "]\n",
    "\n",
    "entries = []                                           \n",
    "for model in models:\n",
    "\n",
    "    rmse_l = []\n",
    "    mape_l = []\n",
    "    r2_score_l = []\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    r2_score_value = round(r2_score(y_test, y_pred_test), 4)\n",
    "    rmse = round(mean_squared_error(y_test, y_pred_test, squared=False), 4)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "    mape = round(mape*100, 4)\n",
    "\n",
    "    r2_score_l.append(r2_score_value)\n",
    "    rmse_l.append(rmse)\n",
    "    mape_l.append(mape)\n",
    "\n",
    "    entries.append([model_name, np.mean(rmse_l), np.mean(mape_l), np.mean(r2_score_l)])\n",
    "\n",
    "model_df = pd.DataFrame(entries, columns=['model_name', 'RMSE', 'MAPE%', 'r2_score'])\n",
    "model_df.sort_values(by=['r2_score'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m total\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([model_df, df2],ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m total\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m], ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "total= pd.concat([model_df, df2],ignore_index=True)\n",
    "total.sort_values(by=['score'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e35676d33e03a9093a17dc7760f2b2aa4960ff6d3c0d7dc06348afdc0ca22c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
