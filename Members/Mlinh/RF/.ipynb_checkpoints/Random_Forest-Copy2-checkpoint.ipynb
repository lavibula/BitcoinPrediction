{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e805ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e626b98e",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "* Handle missing values, duplicated values, outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87e250f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_csv(\"https://raw.githubusercontent.com/lavibula/ML20222.PredictionBitcoin/main/data/data.csv\")\n",
    "total['Date'] = pd.to_datetime(total['Date'])\n",
    "\n",
    "df = total.set_index('Date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "801ccdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45076859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b8e483f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee1c406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe0d20",
   "metadata": {},
   "source": [
    "# Slpit Data (Testing, Training Data Sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ffd5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for index in total.index:\n",
    "    total.loc[index, \"Date\"] = datetime.strptime(str(total.loc[index, \"Date\"])[:10], '%Y-%m-%d').date()\n",
    "\n",
    "Start_day = date(2018,10, 1)\n",
    "Test_day = date(2022,10,1)\n",
    "End_day = date(2023,6,22)\n",
    "\n",
    "\n",
    "# train, test\n",
    "total = total[(total[\"Date\"] >= Start_day) & (total[\"Date\"] <= End_day)].reset_index(drop = True)\n",
    "train_dataset = total[total[\"Date\"] < Test_day].reset_index(drop = True)\n",
    "test_dataset = total[total[\"Date\"] >= Test_day].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1131eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid = train_dataset.drop([\"Date\", \"BTC_close\"], axis=1)[:-1]\n",
    "y_train_valid = train_dataset[\"BTC_close\"][1:].reset_index(drop=True)\n",
    "\n",
    "start_valid = date(2016,3,10)\n",
    "valid_day = date(2022,2,15)\n",
    "end_valid = date(2022,10,1)\n",
    "\n",
    "train_valid = total[(total[\"Date\"] >= start_valid) & (total[\"Date\"] <= end_valid)].reset_index(drop = True)\n",
    "train_val = train_valid[train_valid[\"Date\"] < valid_day].reset_index(drop = True)\n",
    "valid_val = train_valid[train_valid[\"Date\"] >= valid_day].reset_index(drop = True)\n",
    "\n",
    "X_train = train_val.drop([\"Date\", \"BTC_close\"], axis=1)[:-1]\n",
    "y_train = train_val[\"BTC_close\"][1:].reset_index(drop=True)\n",
    "\n",
    "X_valid = valid_val.drop([\"Date\", \"BTC_close\"], axis=1)[:-1]\n",
    "y_valid = valid_val[\"BTC_close\"][1:].reset_index(drop=True)\n",
    "\n",
    "X_test = test_dataset.drop([\"Date\", \"BTC_close\"], axis=1)[:-1]\n",
    "y_test = test_dataset[\"BTC_close\"][1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4648e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = len(test_dataset) / len(total)\n",
    "valid_ratio = len(valid_val) / len(train_valid)\n",
    "\n",
    "print(\"Tỉ lệ test_data/total:\", test_ratio)\n",
    "print(\"Tỉ lệ valid_data/train_valid:\", valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50e6e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training_Valid Features Shape:\", X_train_valid.shape)\n",
    "print(\"Training_Valid Labels Shape:\", y_train_valid.shape)\n",
    "\n",
    "print(\"Train Features Shape:\", X_train.shape)\n",
    "print(\"Train Labels Shape:\", y_train.shape)\n",
    "\n",
    "print(\"Valid Features Shape:\", X_valid.shape)\n",
    "print(\"Valid Labels Shape:\", y_valid.shape)\n",
    "\n",
    "print(\"Testing Features Shape:\", X_test.shape)\n",
    "print(\"Testing Labels Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a77843c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:0.1f} years of data in the training set'.format(X_train_valid.shape[0] / 365.))\n",
    "print('{:0.1f} years of data in the test set'.format(X_test.shape[0] / 365.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cb2ec",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53c11106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn modules\n",
    "import time\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f839a3b0",
   "metadata": {},
   "source": [
    "### Examine the Default Random Forest to Determine Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854b2ae",
   "metadata": {},
   "source": [
    "1. We will use these parameters as a starting point. \n",
    "2. Based on sklearn's random forest documentation, I determined what features to change and what options are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fbc9253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936249a7",
   "metadata": {},
   "source": [
    "### Random Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fc7592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2', 'sqrt', None]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 14, num = 7)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "adbe83b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='neg_mean_absolute_error', \n",
    "                              cv = 3, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6774dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71753d46",
   "metadata": {},
   "source": [
    "#### Top 10 best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eecfd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=10):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "637784af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((len(rf_random.cv_results_[\"params\"])))\n",
    "report(rf_random.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fdef4c",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6034d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "\n",
    "def ACC(model, X_test, y_test, X_train_valid, y_train_valid):    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train_valid)\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print(30*'*')\n",
    "    print(\"Test accuracy for train set\")\n",
    "    #RMSE\n",
    "    print(\"Root Mean Square Error (RMSE):\", np.sqrt(mean_squared_error(y_train_valid, y_train_pred)))\n",
    "\n",
    "    #MAPE\n",
    "    print(\"Mean Absolute Percentage Error (MAPE):\", mean_absolute_percentage_error(y_train_valid,y_train_pred))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(\"Test accuracy for test set\")\n",
    "    #RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Root Mean Square Error (RMSE):\", rmse)\n",
    "\n",
    "    #MAPE\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    print(\" Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "    print()\n",
    "    \n",
    "    sns.displot(y_test - y_pred, kde=True)\n",
    "    plt.xlabel('y_test - y_pred')\n",
    "    plt.ylabel('count')\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    sns.scatterplot(x=y_test, y=y_pred)\n",
    "    plt.xlabel('y_test')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "    ax.plot(y_test, color = 'red', label=\"Bitcoin Price\")\n",
    "    ax.plot(y_pred, color = 'green', label=\"Predicted Bitcoin Price\", linestyle=\"dashed\")\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))  # .3f\n",
    "    plt.title(\"Random Forest Regression for Period 2\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    \n",
    "def AUC(model, X_valid, y_valid, X_train, y_train):    \n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print(30*'*')\n",
    "    print(\"Test accuracy for train set\")\n",
    "    #RMSE\n",
    "    print(\"Root Mean Square Error (RMSE):\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "    #MAPE\n",
    "    print(\"Mean Absolute Percentage Error (MAPE):\", mean_absolute_percentage_error(y_train,y_train_pred))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(\"Test accuracy for test set\")\n",
    "    #RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "    print(\"Root Mean Square Error (RMSE):\", rmse)\n",
    "\n",
    "    #MAPE\n",
    "    mape = mean_absolute_percentage_error(y_valid, y_pred)\n",
    "    print(\" Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "    print()\n",
    "    \n",
    "    sns.displot(y_valid - y_pred, kde=True)\n",
    "    plt.xlabel('y_test - y_pred')\n",
    "    plt.ylabel('count')\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    sns.scatterplot(x=y_valid, y=y_pred)\n",
    "    plt.xlabel('y_test')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "    ax.plot(y_valid, color = 'red', label=\"Bitcoin Price\")\n",
    "    ax.plot(y_pred, color = 'green', label=\"Predicted Bitcoin Price\", linestyle=\"dashed\")\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))  # .3f\n",
    "    plt.title(\"Random Forest Regression for Period 2\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "\n",
    "    train_valid['Date'] = pd.to_datetime(train_valid['Date'][:-1])\n",
    "    test_dataset['Date'] = pd.to_datetime(test_dataset['Date'][:len(y_valid)])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(25, 5))\n",
    "\n",
    "    ax.plot(train_valid['Date'][:-1], train_valid['BTC_close'][1:], color='blue', label=\"Training Data\")\n",
    "    ax.plot(valid_val['Date'][:-1], y_valid, color='orange', label=\"Validation Data\")\n",
    "    ax.plot(valid_val['Date'][:-1], y_pred, color='green', label=\"Predicted Bitcoin Price\", linestyle=\"dashed\")\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x)))) # Format the y-axis\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2283329",
   "metadata": {},
   "source": [
    "### Evaluate the Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea626d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = AUC(base_model, X_valid, y_valid, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e3386",
   "metadata": {},
   "source": [
    "### Evaluate the Best Random Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f62b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = AUC(best_random, X_valid, y_valid, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ae392",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c157170",
   "metadata": {},
   "source": [
    "We can now perform grid search building on the result from the random search. We will test a range of hyperparameters around the best values returned by random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "860c5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [6,8,10, None],\n",
    "    'max_features': [None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "790d141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d6deaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a470a10",
   "metadata": {},
   "source": [
    "#### Evaluate the Best Model from Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e57ae471",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = AUC(best_grid, X_valid, y_valid, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cef4f2",
   "metadata": {},
   "source": [
    "## Final Model & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "afedfe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "print('Final Model Parameters:\\n')\n",
    "pprint(final_model.get_params())\n",
    "print('\\n')\n",
    "grid_final_accuracy = ACC(final_model, X_test, y_test, X_train_valid, y_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d882dce",
   "metadata": {},
   "source": [
    "## Comparison of All Improvement Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3714394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7b228ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate run time and prediction accuracy\n",
    "def evaluate_model(model, X_train_valid, y_train_valid, X_valid, y_valid, X_test, y_test):\n",
    "    n_features = X_train.shape[1]\n",
    "    n_trees = model.get_params()['n_estimators']\n",
    "    \n",
    "    # Train and predict 10 times to evaluate time and accuracy\n",
    "    predictions_test = []\n",
    "    predictions_train_valid = []\n",
    "    predictions_valid = []\n",
    "    run_times = []\n",
    "    for _ in range(10):\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions_valid.append(model.predict(X_valid))\n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "    \n",
    "    for _ in range(10):\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_valid, y_train_valid)\n",
    "        predictions_train_valid.append(model.predict(X_train_valid))\n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "        predictions_test.append(model.predict(X_test))\n",
    "    \n",
    "    # Run time and predictions need to be averaged\n",
    "    run_time = np.mean(run_times)\n",
    "    predictions_test = np.mean(np.array(predictions_test), axis = 0)\n",
    "    predictions_valid = np.mean(np.array(predictions_valid), axis = 0)\n",
    "    predictions_train_valid = np.mean(np.array(predictions_train_valid), axis = 0)\n",
    "   \n",
    "\n",
    "    print('Model Performance')\n",
    "    print(30*'*')\n",
    "    print(\"Test accuracy for train_valid set\")\n",
    "    #RMSE\n",
    "    rmse_train_valid = np.sqrt(mean_squared_error(y_train_valid, predictions_train_valid))\n",
    "    print(\"Root Mean Square Error (RMSE):\", rmse_train_valid)\n",
    "\n",
    "    #MAPE\n",
    "    mape_train_valid = mean_absolute_percentage_error(y_train_valid, predictions_train_valid)\n",
    "    print(\"Mean Absolute Percentage Error (MAPE):\", mape_train_valid)\n",
    "    print()\n",
    "    \n",
    "    print(\"Test accuracy for valid set\")\n",
    "    #RMSE\n",
    "    rmse_valid = np.sqrt(mean_squared_error(y_valid, predictions_valid))\n",
    "    print(\"Root Mean Square Error (RMSE):\", rmse_valid)\n",
    "\n",
    "    #MAPE\n",
    "    mape_valid = mean_absolute_percentage_error(y_valid, predictions_valid)\n",
    "    print(\"Mean Absolute Percentage Error (MAPE):\", mape_valid)\n",
    "    print()\n",
    "\n",
    "    print(\"Test accuracy for test set\")\n",
    "    #RMSE\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, predictions_test))\n",
    "    print(\"Root Mean Square Error (RMSE):\", rmse_test)\n",
    "\n",
    "    #MAPE\n",
    "    mape_test = mean_absolute_percentage_error(y_test, predictions_test)\n",
    "    print(\" Mean Absolute Percentage Error (MAPE):\", mape_test)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # Return results in a dictionary\n",
    "    results = {'time': run_time, 'RMSE_train_valid': rmse_train_valid, 'RMSE_valid': rmse_valid, 'RMSE_test': rmse_test, 'MAPE_train_valid' : mape_train_valid, 'MAPE_valid': mape_valid, 'MAPE_test': mape_test, 'n_trees': n_trees, 'n_features': n_features}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9cbdd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b223e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results = evaluate_model(base_model, X_train_valid, y_train_valid, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3eab4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results['model'] = 'base_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62a4abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e567588",
   "metadata": {},
   "source": [
    "#### Random Search Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "191000fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results = evaluate_model(best_random, X_train_valid, y_train_valid, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "adfa8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results['model'] = 'best_random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20c20205",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3d501",
   "metadata": {},
   "source": [
    "#### First Grid Search Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e6fc3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_grid_results = evaluate_model(best_grid, X_train_valid, y_train_valid, X_valid, y_valid, X_test, y_test)\n",
    "first_grid_results['model'] = 'first_grid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6cce7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d49980",
   "metadata": {},
   "source": [
    "#### Second Grid Search Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "40f54ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_grid_results = evaluate_model(best_grid, X_train_valid, y_train_valid, X_valid, y_valid, X_test, y_test)\n",
    "second_grid_results['model'] = 'second_grid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e2743e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71043b4f",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee7f6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = {\n",
    "    'RMSE_train_valid': [],\n",
    "    'RMSE_valid': [],\n",
    "    'RMSE_test': [],\n",
    "    'MAPE_train_valid': [],\n",
    "    'MAPE_valid': [],\n",
    "    'MAPE_test': [],\n",
    "    'model': [],\n",
    "    'n_features': [],\n",
    "    'n_trees': [],\n",
    "    'time': []}\n",
    "for model in [base_results, random_results, first_grid_results, second_grid_results]:\n",
    "    comparison['RMSE_train_valid'].append(round(model['RMSE_train_valid'], 3))\n",
    "    comparison['RMSE_valid'].append(round(model['RMSE_valid'], 3))\n",
    "    comparison['RMSE_test'].append(round(model['RMSE_test'], 3))\n",
    "    comparison['MAPE_train_valid'].append(round(model['MAPE_train_valid'], 3))\n",
    "    comparison['MAPE_valid'].append(round(model['MAPE_valid'], 3))\n",
    "    comparison['MAPE_test'].append(round(model['MAPE_test'], 3))\n",
    "    comparison['model'].append(model['model'])\n",
    "    comparison['n_features'].append(model['n_features'])\n",
    "    comparison['n_trees'].append(int(model['n_trees']))\n",
    "    comparison['time'].append(round(model['time'], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4192ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame.from_dict(comparison, orient = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c722a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison[['model', 'RMSE_train_valid', 'RMSE_valid', 'RMSE_test', 'MAPE_train_valid', 'MAPE_valid', 'MAPE_test', 'n_features', 'n_trees', 'time']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e3fb5",
   "metadata": {},
   "source": [
    "## Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e3f10163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "87a760f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues = list(range(len(comparison)))\n",
    "plt.subplots(1, 2, figsize=(10, 6))\n",
    "plt.subplot(121)\n",
    "plt.bar(xvalues, comparison['MAPE_test'], color = 'g', edgecolor = 'k', linewidth = 1.8)\n",
    "plt.xticks(xvalues, comparison['model'], rotation = 45, fontsize = 12)\n",
    "plt.ylim(ymin = 0, ymax = 0.1)\n",
    "plt.xlabel('model'); plt.ylabel('MAPE_test'); plt.title('MAPE Comparison');\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.bar(xvalues, comparison['RMSE_test'], color = 'r', edgecolor = 'k', linewidth = 1.8)\n",
    "plt.xticks(xvalues, comparison['model'], rotation = 45)\n",
    "plt.ylim(ymin = 3.5, ymax = 1000)\n",
    "plt.xlabel('model'); plt.ylabel('Error (deg)'); plt.title('Error Comparison');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e72d21",
   "metadata": {},
   "source": [
    "## Importance Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7d8f4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns\n",
    "# Get numerical feature importances\n",
    "importances = list(final_model.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 4)) for feature, importance in zip(features, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "for pair in feature_importances:\n",
    "    print('Variable: {:20} Importance: {}'.format(*pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7b7f6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, features, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "44e2ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features sorted from most to least important\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "# Draw line at 90% of importance retained\n",
    "plt.hlines(y = 0.9, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "573a8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of features for cumulative importance of 90%\n",
    "# Add 1 because Python is zero-indexed\n",
    "num = np.where(cumulative_importances > 0.9)[0][0] + 1\n",
    "print('Number of features for 90% importance:', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9257cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the names of the most important features\n",
    "important_feature_names = [feature[0] for feature in feature_importances[0:num]]\n",
    "print(important_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9a69984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to export the tree \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Write the decision tree as a dot file\n",
    "visual_tree = final_model.estimators_[12]\n",
    "export_graphviz(visual_tree, out_file = '/Users/ibulmnie/Documents/GitHub/ML20222.PredictionBitcoin/ML20222.PredictionBitcoin/Members/Mlinh/images/best_tree_period2.dot', feature_names = X_train.columns, \n",
    "                precision = 2, filled = True, rounded = True, max_depth = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "32049c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pydot for converting to an image file\n",
    "import pydot\n",
    "\n",
    "# Import the dot file to a graph and then convert to a png\n",
    "(graph, ) = pydot.graph_from_dot_file('/Users/ibulmnie/Documents/GitHub/ML20222.PredictionBitcoin/ML20222.PredictionBitcoin/Members/Mlinh/images/best_tree_period2.dot')\n",
    "graph.write_png('/Users/ibulmnie/Documents/GitHub/ML20222.PredictionBitcoin/ML20222.PredictionBitcoin/Members/Mlinh/images/best_tree_period2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0161a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e6d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e865af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9df14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
