{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e805ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e626b98e",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "* Handle missing values, duplicated values, outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87e250f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_csv(\"https://raw.githubusercontent.com/lavibula/ML20222.PredictionBitcoin/main/data/saved_data.csv\")\n",
    "total['Date'] = pd.to_datetime(total['Date'])\n",
    "\n",
    "df = total.set_index('Date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "801ccdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45076859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b8e483f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee1c406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe0d20",
   "metadata": {},
   "source": [
    "# Slpit Data (Testing, Training Data Sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ffd5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for index in total.index:\n",
    "    total.loc[index, \"Date\"] = datetime.strptime(str(total.loc[index, \"Date\"])[:10], '%Y-%m-%d').date()\n",
    "\n",
    "Start_day = date(2015, 12, 30)\n",
    "\n",
    "Test_day = date(2018,3,10)\n",
    "\n",
    "End_day = date(2018,9,30)\n",
    "\n",
    "# train, test\n",
    "total = total[(total[\"Date\"] >= Start_day) & (total[\"Date\"] <= End_day)].reset_index(drop = True)\n",
    "train_dataset = total[total[\"Date\"] < Test_day].reset_index(drop = True)\n",
    "test_dataset = total[total[\"Date\"] >= Test_day].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1131eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop([\"Date\"], axis=1)[:-1]\n",
    "y_train = train_dataset[\"BTC_close\"][1:].reset_index(drop=True)\n",
    "\n",
    "X_test = test_dataset.drop([\"Date\"], axis=1)[:-1]\n",
    "y_test = test_dataset[\"BTC_close\"][1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4648e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = len(test_dataset) / len(total)\n",
    "\n",
    "print(\"Tỉ lệ test_data/total:\", test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50e6e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kích thước X_train:\", X_train.shape)\n",
    "print(\"Kích thước y_train:\", y_train.shape)\n",
    "print(\"Kích thước X_test:\", X_test.shape)\n",
    "print(\"Kích thước y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cb2ec",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53c11106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn modules\n",
    "import time\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbc9253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936249a7",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6774dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1eda9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.displot(y_test - y_pred, kde=True)\n",
    "plt.xlabel('y_test - y_pred')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e45d6d8",
   "metadata": {},
   "source": [
    "The distribution of my data tends to curve up on the right side, which means there are some values that are higher than predicted. This can happen when the data has outliers or when the distribution of the data does not follow a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31f299ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cfa1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "def AUC(y_test, y_pred):\n",
    "    count = 0\n",
    "    for i in range(1,len(y_test)):\n",
    "        if (y_test[i] - y_test[i-1]) * (y_pred[i] - y_pred[i-1]) > 0:\n",
    "            count += 1\n",
    "    return count/(len(y_test)-1)\n",
    "print(\"Test accuracy for train set\")\n",
    "#RMSE\n",
    "print(\"Root Mean Square Error (RMSE):\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "#MAPE\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mean_absolute_percentage_error(y_train,y_train_pred))\n",
    "print()\n",
    "\n",
    "print(\"Test accuracy for test set\")\n",
    "#RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Square Error (RMSE):\", rmse)\n",
    "\n",
    "#MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\" Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "print()\n",
    "AUC = AUC(y_test, y_pred)\n",
    "#AUC\n",
    "print(\"AUC test:\", AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4327e2a7",
   "metadata": {},
   "source": [
    "## Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea27a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of values for n_estimators\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=1000, num=10)]\n",
    "max_depth = [int(x) for x in np.linspace(2, 20, num = 10)]\n",
    "criterion = ['squared_error']\n",
    "max_features = [None]\n",
    "min_samples_split = [2]\n",
    "min_samples_leaf = [1]\n",
    "bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "'max_features': max_features,\n",
    "\n",
    "'criterion': criterion,\n",
    "            \n",
    "''\n",
    "\n",
    "'max_depth': max_depth,\n",
    "\n",
    "'min_samples_split': min_samples_split,\n",
    "              \n",
    "'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "'bootstrap': bootstrap}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada33fa",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fa09d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Create the RandomizedSearchCV object with early stopping\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions = param_grid, scoring=scoring,\n",
    "                                   cv=5, refit=True, verbose=2,\n",
    "                                   n_jobs = -1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64370475",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print ('Best Parameters: ', rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d69eb3",
   "metadata": {},
   "source": [
    "## Using the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29616102",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46cc76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "randmf = RandomForestRegressor(**rf_random.best_params_) \n",
    "randmf.fit(X_train, y_train) \n",
    "\n",
    "end_time = time.time()\n",
    "all_rand_run_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a5d50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred_rand = randmf.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(5, 7))\n",
    "\n",
    "sns.kdeplot(y_test, color=\"r\", label=\"Actual Value\")\n",
    "sns.kdeplot(y_pred_rand, color=\"b\", label=\"Fitted Values\")\n",
    "\n",
    "plt.title('Actual vs Fitted Values for Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3952d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.displot(y_test - y_pred_rand, kde=True)\n",
    "plt.xlabel('y_test - y_pred_rand')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ee1e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_test, y=y_pred_rand)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d76c3",
   "metadata": {},
   "source": [
    "Mostly linearly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf89c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "y_train_rand_pred = randmf.predict(X_train)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "def AUC(y_test, y_pred):\n",
    "    count = 0\n",
    "    for i in range(1,len(y_test)):\n",
    "        if (y_test[i] - y_test[i-1]) * (y_pred[i] - y_pred[i-1]) > 0:\n",
    "            count += 1\n",
    "    return count/(len(y_test)-1)\n",
    "print(\"Test accuracy for train set\")\n",
    "#RMSE\n",
    "print(\"Root Mean Square Error (RMSE):\", np.sqrt(mean_squared_error(y_train, y_train_rand_pred)))\n",
    "\n",
    "#MAPE\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mean_absolute_percentage_error(y_train,y_train_rand_pred))\n",
    "print()\n",
    "\n",
    "print(\"Test accuracy for test set\")\n",
    "#RMSE\n",
    "rmse_all_rand = np.sqrt(mean_squared_error(y_test, y_pred_rand))\n",
    "print(\"Root Mean Square Error (RMSE):\", rmse_all_rand)\n",
    "\n",
    "#MAPE\n",
    "mape_all_rand = mean_absolute_percentage_error(y_test, y_pred_rand)\n",
    "print(\" Mean Absolute Percentage Error (MAPE):\", mape_all_rand)\n",
    "print()\n",
    "AUC_all_rand = AUC(y_test, y_pred_rand)\n",
    "#AUC\n",
    "print(\"AUC test:\", AUC_all_rand)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd44ca",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb77d5",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2d9528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rand = X_train.columns\n",
    "# Get numerical feature importances\n",
    "importances_rand = list(randmf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances_rand = [(feature, round(importance, 4)) for feature, importance in zip(features_rand, importances_rand)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances_rand = sorted(feature_importances_rand, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "for pair in feature_importances_rand:\n",
    "    print('Variable: {:20} Importance: {}'.format(*pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b907a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances_rand)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances_rand, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, features_rand, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bcc8edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features sorted from most to least important\n",
    "sorted_importances_rand = [importance[1] for importance in feature_importances_rand]\n",
    "sorted_features_rand = [importance[0] for importance in feature_importances_rand]\n",
    "# Cumulative importances\n",
    "cumulative_importances_rand = np.cumsum(sorted_importances_rand)\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances_rand, 'g-')\n",
    "# Draw line at 90% of importance retained\n",
    "plt.hlines(y = 0.9, xmin=0, xmax=len(sorted_importances_rand), color = 'r', linestyles = 'dashed')\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features_rand, rotation = 'vertical')\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8abc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of features for cumulative importance of 90%\n",
    "# Add 1 because Python is zero-indexed\n",
    "num_rand = np.where(cumulative_importances_rand > 0.9)[0][0] + 1\n",
    "print('Number of features for 90% importance:', num_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e87a9c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the names of the most important features\n",
    "important_feature_names_rand = [feature[0] for feature in feature_importances_rand[0:num_rand]]\n",
    "print(important_feature_names_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4163b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_rand = X_train[important_feature_names_rand]\n",
    "test_data_rand = X_test[important_feature_names_rand]\n",
    "# Sanity check on operations\n",
    "print('Important train features shape:', train_data_rand.shape)\n",
    "print('Important test features shape:', test_data_rand.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e949a98",
   "metadata": {},
   "source": [
    "#### Training and Evaluating on Important Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716d553",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "976818dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train the expanded model on only the important features\n",
    "randmf.fit(train_data_rand, y_train);\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions_rand = randmf.predict(test_data_rand)\n",
    "\n",
    "end_time = time.time()\n",
    "reduce_rand_run_time = end_time - start_time\n",
    "\n",
    "#RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_reduce_rand = np.sqrt(mean_squared_error(y_test, predictions_rand))\n",
    "print(\"RMSE:\", rmse_reduce_rand)\n",
    "print()\n",
    "\n",
    "#MAPE\n",
    "mape_reduce_rand = np.average(np.abs((y_test - predictions_rand) / y_test))\n",
    "print(\"MAPE:\", mape_reduce_rand)\n",
    "print()\n",
    "\n",
    "AUC_reduce_rand = AUC(np.array(y_test), predictions_rand)\n",
    "print(\"AUC test:\", AUC_reduce_rand )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388cc6b6",
   "metadata": {},
   "source": [
    "## Summary statistical table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ed44c",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "076c1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_rand(AUC_all_rand, rmse_all_rand, mape_all_rand, all_rand_run_time, \n",
    "                       AUC_reduce_rand, rmse_reduce_rand, mape_reduce_rand, reduce_rand_run_time):\n",
    "    headers = ['Type', 'Number of Features','Accuracy', 'RMSE', 'MAPE', 'Run Time (s)']\n",
    "    all_results = [['All', len(importances_rand), AUC_all_rand, rmse_all_rand, mape_all_rand, all_rand_run_time],\n",
    "                   ['Reduce', len(important_feature_names_rand), AUC_reduce_rand, rmse_reduce_rand, mape_reduce_rand, reduce_rand_run_time]]\n",
    "    \n",
    "    # Calculate the maximum width for each column\n",
    "    col_widths = [max(len(str(row[i])) for row in all_results + [headers]) for i in range(len(headers))]\n",
    "\n",
    "    # Print table headers\n",
    "    header_format = '  '.join(f\"{{:<{width}}}\" for width in col_widths)\n",
    "    print(header_format.format(*headers))\n",
    "\n",
    "    # Print separator row\n",
    "    separator = '-' * (sum(col_widths) + 3 * (len(col_widths) - 1))\n",
    "    print(separator)\n",
    "\n",
    "    # Print table rows\n",
    "    row_format = '  '.join(f\"{{:<{width}}}\" for width in col_widths)\n",
    "    for result in all_results:\n",
    "        index, num_features, AUC, rmse, mape, run_time = result\n",
    "        print(row_format.format(index, num_features, AUC, rmse, mape, run_time))\n",
    "        \n",
    "print_results_rand(AUC_all_rand, rmse_all_rand, mape_all_rand, all_rand_run_time, \n",
    "                       AUC_reduce_rand, rmse_reduce_rand, mape_reduce_rand, reduce_rand_run_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571c0a6",
   "metadata": {},
   "source": [
    "# Graph Predicted Values with Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9781f6b",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5b132ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hien thi ket qua du doan\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "ax.plot(y_test, color = 'red', label=\"Bitcoin Price\")\n",
    "ax.plot(y_pred_rand, color = 'green', label=\"Predicted Bitcoin Price\", linestyle=\"dashed\")\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))  # .3f\n",
    "plt.title(\"Random Forest Regression for Period 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8f6c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 5))\n",
    "\n",
    "ax.plot(total['Date'], total['BTC_close'], color='red', label=\"Bitcoin Price\")\n",
    "ax.plot(total['Date'][-len(y_train):], y_train, color='blue', label=\"Training Data\")\n",
    "ax.plot(total['Date'][:len(y_test)], y_test, color='orange', label=\"Test Data\")\n",
    "ax.plot(total['Date'][:len(y_pred)], y_pred_rand, color='green', label=\"Predicted Bitcoin Price\", linestyle=\"dashed\")\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x)))) # Định dạng đường trục y\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8ef88",
   "metadata": {},
   "source": [
    "## Comparing randomized search for hyperparameter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd085606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=10):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b70d7",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ac9004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((len(rf_random.cv_results_[\"params\"])))\n",
    "report(rf_random.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "43e54350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the parameters used in the RandomForestRegressor model\n",
    "print(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020afafe",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "| Metric     | DEFAULT | TUNING | NORMAL |\n",
    "| ---------- | ------- | ------ | ------ |\n",
    "| RMSE(min)  | 80.57   | 84.7   | 79.5   |\n",
    "| MAPE%(min) | 0.009   | 0.009  | 0.009  |\n",
    "| AUC/DA ~ 1 | 0.88    | 0.90   | 0.90   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce29b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default\n",
    "RandomForestRegressor(bootstrap = True, ccp_alpha = 0.0, criterion = 'squared_error' , max_depth = None, \n",
    "                      max_features = 1.0, max_leaf_nodes = None, max_samples = None, \n",
    "                      min_impurity_decrease = 0.0, min_samples_leaf = 1, min_samples_split = 2, \n",
    "                      min_weight_fraction_leaf = 0.0, n_estimators = 100, n_jobs = None, oob_score = False,\n",
    "                      random_state = None, verbose = 0, warm_start = False)\n",
    "\n",
    "#or you can write shorter\n",
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0413d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning & Normalization\n",
    "RandomForestRegressor(n_estimators = 600, min_samples_split = 2, min_samples_leaf = 1, \n",
    "                      max_features = None, max_depth = 10, criterion = 'squared_error', bootstrap = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
