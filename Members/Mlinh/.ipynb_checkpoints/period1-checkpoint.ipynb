{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e805ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e626b98e",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "* Handle missing values, duplicated values, outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e250f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_csv(\"/Users/ibulmnie/Documents/GitHub/ML20222.PredictionBitcoin/data/saved_data.csv\")\n",
    "total['Date'] = pd.to_datetime(total['Date'])\n",
    "\n",
    "df = total.set_index('Date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801ccdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45076859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8e483f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1c406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe0d20",
   "metadata": {},
   "source": [
    "# Slpit Data (Testing, Training Data Sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ffd5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for index in total.index:\n",
    "    total.loc[index, \"Date\"] = datetime.strptime(str(total.loc[index, \"Date\"])[:10], '%Y-%m-%d').date()\n",
    "\n",
    "Start_day = date(2015, 12, 30)\n",
    "Test_day = date(2018,4,1)\n",
    "#chon ra 20-25% data trong giai doan 1\n",
    "End_day = date(2018,9,30)\n",
    "# train, test\n",
    "total = total[(total[\"Date\"] >= Start_day) & (total[\"Date\"] <= End_day)].reset_index(drop = True)\n",
    "train_dataset = total[total[\"Date\"] < Test_day].reset_index(drop = True)\n",
    "test_dataset = total[total[\"Date\"] >= Test_day].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1131eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop([\"Date\"], axis=1)[:-1]\n",
    "y_train = train_dataset[\"BTC_close\"][1:].reset_index(drop=True)\n",
    "\n",
    "X_test = test_dataset.drop([\"Date\"], axis=1)[:-1]\n",
    "y_test = test_dataset[\"BTC_close\"][1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e6e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kích thước X_train:\", X_train.shape)\n",
    "print(\"Kích thước y_train:\", y_train.shape)\n",
    "print(\"Kích thước X_test:\", X_test.shape)\n",
    "print(\"Kích thước y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cb2ec",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c11106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn modules\n",
    "import time\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3f4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of values for n_estimators\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=1000, num=100)]\n",
    "max_depth = [int(x) for x in np.linspace(2, 20, num = 10)]\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "'max_features': max_features,\n",
    "\n",
    "'max_depth': max_depth,\n",
    "\n",
    "'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba925a",
   "metadata": {},
   "source": [
    "# Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe96796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14995574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(estimator = rf,param_distributions = random_grid,\n",
    "               n_iter = 500, cv = 5, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79708f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Parameters: ', rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21322fee",
   "metadata": {},
   "source": [
    "## Using the best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14061652",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "randmf = RandomForestRegressor(**rf_random.best_params_) \n",
    "randmf.fit( X_train, y_train) \n",
    "\n",
    "end_time = time.time()\n",
    "all_run_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d56c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = randmf.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(5, 7))\n",
    "\n",
    "sns.kdeplot(y_test, color=\"r\", label=\"Actual Value\")\n",
    "sns.kdeplot(y_pred, color=\"b\", label=\"Fitted Values\")\n",
    "\n",
    "plt.title('Actual vs Fitted Values for Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0670e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "y_train_pred = randmf.predict(X_train)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "def AUC(y_test, y_pred):\n",
    "    count = 0\n",
    "    for i in range(1,len(y_test)):\n",
    "        if (y_test[i] - y_test[i-1]) * (y_pred[i] - y_pred[i-1]) > 0:\n",
    "            count += 1\n",
    "    return count/(len(y_test)-1)\n",
    "print(\"Test accuracy for train set\")\n",
    "#RMSE\n",
    "print(\"Root Mean Square Error (RMSE):\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "#MAPE\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mean_absolute_percentage_error(y_train,y_train_pred))\n",
    "print()\n",
    "\n",
    "print(\"Test accuracy for test set\")\n",
    "#RMSE\n",
    "rmse_all = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Square Error (RMSE):\", rmse_all)\n",
    "\n",
    "#MAPE\n",
    "mape_all = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\" Mean Absolute Percentage Error (MAPE):\", mape_all)\n",
    "print()\n",
    "AUC_all = AUC(y_test, y_pred)\n",
    "#AUC\n",
    "print(\"AUC test:\", AUC_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f686cc",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns\n",
    "# Get numerical feature importances\n",
    "importances = list(randmf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(features, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, features, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a1b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features sorted from most to least important\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y = 0.95, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of features for cumulative importance of 95%\n",
    "# Add 1 because Python is zero-indexed\n",
    "num = np.where(cumulative_importances > 0.95)[0][0] + 1\n",
    "print('Number of features for 95% importance:', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the names of the most important features\n",
    "important_feature_names = [feature[0] for feature in feature_importances[0:num]]\n",
    "print(important_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdf018",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train[important_feature_names]\n",
    "test_data = X_test[important_feature_names]\n",
    "# Sanity check on operations\n",
    "print('Important train features shape:', train_data.shape)\n",
    "print('Important test features shape:', test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88fab1f",
   "metadata": {},
   "source": [
    "#### Training and Evaluating on Important Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train the expanded model on only the important features\n",
    "randmf.fit(train_data, y_train);\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = randmf.predict(test_data)\n",
    "\n",
    "end_time = time.time()\n",
    "reduce_run_time = end_time - start_time\n",
    "\n",
    "#RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_reduce = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE:\", rmse_reduce)\n",
    "print()\n",
    "\n",
    "#MAPE\n",
    "mape_reduce = np.average(np.abs((y_test - predictions) / y_test))\n",
    "print(\"MAPE:\", mape_reduce)\n",
    "print()\n",
    "\n",
    "AUC_reduce = AUC(np.array(y_test), predictions)\n",
    "print(\"AUC test:\", AUC_reduce )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff150160",
   "metadata": {},
   "source": [
    "#### Normalization with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4293b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize the features using MinMaxScaler for the training dataset\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized_all = scaler.fit_transform(X_train)\n",
    "\n",
    "# Normalize the features using the same scaler for the testing dataset\n",
    "X_test_normalized_all = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor = RandomForestRegressor(**rf_random.best_params_)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_regressor.fit(X_train_normalized_all, y_train)\n",
    "\n",
    "y_pred_norma_all = rf_regressor.predict(X_test_normalized_all)\n",
    "\n",
    "end_time = time.time()\n",
    "normal_all_run_time = end_time - start_time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_normal_all = np.sqrt(mean_squared_error(y_test, y_pred_norma_all))\n",
    "print(\"RMSE:\", rmse_normal_all)\n",
    "print()\n",
    "\n",
    "#MAPE\n",
    "mape_normal_all = np.average(np.abs((y_test - y_pred_norma_all) / y_test))\n",
    "print(\"MAPE:\", mape_normal_all)\n",
    "print()\n",
    "\n",
    "AUC_normal_all = AUC(np.array(y_test), y_pred_norma_all)\n",
    "print(\"AUC test:\", AUC_normal_all )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9af01d",
   "metadata": {},
   "source": [
    "#### Normalization with Importance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize the features using MinMaxScaler for the training dataset\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized_reduce = scaler.fit_transform(train_data)\n",
    "\n",
    "# Normalize the features using the same scaler for the testing dataset\n",
    "X_test_normalized_reduce = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4279a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor = RandomForestRegressor(**rf_random.best_params_)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_regressor.fit(X_train_normalized_reduce, y_train)\n",
    "\n",
    "y_pred_norma_reduce = rf_regressor.predict(X_test_normalized_reduce)\n",
    "\n",
    "end_time = time.time()\n",
    "normal_reduce_run_time = end_time - start_time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_normal_reduce = np.sqrt(mean_squared_error(y_test, y_pred_norma_reduce))\n",
    "print(\"RMSE:\", rmse_normal_reduce)\n",
    "print()\n",
    "\n",
    "#MAPE\n",
    "mape_normal_reduce = np.average(np.abs((y_test - y_pred_norma_reduce) / y_test))\n",
    "print(\"MAPE:\", mape_normal_reduce)\n",
    "print()\n",
    "\n",
    "AUC_normal_reduce = AUC(np.array(y_test), y_pred_norma_reduce)\n",
    "print(\"AUC test:\", AUC_normal_reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1648c5",
   "metadata": {},
   "source": [
    "## Summary statistical table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(AUC_all, rmse_all, mape_all, all_run_time, AUC_reduce, rmse_reduce, mape_reduce, reduce_run_time, \n",
    "                  AUC_normal_all, rmse_normal_all, mape_normal_all, normal_all_run_time,\n",
    "                 AUC_normal_reduce, rmse_normal_reduce, mape_normal_reduce, normal_reduce_run_time):\n",
    "    headers = ['Type', 'Number of Features','Accuracy', 'RMSE', 'MAPE', 'Run Time (s)']\n",
    "    all_results = [['All', len(importances), AUC_all, rmse_all, mape_all, all_run_time],\n",
    "                   ['Reduce', len(important_feature_names), AUC_reduce, rmse_reduce, mape_reduce, reduce_run_time],\n",
    "                   ['Normalization - All', len(importances), AUC_normal_all, rmse_normal_all, mape_normal_all, normal_all_run_time],\n",
    "                  ['Normalization - Reduce', len(important_feature_names), AUC_normal_reduce, rmse_normal_reduce, mape_normal_reduce, normal_reduce_run_time]]\n",
    "\n",
    "    # Calculate the maximum width for each column\n",
    "    col_widths = [max(len(str(row[i])) for row in all_results + [headers]) for i in range(len(headers))]\n",
    "\n",
    "    # Print table headers\n",
    "    header_format = '  '.join(f\"{{:<{width}}}\" for width in col_widths)\n",
    "    print(header_format.format(*headers))\n",
    "\n",
    "    # Print separator row\n",
    "    separator = '-' * (sum(col_widths) + 3 * (len(col_widths) - 1))\n",
    "    print(separator)\n",
    "\n",
    "    # Print table rows\n",
    "    row_format = '  '.join(f\"{{:<{width}}}\" for width in col_widths)\n",
    "    for result in all_results:\n",
    "        index, num_features, AUC, rmse, mape, run_time = result\n",
    "        print(row_format.format(index, num_features, AUC, rmse, mape, run_time))\n",
    "        \n",
    "print_results(AUC_all, rmse_all, mape_all, all_run_time, AUC_reduce, rmse_reduce, mape_reduce, reduce_run_time,\n",
    "             AUC_normal_all, rmse_normal_all, mape_normal_all, normal_all_run_time,\n",
    "             AUC_normal_reduce, rmse_normal_reduce, mape_normal_reduce, normal_reduce_run_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bf7e8",
   "metadata": {},
   "source": [
    "# Graph Predicted Values with Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77357bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#hien thi ket qua du doan\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "ax.plot(y_test, color = 'red', label=\"Bitcoin Price\")\n",
    "ax.plot(y_pred, color = 'green', label=\"Predicted Bitcoin Price\", linestyle=\"dashed\")\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))  # .3f\n",
    "plt.title(\"Random Forest Regression for Period 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 5))\n",
    "\n",
    "ax.plot(total['Date'], total['BTC_close'], color='red', label=\"Bitcoin Price\")\n",
    "ax.plot(total['Date'][-len(y_train):], y_train, color='blue', label=\"Training Data\")\n",
    "ax.plot(total['Date'][:len(y_test)], y_test, color='orange', label=\"Test Data\")\n",
    "ax.plot(total['Date'][:len(y_pred)], y_pred, color='green', label=\"Predicted Bitcoin Price\", linestyle=\"dashed\")\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x)))) # Định dạng đường trục y\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2affc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
