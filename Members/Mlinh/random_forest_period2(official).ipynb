{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e805ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e626b98e",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "* Handle missing values, duplicated values, outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "87e250f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_csv(\"https://raw.githubusercontent.com/lavibula/ML20222.PredictionBitcoin/main/data/saved_data.csv\")\n",
    "total['Date'] = pd.to_datetime(total['Date'])\n",
    "\n",
    "df = total.set_index('Date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "801ccdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "45076859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0b8e483f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ee1c406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe0d20",
   "metadata": {},
   "source": [
    "# Slpit Data (Testing, Training Data Sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7ffd5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for index in total.index:\n",
    "    total.loc[index, \"Date\"] = datetime.strptime(str(total.loc[index, \"Date\"])[:10], '%Y-%m-%d').date()\n",
    "\n",
    "Start_day = date(2018, 10, 1)\n",
    "Test_day = date(2022,8,1)\n",
    "#chon ra 20-25% data trong giai doan 1\n",
    "End_day = date(2023,4,16)\n",
    "# train, test\n",
    "total = total[(total[\"Date\"] >= Start_day) & (total[\"Date\"] <= End_day)].reset_index(drop = True)\n",
    "train_dataset = total[total[\"Date\"] < Test_day].reset_index(drop = True)\n",
    "test_dataset = total[total[\"Date\"] >= Test_day].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1131eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop([\"Date\"], axis=1)[:-1]\n",
    "y_train = train_dataset[\"BTC_close\"][1:].reset_index(drop=True)\n",
    "\n",
    "X_test = test_dataset.drop([\"Date\"], axis=1)[:-1]\n",
    "y_test = test_dataset[\"BTC_close\"][1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1fbb27dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = len(test_dataset) / len(total)\n",
    "\n",
    "print(\"Tỉ lệ test_data/total:\", test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "50e6e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kích thước X_train:\", X_train.shape)\n",
    "print(\"Kích thước y_train:\", y_train.shape)\n",
    "print(\"Kích thước X_test:\", X_test.shape)\n",
    "print(\"Kích thước y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cb2ec",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "53c11106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn modules\n",
    "import time\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fbc9253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936249a7",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d6774dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1cfa1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "def AUC(y_test, y_pred):\n",
    "    count = 0\n",
    "    for i in range(1,len(y_test)):\n",
    "        if (y_test[i] - y_test[i-1]) * (y_pred[i] - y_pred[i-1]) > 0:\n",
    "            count += 1\n",
    "    return count/(len(y_test)-1)\n",
    "print(\"Test accuracy for train set\")\n",
    "#RMSE\n",
    "print(\"Root Mean Square Error (RMSE):\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "#MAPE\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mean_absolute_percentage_error(y_train,y_train_pred))\n",
    "print()\n",
    "\n",
    "print(\"Test accuracy for test set\")\n",
    "#RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Square Error (RMSE):\", rmse)\n",
    "\n",
    "#MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\" Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "print()\n",
    "AUC = AUC(y_test, y_pred)\n",
    "#AUC\n",
    "print(\"AUC test:\", AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4327e2a7",
   "metadata": {},
   "source": [
    "## Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ea27a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of values for n_estimators\n",
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=1000, num=10)]\n",
    "max_depth = [int(x) for x in np.linspace(2, 10, num = 5)]\n",
    "max_features = [None]\n",
    "bootstrap = [False] # method used to sample data points\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "'max_features': max_features,\n",
    "\n",
    "'max_depth': max_depth,\n",
    "\n",
    "'bootstrap': bootstrap}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada33fa",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0fa09d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Create the RandomizedSearchCV object with early stopping\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions = param_grid, scoring=scoring,\n",
    "                                   cv=200, refit=True, verbose=2,\n",
    "                                   n_jobs = -1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "64370475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print ('Best Parameters: ', rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d69eb3",
   "metadata": {},
   "source": [
    "## Using the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29616102",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "randmf = RandomForestRegressor(**rf_random.best_params_) \n",
    "randmf.fit(X_train, y_train) \n",
    "\n",
    "end_time = time.time()\n",
    "all_rand_run_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred_rand = randmf.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(5, 7))\n",
    "\n",
    "sns.kdeplot(y_test, color=\"r\", label=\"Actual Value\")\n",
    "sns.kdeplot(y_pred_rand, color=\"b\", label=\"Fitted Values\")\n",
    "\n",
    "plt.title('Actual vs Fitted Values for Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "y_train_rand_pred = randmf.predict(X_train)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "def AUC(y_test, y_pred):\n",
    "    count = 0\n",
    "    for i in range(1,len(y_test)):\n",
    "        if (y_test[i] - y_test[i-1]) * (y_pred[i] - y_pred[i-1]) > 0:\n",
    "            count += 1\n",
    "    return count/(len(y_test)-1)\n",
    "print(\"Test accuracy for train set\")\n",
    "#RMSE\n",
    "print(\"Root Mean Square Error (RMSE):\", np.sqrt(mean_squared_error(y_train, y_train_rand_pred)))\n",
    "\n",
    "#MAPE\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mean_absolute_percentage_error(y_train,y_train_rand_pred))\n",
    "print()\n",
    "\n",
    "print(\"Test accuracy for test set\")\n",
    "#RMSE\n",
    "rmse_all_rand = np.sqrt(mean_squared_error(y_test, y_pred_rand))\n",
    "print(\"Root Mean Square Error (RMSE):\", rmse_all_rand)\n",
    "\n",
    "#MAPE\n",
    "mape_all_rand = mean_absolute_percentage_error(y_test, y_pred_rand)\n",
    "print(\" Mean Absolute Percentage Error (MAPE):\", mape_all_rand)\n",
    "print()\n",
    "AUC_all_rand = AUC(y_test, y_pred_rand)\n",
    "#AUC\n",
    "print(\"AUC test:\", AUC_all_rand)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd44ca",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb77d5",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rand = X_train.columns\n",
    "# Get numerical feature importances\n",
    "importances_rand = list(randmf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances_rand = [(feature, round(importance, 4)) for feature, importance in zip(features_rand, importances_rand)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances_rand = sorted(feature_importances_rand, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "for pair in feature_importances_rand:\n",
    "    print('Variable: {:20} Importance: {}'.format(*pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances_rand)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances_rand, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, features_rand, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features sorted from most to least important\n",
    "sorted_importances_rand = [importance[1] for importance in feature_importances_rand]\n",
    "sorted_features_rand = [importance[0] for importance in feature_importances_rand]\n",
    "# Cumulative importances\n",
    "cumulative_importances_rand = np.cumsum(sorted_importances_rand)\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances_rand, 'g-')\n",
    "# Draw line at 90% of importance retained\n",
    "plt.hlines(y = 0.9, xmin=0, xmax=len(sorted_importances_rand), color = 'r', linestyles = 'dashed')\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features_rand, rotation = 'vertical')\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8abc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of features for cumulative importance of 90%\n",
    "# Add 1 because Python is zero-indexed\n",
    "num_rand = np.where(cumulative_importances_rand > 0.9)[0][0] + 1\n",
    "print('Number of features for 90% importance:', num_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a9c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the names of the most important features\n",
    "important_feature_names_rand = [feature[0] for feature in feature_importances_rand[0:num_rand]]\n",
    "print(important_feature_names_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4163b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_rand = X_train[important_feature_names_rand]\n",
    "test_data_rand = X_test[important_feature_names_rand]\n",
    "# Sanity check on operations\n",
    "print('Important train features shape:', train_data_rand.shape)\n",
    "print('Important test features shape:', test_data_rand.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e949a98",
   "metadata": {},
   "source": [
    "#### Training and Evaluating on Important Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716d553",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976818dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train the expanded model on only the important features\n",
    "randmf.fit(train_data_rand, y_train);\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions_rand = randmf.predict(test_data_rand)\n",
    "\n",
    "end_time = time.time()\n",
    "reduce_rand_run_time = end_time - start_time\n",
    "\n",
    "#RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_reduce_rand = np.sqrt(mean_squared_error(y_test, predictions_rand))\n",
    "print(\"RMSE:\", rmse_reduce_rand)\n",
    "print()\n",
    "\n",
    "#MAPE\n",
    "mape_reduce_rand = np.average(np.abs((y_test - predictions_rand) / y_test))\n",
    "print(\"MAPE:\", mape_reduce_rand)\n",
    "print()\n",
    "\n",
    "AUC_reduce_rand = AUC(np.array(y_test), predictions_rand)\n",
    "print(\"AUC test:\", AUC_reduce_rand )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73043622",
   "metadata": {},
   "source": [
    "#### Normalization with original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bba7d4",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42072cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize the features using MinMaxScaler for the training dataset\n",
    "scaler_all_rand = MinMaxScaler()\n",
    "X_train_normalized_all_rand = scaler_all_rand.fit_transform(X_train)\n",
    "\n",
    "# Normalize the features using the same scaler for the testing dataset\n",
    "X_test_normalized_all_rand = scaler_all_rand.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor_all_rand = RandomForestRegressor(**rf_random.best_params_)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rf_regressor_all_rand.fit(X_train_normalized_all_rand, y_train)\n",
    "\n",
    "y_pred_norma_all_rand = rf_regressor_all_rand.predict(X_test_normalized_all_rand)\n",
    "\n",
    "end_time = time.time()\n",
    "normal_all_rand_run_time = end_time - start_time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_normal_all_rand = np.sqrt(mean_squared_error(y_test, y_pred_norma_all_rand))\n",
    "print(\"RMSE:\", rmse_normal_all_rand)\n",
    "print()\n",
    "\n",
    "#MAPE\n",
    "mape_normal_all_rand = np.average(np.abs((y_test - y_pred_norma_all_rand) / y_test))\n",
    "print(\"MAPE:\", mape_normal_all_rand)\n",
    "print()\n",
    "\n",
    "AUC_normal_all_rand = AUC(np.array(y_test), y_pred_norma_all_rand)\n",
    "print(\"AUC test:\", AUC_normal_all_rand )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a10778",
   "metadata": {},
   "source": [
    "#### Normalization with Importance Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e1a58",
   "metadata": {},
   "source": [
    "### Radomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize the features using MinMaxScaler for the training dataset\n",
    "scaler_reduce_rand = MinMaxScaler()\n",
    "X_train_normalized_reduce_rand = scaler_reduce_rand.fit_transform(train_data_rand)\n",
    "\n",
    "# Normalize the features using the same scaler for the testing dataset\n",
    "X_test_normalized_reduce_rand = scaler_reduce_rand.transform(test_data_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ebc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor_reduce_rand = RandomForestRegressor(**rf_random.best_params_)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_regressor_reduce_rand.fit(X_train_normalized_reduce_rand, y_train)\n",
    "\n",
    "y_pred_norma_reduce_rand = rf_regressor_reduce_rand.predict(X_test_normalized_reduce_rand)\n",
    "\n",
    "end_time = time.time()\n",
    "normal_reduce_rand_run_time = end_time - start_time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_normal_reduce_rand = np.sqrt(mean_squared_error(y_test, y_pred_norma_reduce_rand))\n",
    "print(\"RMSE:\", rmse_normal_reduce_rand)\n",
    "print()\n",
    "\n",
    "#MAPE\n",
    "mape_normal_reduce_rand = np.average(np.abs((y_test - y_pred_norma_reduce_rand) / y_test))\n",
    "print(\"MAPE:\", mape_normal_reduce_rand)\n",
    "print()\n",
    "\n",
    "AUC_normal_reduce_rand = AUC(np.array(y_test), y_pred_norma_reduce_rand)\n",
    "print(\"AUC test:\", AUC_normal_reduce_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388cc6b6",
   "metadata": {},
   "source": [
    "## Summary statistical table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ed44c",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_rand(AUC_all_rand, rmse_all_rand, mape_all_rand, all_rand_run_time, \n",
    "                       AUC_reduce_rand, rmse_reduce_rand, mape_reduce_rand, reduce_rand_run_time, \n",
    "                  AUC_normal_all_rand, rmse_normal_all_rand, mape_normal_all_rand, normal_all_rand_run_time,\n",
    "                 AUC_normal_reduce_rand, rmse_normal_reduce_rand, mape_normal_reduce_rand, normal_reduce_rand_run_time):\n",
    "    headers = ['Type', 'Number of Features','Accuracy', 'RMSE', 'MAPE', 'Run Time (s)']\n",
    "    all_results = [['All', len(importances_rand), AUC_all_rand, rmse_all_rand, mape_all_rand, all_rand_run_time],\n",
    "                   ['Reduce', len(important_feature_names_rand), AUC_reduce_rand, rmse_reduce_rand, mape_reduce_rand, reduce_rand_run_time],\n",
    "                   ['Normalization - All', len(importances_rand), AUC_normal_all_rand, rmse_normal_all_rand, mape_normal_all_rand, normal_all_rand_run_time],\n",
    "                  ['Normalization - Reduce', len(important_feature_names_rand), AUC_normal_reduce_rand, rmse_normal_reduce_rand, mape_normal_reduce_rand, normal_reduce_rand_run_time]]\n",
    "\n",
    "    # Calculate the maximum width for each column\n",
    "    col_widths = [max(len(str(row[i])) for row in all_results + [headers]) for i in range(len(headers))]\n",
    "\n",
    "    # Print table headers\n",
    "    header_format = '  '.join(f\"{{:<{width}}}\" for width in col_widths)\n",
    "    print(header_format.format(*headers))\n",
    "\n",
    "    # Print separator row\n",
    "    separator = '-' * (sum(col_widths) + 3 * (len(col_widths) - 1))\n",
    "    print(separator)\n",
    "\n",
    "    # Print table rows\n",
    "    row_format = '  '.join(f\"{{:<{width}}}\" for width in col_widths)\n",
    "    for result in all_results:\n",
    "        index, num_features, AUC, rmse, mape, run_time = result\n",
    "        print(row_format.format(index, num_features, AUC, rmse, mape, run_time))\n",
    "        \n",
    "print_results_rand(AUC_all_rand, rmse_all_rand, mape_all_rand, all_rand_run_time, \n",
    "                       AUC_reduce_rand, rmse_reduce_rand, mape_reduce_rand, reduce_rand_run_time, \n",
    "                  AUC_normal_all_rand, rmse_normal_all_rand, mape_normal_all_rand, normal_all_rand_run_time,\n",
    "                 AUC_normal_reduce_rand, rmse_normal_reduce_rand, mape_normal_reduce_rand, normal_reduce_rand_run_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571c0a6",
   "metadata": {},
   "source": [
    "# Graph Predicted Values with Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9781f6b",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b132ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hien thi ket qua du doan\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "ax.plot(y_test, color = 'red', label=\"Bitcoin Price\")\n",
    "ax.plot(y_pred_rand, color = 'green', label=\"Predicted Bitcoin Price\", linestyle=\"dashed\")\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))  # .3f\n",
    "plt.title(\"Random Forest Regression for Period 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 5))\n",
    "\n",
    "ax.plot(total['Date'], total['BTC_close'], color='red', label=\"Bitcoin Price\")\n",
    "ax.plot(total['Date'][-len(y_train):], y_train, color='blue', label=\"Training Data\")\n",
    "ax.plot(total['Date'][:len(y_test)], y_test, color='orange', label=\"Test Data\")\n",
    "ax.plot(total['Date'][:len(y_pred)], y_pred_rand, color='green', label=\"Predicted Bitcoin Price\", linestyle=\"dashed\")\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x)))) # Định dạng đường trục y\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8ef88",
   "metadata": {},
   "source": [
    "## Comparing randomized search and grid search for hyperparameter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd085606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=10):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b70d7",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((len(rf_random.cv_results_[\"params\"])))\n",
    "report(rf_random.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e54350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf5718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581a4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
